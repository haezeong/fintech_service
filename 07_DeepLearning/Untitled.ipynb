{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1b6c55fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04d37519",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "51bb3714",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = pd.read_csv(\"../06_machine_learning/data/winequality-white.csv\", sep=\";\")\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a4169c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4898 entries, 0 to 4897\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         4898 non-null   float64\n",
      " 1   volatile acidity      4898 non-null   float64\n",
      " 2   citric acid           4898 non-null   float64\n",
      " 3   residual sugar        4898 non-null   float64\n",
      " 4   chlorides             4898 non-null   float64\n",
      " 5   free sulfur dioxide   4898 non-null   float64\n",
      " 6   total sulfur dioxide  4898 non-null   float64\n",
      " 7   density               4898 non-null   float64\n",
      " 8   pH                    4898 non-null   float64\n",
      " 9   sulphates             4898 non-null   float64\n",
      " 10  alcohol               4898 non-null   float64\n",
      " 11  quality               4898 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 459.3 KB\n"
     ]
    }
   ],
   "source": [
    "wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4ba26ec7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "48acc82f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quality\n",
       "6    2198\n",
       "5    1457\n",
       "7     880\n",
       "8     175\n",
       "4     163\n",
       "3      20\n",
       "9       5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2cae47df",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wine.drop('quality', axis=1).copy()\n",
    "y = wine['quality'].copy()\n",
    "y2 = wine['quality'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bd12eb33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 스케일링하기 \n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "\n",
    "# 이상치가 많기 때문에 RobustScaler 로 사용한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0a04e60",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.2       ,  0.09090909,  0.33333333, ..., -0.94736842,\n",
       "        -0.14285714, -0.84210526],\n",
       "       [-0.5       ,  0.36363636,  0.16666667, ...,  0.63157895,\n",
       "         0.14285714, -0.47368421],\n",
       "       [ 1.3       ,  0.18181818,  0.66666667, ...,  0.42105263,\n",
       "        -0.21428571, -0.15789474],\n",
       "       ...,\n",
       "       [-0.3       , -0.18181818, -1.08333333, ..., -1.        ,\n",
       "        -0.07142857, -0.52631579],\n",
       "       [-1.3       ,  0.27272727, -0.16666667, ...,  0.84210526,\n",
       "        -0.64285714,  1.26315789],\n",
       "       [-0.8       , -0.45454545,  0.5       , ...,  0.42105263,\n",
       "        -1.07142857,  0.73684211]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs2 =  RobustScaler() # 중앙값과 IQR 을 사용한 스케일링\n",
    "\n",
    "X_scaled = rs2.fit_transform(X)\n",
    "X_scaled\n",
    "\n",
    "# 중앙값을 기준으로 스케일링하고, 사분위 범위를 사용하여 이상치의 영향을 줄인다. \n",
    "# 이상치에 강한 스케일링 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a7a2ecca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          3      4      5      6      7      8      9\n",
       "0     False  False  False   True  False  False  False\n",
       "1     False  False  False   True  False  False  False\n",
       "2     False  False  False   True  False  False  False\n",
       "3     False  False  False   True  False  False  False\n",
       "4     False  False  False   True  False  False  False\n",
       "...     ...    ...    ...    ...    ...    ...    ...\n",
       "4893  False  False  False   True  False  False  False\n",
       "4894  False  False   True  False  False  False  False\n",
       "4895  False  False  False   True  False  False  False\n",
       "4896  False  False  False  False   True  False  False\n",
       "4897  False  False  False   True  False  False  False\n",
       "\n",
       "[4898 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bb1b9015",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "277c9d15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 데이터 4000개이니 valid 로 하기 \n",
    "\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X_scaled, y, test_size=0.4, stratify=y, random_state=10)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5, stratify=y_valid, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9e0453ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1) Sequential\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, Model,load_model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c7b8c669",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "023a4f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 14:47:51.714570: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 64)                768       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 7,687\n",
      "Trainable params: 7,687\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 14:47:51.716332: I tensorflow/c/logging.cc:34] DirectML: creating device on adapter 0 (AMD Radeon(TM) Graphics)\n",
      "2024-09-10 14:47:51.787792: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 14:47:51.787841: W tensorflow/core/common_runtime/pluggable_device/pluggable_device_bfc_allocator.cc:28] Overriding allow_growth setting because force_memory_growth was requested by the device.\n",
      "2024-09-10 14:47:51.787863: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Dense(64, input_dim=X_train.shape[1], activation='relu'))   # 입력층\n",
    "model2.add(Dense(32, activation='relu'))                  # 은닉층 1\n",
    "model2.add(Dense(64, activation='relu'))                  # 은닉층 2\n",
    "model2.add(Dense(32, activation='relu'))                  # 은닉층 3\n",
    "model2.add(Dense(16, activation='relu'))                  # 은닉층 4\n",
    "model2.add(Dense(7, activation='softmax'))                # 출력층, 다중분류\n",
    "# 클래스가 7개이기 때문에 7을 준다.\n",
    "model2.summary()\n",
    "\n",
    "# 다중분류"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3c48461f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 14:47:52.553923: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-10 14:47:52.612159: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 14:47:52.612233: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 2s 99ms/step - loss: 1.9010 - accuracy: 0.2049 - val_loss: 1.8530 - val_accuracy: 0.3745\n",
      "Epoch 2/10000\n",
      "1/6 [====>.........................] - ETA: 0s - loss: 1.8373 - accuracy: 0.4720"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 14:47:53.508257: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-10 14:47:53.535917: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 14:47:53.535983: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 29ms/step - loss: 1.8020 - accuracy: 0.4523 - val_loss: 1.7453 - val_accuracy: 0.4469\n",
      "Epoch 3/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.6862 - accuracy: 0.4493 - val_loss: 1.6168 - val_accuracy: 0.4480\n",
      "Epoch 4/10000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 1.5490 - accuracy: 0.4489 - val_loss: 1.4837 - val_accuracy: 0.4469\n",
      "Epoch 5/10000\n",
      "6/6 [==============================] - 0s 40ms/step - loss: 1.4167 - accuracy: 0.4571 - val_loss: 1.3713 - val_accuracy: 0.4633\n",
      "Epoch 6/10000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.3149 - accuracy: 0.4997 - val_loss: 1.3030 - val_accuracy: 0.4867\n",
      "Epoch 7/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.2555 - accuracy: 0.5235 - val_loss: 1.2611 - val_accuracy: 0.5051\n",
      "Epoch 8/10000\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 1.2281 - accuracy: 0.5242 - val_loss: 1.2416 - val_accuracy: 0.5071\n",
      "Epoch 9/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 1.2044 - accuracy: 0.5286 - val_loss: 1.2209 - val_accuracy: 0.5245\n",
      "Epoch 10/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.1853 - accuracy: 0.5357 - val_loss: 1.2068 - val_accuracy: 0.5224\n",
      "Epoch 11/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 1.1681 - accuracy: 0.5364 - val_loss: 1.1921 - val_accuracy: 0.5204\n",
      "Epoch 12/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 1.1520 - accuracy: 0.5337 - val_loss: 1.1802 - val_accuracy: 0.5204\n",
      "Epoch 13/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 1.1378 - accuracy: 0.5361 - val_loss: 1.1693 - val_accuracy: 0.5255\n",
      "Epoch 14/10000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 1.1252 - accuracy: 0.5429 - val_loss: 1.1582 - val_accuracy: 0.5255\n",
      "Epoch 15/10000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 1.1143 - accuracy: 0.5494 - val_loss: 1.1480 - val_accuracy: 0.5469\n",
      "Epoch 16/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 1.1019 - accuracy: 0.5579 - val_loss: 1.1383 - val_accuracy: 0.5357\n",
      "Epoch 17/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.0940 - accuracy: 0.5575 - val_loss: 1.1305 - val_accuracy: 0.5337\n",
      "Epoch 18/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.0866 - accuracy: 0.5616 - val_loss: 1.1268 - val_accuracy: 0.5490\n",
      "Epoch 19/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 1.0772 - accuracy: 0.5647 - val_loss: 1.1168 - val_accuracy: 0.5439\n",
      "Epoch 20/10000\n",
      "6/6 [==============================] - 0s 35ms/step - loss: 1.0671 - accuracy: 0.5654 - val_loss: 1.1122 - val_accuracy: 0.5439\n",
      "Epoch 21/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.0618 - accuracy: 0.5660 - val_loss: 1.1054 - val_accuracy: 0.5469\n",
      "Epoch 22/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.0531 - accuracy: 0.5745 - val_loss: 1.0996 - val_accuracy: 0.5429\n",
      "Epoch 23/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 1.0465 - accuracy: 0.5759 - val_loss: 1.0957 - val_accuracy: 0.5480\n",
      "Epoch 24/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.0420 - accuracy: 0.5718 - val_loss: 1.0918 - val_accuracy: 0.5561\n",
      "Epoch 25/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.0355 - accuracy: 0.5773 - val_loss: 1.0913 - val_accuracy: 0.5429\n",
      "Epoch 26/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.0306 - accuracy: 0.5783 - val_loss: 1.0840 - val_accuracy: 0.5531\n",
      "Epoch 27/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.0230 - accuracy: 0.5841 - val_loss: 1.0871 - val_accuracy: 0.5418\n",
      "Epoch 28/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.0177 - accuracy: 0.5779 - val_loss: 1.0773 - val_accuracy: 0.5561\n",
      "Epoch 29/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.0140 - accuracy: 0.5790 - val_loss: 1.0762 - val_accuracy: 0.5398\n",
      "Epoch 30/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 1.0091 - accuracy: 0.5803 - val_loss: 1.0775 - val_accuracy: 0.5449\n",
      "Epoch 31/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.0038 - accuracy: 0.5861 - val_loss: 1.0709 - val_accuracy: 0.5551\n",
      "Epoch 32/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.9977 - accuracy: 0.5892 - val_loss: 1.0771 - val_accuracy: 0.5449\n",
      "Epoch 33/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.9960 - accuracy: 0.5844 - val_loss: 1.0671 - val_accuracy: 0.5510\n",
      "Epoch 34/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.9897 - accuracy: 0.5895 - val_loss: 1.0725 - val_accuracy: 0.5459\n",
      "Epoch 35/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.9871 - accuracy: 0.5865 - val_loss: 1.0648 - val_accuracy: 0.5510\n",
      "Epoch 36/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.9846 - accuracy: 0.5865 - val_loss: 1.0677 - val_accuracy: 0.5480\n",
      "Epoch 37/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.9814 - accuracy: 0.5848 - val_loss: 1.0606 - val_accuracy: 0.5490\n",
      "Epoch 38/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.9748 - accuracy: 0.5933 - val_loss: 1.0601 - val_accuracy: 0.5449\n",
      "Epoch 39/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.9709 - accuracy: 0.5956 - val_loss: 1.0619 - val_accuracy: 0.5541\n",
      "Epoch 40/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.9662 - accuracy: 0.5950 - val_loss: 1.0602 - val_accuracy: 0.5490\n",
      "Epoch 41/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.9642 - accuracy: 0.5960 - val_loss: 1.0616 - val_accuracy: 0.5439\n",
      "Epoch 42/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.9621 - accuracy: 0.5960 - val_loss: 1.0604 - val_accuracy: 0.5449\n",
      "Epoch 43/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.9551 - accuracy: 0.5987 - val_loss: 1.0589 - val_accuracy: 0.5592\n",
      "Epoch 44/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.9530 - accuracy: 0.5990 - val_loss: 1.0613 - val_accuracy: 0.5480\n",
      "Epoch 45/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.9500 - accuracy: 0.6007 - val_loss: 1.0570 - val_accuracy: 0.5541\n",
      "Epoch 46/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.9485 - accuracy: 0.6035 - val_loss: 1.0584 - val_accuracy: 0.5500\n",
      "Epoch 47/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.9444 - accuracy: 0.6072 - val_loss: 1.0571 - val_accuracy: 0.5551\n",
      "Epoch 48/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.9395 - accuracy: 0.6072 - val_loss: 1.0597 - val_accuracy: 0.5510\n",
      "Epoch 49/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.9356 - accuracy: 0.6065 - val_loss: 1.0597 - val_accuracy: 0.5531\n",
      "Epoch 50/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.9317 - accuracy: 0.6103 - val_loss: 1.0586 - val_accuracy: 0.5429\n",
      "Epoch 51/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.9281 - accuracy: 0.6120 - val_loss: 1.0574 - val_accuracy: 0.5571\n",
      "Epoch 52/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.9243 - accuracy: 0.6140 - val_loss: 1.0600 - val_accuracy: 0.5490\n",
      "Epoch 53/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.9208 - accuracy: 0.6161 - val_loss: 1.0620 - val_accuracy: 0.5582\n",
      "Epoch 54/10000\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.9170 - accuracy: 0.6222 - val_loss: 1.0568 - val_accuracy: 0.5480\n",
      "Epoch 55/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.9158 - accuracy: 0.6201 - val_loss: 1.0667 - val_accuracy: 0.5561\n",
      "Epoch 56/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.9151 - accuracy: 0.6229 - val_loss: 1.0652 - val_accuracy: 0.5541\n",
      "Epoch 57/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.9075 - accuracy: 0.6232 - val_loss: 1.0575 - val_accuracy: 0.5561\n",
      "Epoch 58/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.9034 - accuracy: 0.6276 - val_loss: 1.0590 - val_accuracy: 0.5592\n",
      "Epoch 59/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 16ms/step - loss: 0.8980 - accuracy: 0.6253 - val_loss: 1.0598 - val_accuracy: 0.5561\n",
      "Epoch 60/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8957 - accuracy: 0.6249 - val_loss: 1.0598 - val_accuracy: 0.5551\n",
      "Epoch 61/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8927 - accuracy: 0.6293 - val_loss: 1.0591 - val_accuracy: 0.5622\n",
      "Epoch 62/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.8902 - accuracy: 0.6280 - val_loss: 1.0737 - val_accuracy: 0.5510\n",
      "Epoch 63/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8875 - accuracy: 0.6307 - val_loss: 1.0661 - val_accuracy: 0.5551\n",
      "Epoch 64/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.8798 - accuracy: 0.6338 - val_loss: 1.0646 - val_accuracy: 0.5633\n",
      "Epoch 65/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8771 - accuracy: 0.6372 - val_loss: 1.0633 - val_accuracy: 0.5571\n",
      "Epoch 66/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8737 - accuracy: 0.6423 - val_loss: 1.0677 - val_accuracy: 0.5633\n",
      "Epoch 67/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8687 - accuracy: 0.6389 - val_loss: 1.0772 - val_accuracy: 0.5480\n",
      "Epoch 68/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8663 - accuracy: 0.6416 - val_loss: 1.0649 - val_accuracy: 0.5571\n",
      "Epoch 69/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8594 - accuracy: 0.6433 - val_loss: 1.0685 - val_accuracy: 0.5531\n",
      "Epoch 70/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.8557 - accuracy: 0.6477 - val_loss: 1.0688 - val_accuracy: 0.5541\n",
      "Epoch 71/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8524 - accuracy: 0.6481 - val_loss: 1.0759 - val_accuracy: 0.5592\n",
      "Epoch 72/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.8478 - accuracy: 0.6447 - val_loss: 1.0747 - val_accuracy: 0.5633\n",
      "Epoch 73/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8422 - accuracy: 0.6515 - val_loss: 1.0775 - val_accuracy: 0.5643\n",
      "Epoch 74/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8387 - accuracy: 0.6532 - val_loss: 1.0782 - val_accuracy: 0.5684\n",
      "Epoch 75/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8344 - accuracy: 0.6576 - val_loss: 1.0788 - val_accuracy: 0.5612\n",
      "Epoch 76/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8268 - accuracy: 0.6590 - val_loss: 1.1052 - val_accuracy: 0.5561\n",
      "Epoch 77/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8287 - accuracy: 0.6579 - val_loss: 1.0820 - val_accuracy: 0.5643\n",
      "Epoch 78/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8283 - accuracy: 0.6576 - val_loss: 1.0841 - val_accuracy: 0.5663\n",
      "Epoch 79/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8203 - accuracy: 0.6634 - val_loss: 1.0931 - val_accuracy: 0.5684\n",
      "Epoch 80/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.8203 - accuracy: 0.6603 - val_loss: 1.1007 - val_accuracy: 0.5684\n",
      "Epoch 81/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8169 - accuracy: 0.6644 - val_loss: 1.0998 - val_accuracy: 0.5612\n",
      "Epoch 82/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8171 - accuracy: 0.6647 - val_loss: 1.0959 - val_accuracy: 0.5714\n",
      "Epoch 83/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.8056 - accuracy: 0.6722 - val_loss: 1.1180 - val_accuracy: 0.5520\n",
      "Epoch 84/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.8040 - accuracy: 0.6746 - val_loss: 1.1166 - val_accuracy: 0.5694\n",
      "Epoch 85/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7990 - accuracy: 0.6736 - val_loss: 1.1028 - val_accuracy: 0.5724\n",
      "Epoch 86/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7951 - accuracy: 0.6722 - val_loss: 1.1070 - val_accuracy: 0.5745\n",
      "Epoch 87/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7886 - accuracy: 0.6862 - val_loss: 1.1035 - val_accuracy: 0.5786\n",
      "Epoch 88/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7863 - accuracy: 0.6790 - val_loss: 1.1229 - val_accuracy: 0.5786\n",
      "Epoch 89/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7849 - accuracy: 0.6858 - val_loss: 1.1168 - val_accuracy: 0.5786\n",
      "Epoch 90/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7773 - accuracy: 0.6838 - val_loss: 1.1225 - val_accuracy: 0.5704\n",
      "Epoch 91/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7770 - accuracy: 0.6811 - val_loss: 1.1285 - val_accuracy: 0.5694\n",
      "Epoch 92/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7764 - accuracy: 0.6872 - val_loss: 1.1266 - val_accuracy: 0.5714\n",
      "Epoch 93/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7745 - accuracy: 0.6943 - val_loss: 1.1250 - val_accuracy: 0.5806\n",
      "Epoch 94/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7668 - accuracy: 0.6896 - val_loss: 1.1248 - val_accuracy: 0.5735\n",
      "Epoch 95/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7674 - accuracy: 0.6964 - val_loss: 1.1318 - val_accuracy: 0.5745\n",
      "Epoch 96/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7572 - accuracy: 0.7018 - val_loss: 1.1414 - val_accuracy: 0.5796\n",
      "Epoch 97/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7568 - accuracy: 0.6964 - val_loss: 1.1401 - val_accuracy: 0.5673\n",
      "Epoch 98/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7527 - accuracy: 0.7035 - val_loss: 1.1309 - val_accuracy: 0.5816\n",
      "Epoch 99/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7488 - accuracy: 0.7029 - val_loss: 1.1366 - val_accuracy: 0.5857\n",
      "Epoch 100/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7434 - accuracy: 0.7097 - val_loss: 1.1473 - val_accuracy: 0.5735\n",
      "Epoch 101/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7418 - accuracy: 0.7083 - val_loss: 1.1474 - val_accuracy: 0.5786\n",
      "Epoch 102/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7429 - accuracy: 0.7042 - val_loss: 1.1436 - val_accuracy: 0.5827\n",
      "Epoch 103/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7357 - accuracy: 0.7046 - val_loss: 1.1530 - val_accuracy: 0.5745\n",
      "Epoch 104/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7295 - accuracy: 0.7151 - val_loss: 1.1503 - val_accuracy: 0.5837\n",
      "Epoch 105/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7256 - accuracy: 0.7158 - val_loss: 1.1532 - val_accuracy: 0.5796\n",
      "Epoch 106/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7294 - accuracy: 0.7202 - val_loss: 1.1550 - val_accuracy: 0.5776\n",
      "Epoch 107/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7266 - accuracy: 0.7127 - val_loss: 1.1533 - val_accuracy: 0.5745\n",
      "Epoch 108/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7198 - accuracy: 0.7195 - val_loss: 1.1643 - val_accuracy: 0.5816\n",
      "Epoch 109/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7190 - accuracy: 0.7148 - val_loss: 1.1614 - val_accuracy: 0.5786\n",
      "Epoch 110/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.7174 - accuracy: 0.7178 - val_loss: 1.1709 - val_accuracy: 0.5806\n",
      "Epoch 111/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7141 - accuracy: 0.7189 - val_loss: 1.1707 - val_accuracy: 0.5827\n",
      "Epoch 112/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7104 - accuracy: 0.7226 - val_loss: 1.1886 - val_accuracy: 0.5908\n",
      "Epoch 113/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7081 - accuracy: 0.7229 - val_loss: 1.1857 - val_accuracy: 0.5745\n",
      "Epoch 114/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7041 - accuracy: 0.7233 - val_loss: 1.2241 - val_accuracy: 0.5786\n",
      "Epoch 115/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.7061 - accuracy: 0.7199 - val_loss: 1.1954 - val_accuracy: 0.5786\n",
      "Epoch 116/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6987 - accuracy: 0.7226 - val_loss: 1.2269 - val_accuracy: 0.5816\n",
      "Epoch 117/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6984 - accuracy: 0.7246 - val_loss: 1.2070 - val_accuracy: 0.5806\n",
      "Epoch 118/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6953 - accuracy: 0.7270 - val_loss: 1.2054 - val_accuracy: 0.5867\n",
      "Epoch 119/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6911 - accuracy: 0.7270 - val_loss: 1.2239 - val_accuracy: 0.5867\n",
      "Epoch 120/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6860 - accuracy: 0.7304 - val_loss: 1.1978 - val_accuracy: 0.5714\n",
      "Epoch 121/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6782 - accuracy: 0.7383 - val_loss: 1.2107 - val_accuracy: 0.5888\n",
      "Epoch 122/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6820 - accuracy: 0.7342 - val_loss: 1.1993 - val_accuracy: 0.5786\n",
      "Epoch 123/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6842 - accuracy: 0.7314 - val_loss: 1.2053 - val_accuracy: 0.5582\n",
      "Epoch 124/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6838 - accuracy: 0.7386 - val_loss: 1.2149 - val_accuracy: 0.5704\n",
      "Epoch 125/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6757 - accuracy: 0.7372 - val_loss: 1.2093 - val_accuracy: 0.5673\n",
      "Epoch 126/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6768 - accuracy: 0.7369 - val_loss: 1.2086 - val_accuracy: 0.5714\n",
      "Epoch 127/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6673 - accuracy: 0.7451 - val_loss: 1.2055 - val_accuracy: 0.5724\n",
      "Epoch 128/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6665 - accuracy: 0.7471 - val_loss: 1.2213 - val_accuracy: 0.5653\n",
      "Epoch 129/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6639 - accuracy: 0.7423 - val_loss: 1.2230 - val_accuracy: 0.5786\n",
      "Epoch 130/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6602 - accuracy: 0.7481 - val_loss: 1.2257 - val_accuracy: 0.5745\n",
      "Epoch 131/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6585 - accuracy: 0.7464 - val_loss: 1.2340 - val_accuracy: 0.5827\n",
      "Epoch 132/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6548 - accuracy: 0.7481 - val_loss: 1.2374 - val_accuracy: 0.5714\n",
      "Epoch 133/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6502 - accuracy: 0.7519 - val_loss: 1.2635 - val_accuracy: 0.5806\n",
      "Epoch 134/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6519 - accuracy: 0.7536 - val_loss: 1.2427 - val_accuracy: 0.5786\n",
      "Epoch 135/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6461 - accuracy: 0.7526 - val_loss: 1.2585 - val_accuracy: 0.5837\n",
      "Epoch 136/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6421 - accuracy: 0.7505 - val_loss: 1.2437 - val_accuracy: 0.5724\n",
      "Epoch 137/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6376 - accuracy: 0.7617 - val_loss: 1.2526 - val_accuracy: 0.5714\n",
      "Epoch 138/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6330 - accuracy: 0.7631 - val_loss: 1.2508 - val_accuracy: 0.5776\n",
      "Epoch 139/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6351 - accuracy: 0.7587 - val_loss: 1.2580 - val_accuracy: 0.5684\n",
      "Epoch 140/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6365 - accuracy: 0.7594 - val_loss: 1.2632 - val_accuracy: 0.5878\n",
      "Epoch 141/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6303 - accuracy: 0.7668 - val_loss: 1.2640 - val_accuracy: 0.5755\n",
      "Epoch 142/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6221 - accuracy: 0.7692 - val_loss: 1.2776 - val_accuracy: 0.5857\n",
      "Epoch 143/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6216 - accuracy: 0.7709 - val_loss: 1.2872 - val_accuracy: 0.5776\n",
      "Epoch 144/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6214 - accuracy: 0.7675 - val_loss: 1.2917 - val_accuracy: 0.5673\n",
      "Epoch 145/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6191 - accuracy: 0.7689 - val_loss: 1.2776 - val_accuracy: 0.5776\n",
      "Epoch 146/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6153 - accuracy: 0.7723 - val_loss: 1.2859 - val_accuracy: 0.5908\n",
      "Epoch 147/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6150 - accuracy: 0.7679 - val_loss: 1.2990 - val_accuracy: 0.5755\n",
      "Epoch 148/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6131 - accuracy: 0.7709 - val_loss: 1.2858 - val_accuracy: 0.5857\n",
      "Epoch 149/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6058 - accuracy: 0.7760 - val_loss: 1.2999 - val_accuracy: 0.5796\n",
      "Epoch 150/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6072 - accuracy: 0.7709 - val_loss: 1.3137 - val_accuracy: 0.5878\n",
      "Epoch 151/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6042 - accuracy: 0.7771 - val_loss: 1.2960 - val_accuracy: 0.5776\n",
      "Epoch 152/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6040 - accuracy: 0.7726 - val_loss: 1.3056 - val_accuracy: 0.5694\n",
      "Epoch 153/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6103 - accuracy: 0.7723 - val_loss: 1.3149 - val_accuracy: 0.5704\n",
      "Epoch 154/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.6031 - accuracy: 0.7723 - val_loss: 1.3161 - val_accuracy: 0.5786\n"
     ]
    }
   ],
   "source": [
    "model2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "early_stop = EarlyStopping(patience = 100)\n",
    "filepath = \"./model/white_wine{epoch:04d}__{val_loss:.4f}.keras\"\n",
    "model_save = ModelCheckpoint(filepath = filepath, save_best_only=True)\n",
    "history2 = model2.fit(X_train, y_train, epochs = 10000, batch_size = 500, validation_data = (X_valid, y_valid), callbacks = [early_stop, model_save]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f2f4f874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 14:49:37.670096: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-10 14:49:37.800029: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 14:49:37.800100: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2024-09-10 14:49:37.814751: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 14:49:37.814844: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2024-09-10 14:49:37.819582: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 14:49:37.819641: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "wine_best_model = load_model(\"./model/white_wine0054__1.0568.keras\")\n",
    "wine_pred = wine_best_model.predict(X_test)\n",
    "wine_pred = pd.DataFrame(wine_pred, columns = y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7879a836",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000810</td>\n",
       "      <td>0.012706</td>\n",
       "      <td>0.201264</td>\n",
       "      <td>0.713881</td>\n",
       "      <td>0.067780</td>\n",
       "      <td>0.003252</td>\n",
       "      <td>0.000308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.005689</td>\n",
       "      <td>0.015725</td>\n",
       "      <td>0.082667</td>\n",
       "      <td>0.575807</td>\n",
       "      <td>0.266987</td>\n",
       "      <td>0.052112</td>\n",
       "      <td>0.001014</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.004498</td>\n",
       "      <td>0.172154</td>\n",
       "      <td>0.322061</td>\n",
       "      <td>0.364143</td>\n",
       "      <td>0.132409</td>\n",
       "      <td>0.002944</td>\n",
       "      <td>0.001790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000769</td>\n",
       "      <td>0.006318</td>\n",
       "      <td>0.069184</td>\n",
       "      <td>0.676899</td>\n",
       "      <td>0.237136</td>\n",
       "      <td>0.009608</td>\n",
       "      <td>0.000086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001719</td>\n",
       "      <td>0.006446</td>\n",
       "      <td>0.141600</td>\n",
       "      <td>0.705490</td>\n",
       "      <td>0.125645</td>\n",
       "      <td>0.018788</td>\n",
       "      <td>0.000313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0.008449</td>\n",
       "      <td>0.031840</td>\n",
       "      <td>0.538678</td>\n",
       "      <td>0.389349</td>\n",
       "      <td>0.018900</td>\n",
       "      <td>0.008899</td>\n",
       "      <td>0.003885</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>0.001661</td>\n",
       "      <td>0.602809</td>\n",
       "      <td>0.295876</td>\n",
       "      <td>0.066721</td>\n",
       "      <td>0.032486</td>\n",
       "      <td>0.000095</td>\n",
       "      <td>0.000352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>0.002192</td>\n",
       "      <td>0.020843</td>\n",
       "      <td>0.090549</td>\n",
       "      <td>0.612723</td>\n",
       "      <td>0.261726</td>\n",
       "      <td>0.011838</td>\n",
       "      <td>0.000131</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>0.006230</td>\n",
       "      <td>0.114142</td>\n",
       "      <td>0.492076</td>\n",
       "      <td>0.334966</td>\n",
       "      <td>0.045526</td>\n",
       "      <td>0.002929</td>\n",
       "      <td>0.004129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>0.005508</td>\n",
       "      <td>0.024475</td>\n",
       "      <td>0.503148</td>\n",
       "      <td>0.430980</td>\n",
       "      <td>0.024501</td>\n",
       "      <td>0.008750</td>\n",
       "      <td>0.002638</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>980 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            3         4         5         6         7         8         9\n",
       "0    0.000810  0.012706  0.201264  0.713881  0.067780  0.003252  0.000308\n",
       "1    0.005689  0.015725  0.082667  0.575807  0.266987  0.052112  0.001014\n",
       "2    0.004498  0.172154  0.322061  0.364143  0.132409  0.002944  0.001790\n",
       "3    0.000769  0.006318  0.069184  0.676899  0.237136  0.009608  0.000086\n",
       "4    0.001719  0.006446  0.141600  0.705490  0.125645  0.018788  0.000313\n",
       "..        ...       ...       ...       ...       ...       ...       ...\n",
       "975  0.008449  0.031840  0.538678  0.389349  0.018900  0.008899  0.003885\n",
       "976  0.001661  0.602809  0.295876  0.066721  0.032486  0.000095  0.000352\n",
       "977  0.002192  0.020843  0.090549  0.612723  0.261726  0.011838  0.000131\n",
       "978  0.006230  0.114142  0.492076  0.334966  0.045526  0.002929  0.004129\n",
       "979  0.005508  0.024475  0.503148  0.430980  0.024501  0.008750  0.002638\n",
       "\n",
       "[980 rows x 7 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_pred "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "4df405e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      6\n",
       "1      6\n",
       "2      7\n",
       "3      7\n",
       "4      5\n",
       "      ..\n",
       "975    6\n",
       "976    4\n",
       "977    5\n",
       "978    6\n",
       "979    6\n",
       "Length: 980, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_class = y_test.idxmax(axis = 1)\n",
    "y_test_class = y_test_class.reset_index(drop=True)\n",
    "y_test_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26a85def",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      6\n",
       "1      6\n",
       "2      6\n",
       "3      6\n",
       "4      6\n",
       "      ..\n",
       "975    5\n",
       "976    4\n",
       "977    6\n",
       "978    5\n",
       "979    5\n",
       "Length: 980, dtype: int64"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_pred_class = wine_pred.idxmax(axis=1)\n",
    "wine_pred_class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d9ae97a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.67      0.06      0.11        33\n",
      "           5       0.59      0.55      0.57       291\n",
      "           6       0.55      0.73      0.62       440\n",
      "           7       0.53      0.36      0.43       176\n",
      "           8       0.00      0.00      0.00        35\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.56       980\n",
      "   macro avg       0.33      0.24      0.25       980\n",
      "weighted avg       0.54      0.56      0.53       980\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_class, wine_pred_class ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00308f9a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f51edc0e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff517b1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522895f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b507c848",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

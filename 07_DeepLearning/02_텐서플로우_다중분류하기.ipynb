{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1eb46755",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b1db54fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepal_length  sepal_width  petal_length  petal_width      species\n",
       "0           5.1          3.5           1.4          0.2  Iris-setosa\n",
       "1           4.9          3.0           1.4          0.2  Iris-setosa\n",
       "2           4.7          3.2           1.3          0.2  Iris-setosa\n",
       "3           4.6          3.1           1.5          0.2  Iris-setosa\n",
       "4           5.0          3.6           1.4          0.2  Iris-setosa"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/haram4th/ADsP/main/iris3.csv\")\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "455caa31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 넓이와 길이에따라 품종이 달라져"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5d8305d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      " 4   species       150 non-null    object \n",
      "dtypes: float64(4), object(1)\n",
      "memory usage: 6.0+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "985f3679",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "      <td>150.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>5.843333</td>\n",
       "      <td>3.054000</td>\n",
       "      <td>3.758667</td>\n",
       "      <td>1.198667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.828066</td>\n",
       "      <td>0.433594</td>\n",
       "      <td>1.764420</td>\n",
       "      <td>0.763161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>4.300000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>5.100000</td>\n",
       "      <td>2.800000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>0.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>5.800000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>4.350000</td>\n",
       "      <td>1.300000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>6.400000</td>\n",
       "      <td>3.300000</td>\n",
       "      <td>5.100000</td>\n",
       "      <td>1.800000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>7.900000</td>\n",
       "      <td>4.400000</td>\n",
       "      <td>6.900000</td>\n",
       "      <td>2.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       sepal_length  sepal_width  petal_length  petal_width\n",
       "count    150.000000   150.000000    150.000000   150.000000\n",
       "mean       5.843333     3.054000      3.758667     1.198667\n",
       "std        0.828066     0.433594      1.764420     0.763161\n",
       "min        4.300000     2.000000      1.000000     0.100000\n",
       "25%        5.100000     2.800000      1.600000     0.300000\n",
       "50%        5.800000     3.000000      4.350000     1.300000\n",
       "75%        6.400000     3.300000      5.100000     1.800000\n",
       "max        7.900000     4.400000      6.900000     2.500000"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "537e7eee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "60940977",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "species\n",
       "Iris-setosa        50\n",
       "Iris-versicolor    50\n",
       "Iris-virginica     50\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['species'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b78e4506",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data.drop(\"species\", axis=1)\n",
    "y = data['species']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6d042b20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "106e6d69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>0.625000</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.050847</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.083333</td>\n",
       "      <td>0.458333</td>\n",
       "      <td>0.084746</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.194444</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.067797</td>\n",
       "      <td>0.041667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.208333</td>\n",
       "      <td>0.677966</td>\n",
       "      <td>0.750000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>0.611111</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.711864</td>\n",
       "      <td>0.791667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>0.527778</td>\n",
       "      <td>0.583333</td>\n",
       "      <td>0.745763</td>\n",
       "      <td>0.916667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.416667</td>\n",
       "      <td>0.694915</td>\n",
       "      <td>0.708333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width\n",
       "0        0.222222     0.625000      0.067797     0.041667\n",
       "1        0.166667     0.416667      0.067797     0.041667\n",
       "2        0.111111     0.500000      0.050847     0.041667\n",
       "3        0.083333     0.458333      0.084746     0.041667\n",
       "4        0.194444     0.666667      0.067797     0.041667\n",
       "..            ...          ...           ...          ...\n",
       "145      0.666667     0.416667      0.711864     0.916667\n",
       "146      0.555556     0.208333      0.677966     0.750000\n",
       "147      0.611111     0.416667      0.711864     0.791667\n",
       "148      0.527778     0.583333      0.745763     0.916667\n",
       "149      0.444444     0.416667      0.694915     0.708333\n",
       "\n",
       "[150 rows x 4 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mms = MinMaxScaler()\n",
    "X_scaled = mms.fit_transform(X)\n",
    "X_scaled = pd.DataFrame(X_scaled, columns=X.columns)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "38ef5cd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dfadd523",
   "metadata": {},
   "outputs": [],
   "source": [
    "le = LabelEncoder()\n",
    "y_labeled = le.fit_transform(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d9906781",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2,\n",
       "       2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_labeled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "de10a7ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "af8cfd30",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2914cad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_test2, y_train2, y_test2 = train_test_split(X_scaled, y_labeled, test_size=0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cb998cf7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00        14\n",
      "           1       0.94      1.00      0.97        17\n",
      "           2       1.00      0.93      0.96        14\n",
      "\n",
      "    accuracy                           0.98        45\n",
      "   macro avg       0.98      0.98      0.98        45\n",
      "weighted avg       0.98      0.98      0.98        45\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=3, random_state=10)\n",
    "dtc.fit(X_train2, y_train2)\n",
    "pred2 = dtc.predict(X_test2)\n",
    "print(classification_report(y_test2, pred2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e9da5e4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iris-setosa</th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>146</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>147</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>150 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Iris-setosa  Iris-versicolor  Iris-virginica\n",
       "0           True            False           False\n",
       "1           True            False           False\n",
       "2           True            False           False\n",
       "3           True            False           False\n",
       "4           True            False           False\n",
       "..           ...              ...             ...\n",
       "145        False            False            True\n",
       "146        False            False            True\n",
       "147        False            False            True\n",
       "148        False            False            True\n",
       "149        False            False            True\n",
       "\n",
       "[150 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y= pd.get_dummies(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86db28fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size= 0.3, random_state=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca013482",
   "metadata": {},
   "source": [
    "# Sequential"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "edf1f0f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 10:19:58.699691: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-10 10:20:00.515217: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libdirectml.d6f03b303ac3c4f2eeb8ca631688c9757b361310.so\n",
      "2024-09-10 10:20:00.515360: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libdxcore.so\n",
      "2024-09-10 10:20:00.519269: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libd3d12.so\n",
      "2024-09-10 10:20:01.110013: I tensorflow/c/logging.cc:34] DirectML device enumeration: found 1 compatible adapters.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1fbaa8c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 12)                60        \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 6)                 78        \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 3)                 21        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 159\n",
      "Trainable params: 159\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 10:20:01.414838: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-10 10:20:01.416343: I tensorflow/c/logging.cc:34] DirectML: creating device on adapter 0 (AMD Radeon(TM) Graphics)\n",
      "2024-09-10 10:20:01.490759: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 10:20:01.490809: W tensorflow/core/common_runtime/pluggable_device/pluggable_device_bfc_allocator.cc:28] Overriding allow_growth setting because force_memory_growth was requested by the device.\n",
      "2024-09-10 10:20:01.490831: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(12, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(6, activation='relu'))\n",
    "model.add(Dense(3, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "03cc182f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 10:23:46.275373: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-10 10:23:46.318938: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 10:23:46.319015: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 903ms/step - loss: 1.1375 - accuracy: 0.3429 - val_loss: 1.1626 - val_accuracy: 0.3111\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1358 - accuracy: 0.3429 - val_loss: 1.1608 - val_accuracy: 0.3111\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.1342 - accuracy: 0.3429 - val_loss: 1.1590 - val_accuracy: 0.3111\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.1326 - accuracy: 0.3429 - val_loss: 1.1572 - val_accuracy: 0.3111\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1310 - accuracy: 0.3429"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 10:23:46.861177: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-10 10:23:46.884691: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 10:23:46.884770: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step - loss: 1.1310 - accuracy: 0.3429 - val_loss: 1.1554 - val_accuracy: 0.3111\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1294 - accuracy: 0.3429 - val_loss: 1.1537 - val_accuracy: 0.3111\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1278 - accuracy: 0.3429 - val_loss: 1.1519 - val_accuracy: 0.3111\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.1263 - accuracy: 0.3429 - val_loss: 1.1501 - val_accuracy: 0.3111\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1247 - accuracy: 0.3429 - val_loss: 1.1483 - val_accuracy: 0.3111\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.1232 - accuracy: 0.3429 - val_loss: 1.1466 - val_accuracy: 0.3111\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1217 - accuracy: 0.3429 - val_loss: 1.1449 - val_accuracy: 0.3111\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1202 - accuracy: 0.3429 - val_loss: 1.1432 - val_accuracy: 0.3111\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.1188 - accuracy: 0.3429 - val_loss: 1.1415 - val_accuracy: 0.3111\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.1173 - accuracy: 0.3429 - val_loss: 1.1398 - val_accuracy: 0.3111\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.1159 - accuracy: 0.3429 - val_loss: 1.1382 - val_accuracy: 0.2889\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.1145 - accuracy: 0.3429 - val_loss: 1.1366 - val_accuracy: 0.2889\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.1131 - accuracy: 0.3429 - val_loss: 1.1350 - val_accuracy: 0.2889\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.1117 - accuracy: 0.3429 - val_loss: 1.1334 - val_accuracy: 0.2889\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1104 - accuracy: 0.3429 - val_loss: 1.1319 - val_accuracy: 0.2889\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1091 - accuracy: 0.3429 - val_loss: 1.1303 - val_accuracy: 0.2889\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.1078 - accuracy: 0.3429 - val_loss: 1.1288 - val_accuracy: 0.2889\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1064 - accuracy: 0.3429 - val_loss: 1.1273 - val_accuracy: 0.2889\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1051 - accuracy: 0.3429 - val_loss: 1.1259 - val_accuracy: 0.2889\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1039 - accuracy: 0.3429 - val_loss: 1.1245 - val_accuracy: 0.2889\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.1026 - accuracy: 0.3429 - val_loss: 1.1231 - val_accuracy: 0.2889\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.1013 - accuracy: 0.3429 - val_loss: 1.1217 - val_accuracy: 0.2889\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.1000 - accuracy: 0.3429 - val_loss: 1.1203 - val_accuracy: 0.2889\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0988 - accuracy: 0.3524 - val_loss: 1.1190 - val_accuracy: 0.3111\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0976 - accuracy: 0.3714 - val_loss: 1.1177 - val_accuracy: 0.3111\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 1.0964 - accuracy: 0.4000 - val_loss: 1.1164 - val_accuracy: 0.3333\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0951 - accuracy: 0.4190 - val_loss: 1.1151 - val_accuracy: 0.3556\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 1.0939 - accuracy: 0.4571 - val_loss: 1.1139 - val_accuracy: 0.3556\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0928 - accuracy: 0.4667 - val_loss: 1.1126 - val_accuracy: 0.3556\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0916 - accuracy: 0.4952 - val_loss: 1.1114 - val_accuracy: 0.4222\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0904 - accuracy: 0.5333 - val_loss: 1.1102 - val_accuracy: 0.4444\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0892 - accuracy: 0.5714 - val_loss: 1.1089 - val_accuracy: 0.4667\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0881 - accuracy: 0.6000 - val_loss: 1.1077 - val_accuracy: 0.5333\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0869 - accuracy: 0.6286 - val_loss: 1.1066 - val_accuracy: 0.5333\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0858 - accuracy: 0.6381 - val_loss: 1.1054 - val_accuracy: 0.5333\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0846 - accuracy: 0.6476 - val_loss: 1.1042 - val_accuracy: 0.5333\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0835 - accuracy: 0.6571 - val_loss: 1.1030 - val_accuracy: 0.5556\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0823 - accuracy: 0.6762 - val_loss: 1.1019 - val_accuracy: 0.5778\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0812 - accuracy: 0.6857 - val_loss: 1.1007 - val_accuracy: 0.5778\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0800 - accuracy: 0.6857 - val_loss: 1.0996 - val_accuracy: 0.5778\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0789 - accuracy: 0.6857 - val_loss: 1.0984 - val_accuracy: 0.5778\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0777 - accuracy: 0.6857 - val_loss: 1.0972 - val_accuracy: 0.5778\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0766 - accuracy: 0.6857 - val_loss: 1.0961 - val_accuracy: 0.6000\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0754 - accuracy: 0.6857 - val_loss: 1.0949 - val_accuracy: 0.6000\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0743 - accuracy: 0.6857 - val_loss: 1.0938 - val_accuracy: 0.6000\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0731 - accuracy: 0.6857 - val_loss: 1.0926 - val_accuracy: 0.6000\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0719 - accuracy: 0.6857 - val_loss: 1.0915 - val_accuracy: 0.6000\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0708 - accuracy: 0.6857 - val_loss: 1.0904 - val_accuracy: 0.6000\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0696 - accuracy: 0.6857 - val_loss: 1.0892 - val_accuracy: 0.6000\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0684 - accuracy: 0.6857 - val_loss: 1.0881 - val_accuracy: 0.6000\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0673 - accuracy: 0.6857 - val_loss: 1.0869 - val_accuracy: 0.6000\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0661 - accuracy: 0.6857 - val_loss: 1.0858 - val_accuracy: 0.6000\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0649 - accuracy: 0.6857 - val_loss: 1.0846 - val_accuracy: 0.6000\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0637 - accuracy: 0.6857 - val_loss: 1.0835 - val_accuracy: 0.6000\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0625 - accuracy: 0.6857 - val_loss: 1.0823 - val_accuracy: 0.6000\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0613 - accuracy: 0.6857 - val_loss: 1.0811 - val_accuracy: 0.6000\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0601 - accuracy: 0.6857 - val_loss: 1.0800 - val_accuracy: 0.6000\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0589 - accuracy: 0.6857 - val_loss: 1.0788 - val_accuracy: 0.6000\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0577 - accuracy: 0.6857 - val_loss: 1.0777 - val_accuracy: 0.6000\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0565 - accuracy: 0.6857 - val_loss: 1.0765 - val_accuracy: 0.6000\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0552 - accuracy: 0.6857 - val_loss: 1.0753 - val_accuracy: 0.6000\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0540 - accuracy: 0.6857 - val_loss: 1.0741 - val_accuracy: 0.6000\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0527 - accuracy: 0.6857 - val_loss: 1.0730 - val_accuracy: 0.6000\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0515 - accuracy: 0.6857 - val_loss: 1.0718 - val_accuracy: 0.6000\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0502 - accuracy: 0.6857 - val_loss: 1.0706 - val_accuracy: 0.6000\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0490 - accuracy: 0.6857 - val_loss: 1.0694 - val_accuracy: 0.6000\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0477 - accuracy: 0.6857 - val_loss: 1.0682 - val_accuracy: 0.6000\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0464 - accuracy: 0.6857 - val_loss: 1.0670 - val_accuracy: 0.6000\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0451 - accuracy: 0.6857 - val_loss: 1.0658 - val_accuracy: 0.6000\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0438 - accuracy: 0.6857 - val_loss: 1.0646 - val_accuracy: 0.6000\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0425 - accuracy: 0.6857 - val_loss: 1.0633 - val_accuracy: 0.6000\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0412 - accuracy: 0.6857 - val_loss: 1.0621 - val_accuracy: 0.6000\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0399 - accuracy: 0.6857 - val_loss: 1.0609 - val_accuracy: 0.6000\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0386 - accuracy: 0.6857 - val_loss: 1.0596 - val_accuracy: 0.6000\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0372 - accuracy: 0.6857 - val_loss: 1.0584 - val_accuracy: 0.6000\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0359 - accuracy: 0.6857 - val_loss: 1.0571 - val_accuracy: 0.6000\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0346 - accuracy: 0.6857 - val_loss: 1.0559 - val_accuracy: 0.6000\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0332 - accuracy: 0.6857 - val_loss: 1.0546 - val_accuracy: 0.6000\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0319 - accuracy: 0.6857 - val_loss: 1.0534 - val_accuracy: 0.6000\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0305 - accuracy: 0.6857 - val_loss: 1.0521 - val_accuracy: 0.6000\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0292 - accuracy: 0.6857 - val_loss: 1.0508 - val_accuracy: 0.6000\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0278 - accuracy: 0.6857 - val_loss: 1.0495 - val_accuracy: 0.6000\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0264 - accuracy: 0.6857 - val_loss: 1.0482 - val_accuracy: 0.6000\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0250 - accuracy: 0.6857 - val_loss: 1.0469 - val_accuracy: 0.6000\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0237 - accuracy: 0.6857 - val_loss: 1.0456 - val_accuracy: 0.6000\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0223 - accuracy: 0.6857 - val_loss: 1.0443 - val_accuracy: 0.6000\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0209 - accuracy: 0.6857 - val_loss: 1.0431 - val_accuracy: 0.6000\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0195 - accuracy: 0.6857 - val_loss: 1.0418 - val_accuracy: 0.6000\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0181 - accuracy: 0.6857 - val_loss: 1.0405 - val_accuracy: 0.6000\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0168 - accuracy: 0.6857 - val_loss: 1.0392 - val_accuracy: 0.6000\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0154 - accuracy: 0.6857 - val_loss: 1.0379 - val_accuracy: 0.6000\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0140 - accuracy: 0.6857 - val_loss: 1.0366 - val_accuracy: 0.6000\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0126 - accuracy: 0.6857 - val_loss: 1.0353 - val_accuracy: 0.6000\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0112 - accuracy: 0.6857 - val_loss: 1.0340 - val_accuracy: 0.6000\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0098 - accuracy: 0.6857 - val_loss: 1.0327 - val_accuracy: 0.6000\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0083 - accuracy: 0.6857 - val_loss: 1.0314 - val_accuracy: 0.6000\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0069 - accuracy: 0.6857 - val_loss: 1.0301 - val_accuracy: 0.6000\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0055 - accuracy: 0.6857 - val_loss: 1.0287 - val_accuracy: 0.6000\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0040 - accuracy: 0.6857 - val_loss: 1.0274 - val_accuracy: 0.6000\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 1.0026 - accuracy: 0.6857 - val_loss: 1.0260 - val_accuracy: 0.6000\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0011 - accuracy: 0.6857 - val_loss: 1.0247 - val_accuracy: 0.6000\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9996 - accuracy: 0.6857 - val_loss: 1.0233 - val_accuracy: 0.6000\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9981 - accuracy: 0.6857 - val_loss: 1.0220 - val_accuracy: 0.6000\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9967 - accuracy: 0.6857 - val_loss: 1.0206 - val_accuracy: 0.6000\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9951 - accuracy: 0.6857 - val_loss: 1.0192 - val_accuracy: 0.6000\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9936 - accuracy: 0.6857 - val_loss: 1.0178 - val_accuracy: 0.6000\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9921 - accuracy: 0.6857 - val_loss: 1.0164 - val_accuracy: 0.6000\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9906 - accuracy: 0.6857 - val_loss: 1.0149 - val_accuracy: 0.6000\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9890 - accuracy: 0.6857 - val_loss: 1.0135 - val_accuracy: 0.6000\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9875 - accuracy: 0.6857 - val_loss: 1.0121 - val_accuracy: 0.6000\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9859 - accuracy: 0.6857 - val_loss: 1.0106 - val_accuracy: 0.6000\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9843 - accuracy: 0.6857 - val_loss: 1.0092 - val_accuracy: 0.6000\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9827 - accuracy: 0.6857 - val_loss: 1.0077 - val_accuracy: 0.6000\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9811 - accuracy: 0.6857 - val_loss: 1.0062 - val_accuracy: 0.6000\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9795 - accuracy: 0.6857 - val_loss: 1.0047 - val_accuracy: 0.6000\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9779 - accuracy: 0.6857 - val_loss: 1.0032 - val_accuracy: 0.6000\n",
      "Epoch 121/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9763 - accuracy: 0.6857 - val_loss: 1.0016 - val_accuracy: 0.6000\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9746 - accuracy: 0.6857 - val_loss: 1.0001 - val_accuracy: 0.6000\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9730 - accuracy: 0.6857 - val_loss: 0.9986 - val_accuracy: 0.6000\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9713 - accuracy: 0.6857 - val_loss: 0.9970 - val_accuracy: 0.6000\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9696 - accuracy: 0.6857 - val_loss: 0.9955 - val_accuracy: 0.6000\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.9679 - accuracy: 0.6857 - val_loss: 0.9939 - val_accuracy: 0.6000\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9663 - accuracy: 0.6857 - val_loss: 0.9923 - val_accuracy: 0.6000\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9645 - accuracy: 0.6857 - val_loss: 0.9907 - val_accuracy: 0.6000\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9628 - accuracy: 0.6857 - val_loss: 0.9891 - val_accuracy: 0.6000\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9611 - accuracy: 0.6857 - val_loss: 0.9874 - val_accuracy: 0.6000\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9593 - accuracy: 0.6857 - val_loss: 0.9858 - val_accuracy: 0.6000\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9576 - accuracy: 0.6857 - val_loss: 0.9841 - val_accuracy: 0.6000\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9558 - accuracy: 0.6857 - val_loss: 0.9825 - val_accuracy: 0.6000\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9540 - accuracy: 0.6857 - val_loss: 0.9808 - val_accuracy: 0.6000\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9522 - accuracy: 0.6857 - val_loss: 0.9791 - val_accuracy: 0.6000\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9504 - accuracy: 0.6857 - val_loss: 0.9774 - val_accuracy: 0.6000\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9486 - accuracy: 0.6857 - val_loss: 0.9757 - val_accuracy: 0.6000\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9467 - accuracy: 0.6857 - val_loss: 0.9739 - val_accuracy: 0.6000\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9449 - accuracy: 0.6857 - val_loss: 0.9722 - val_accuracy: 0.6000\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9430 - accuracy: 0.6857 - val_loss: 0.9704 - val_accuracy: 0.6000\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9412 - accuracy: 0.6857 - val_loss: 0.9687 - val_accuracy: 0.6000\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9393 - accuracy: 0.6857 - val_loss: 0.9669 - val_accuracy: 0.6000\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9374 - accuracy: 0.6857 - val_loss: 0.9651 - val_accuracy: 0.6000\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9355 - accuracy: 0.6857 - val_loss: 0.9633 - val_accuracy: 0.6222\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9336 - accuracy: 0.6857 - val_loss: 0.9615 - val_accuracy: 0.6222\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9317 - accuracy: 0.6857 - val_loss: 0.9597 - val_accuracy: 0.6222\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9298 - accuracy: 0.6857 - val_loss: 0.9579 - val_accuracy: 0.6222\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.9278 - accuracy: 0.6857 - val_loss: 0.9561 - val_accuracy: 0.6222\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9259 - accuracy: 0.6857 - val_loss: 0.9543 - val_accuracy: 0.6222\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9239 - accuracy: 0.6857 - val_loss: 0.9524 - val_accuracy: 0.6222\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.9220 - accuracy: 0.6857 - val_loss: 0.9506 - val_accuracy: 0.6222\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9200 - accuracy: 0.6857 - val_loss: 0.9487 - val_accuracy: 0.6222\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9180 - accuracy: 0.6857 - val_loss: 0.9469 - val_accuracy: 0.6222\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9160 - accuracy: 0.6857 - val_loss: 0.9450 - val_accuracy: 0.6222\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9140 - accuracy: 0.6857 - val_loss: 0.9431 - val_accuracy: 0.6222\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9120 - accuracy: 0.6857 - val_loss: 0.9412 - val_accuracy: 0.6222\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9099 - accuracy: 0.6857 - val_loss: 0.9394 - val_accuracy: 0.6222\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9079 - accuracy: 0.6857 - val_loss: 0.9375 - val_accuracy: 0.6222\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9059 - accuracy: 0.6857 - val_loss: 0.9355 - val_accuracy: 0.6222\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9038 - accuracy: 0.6857 - val_loss: 0.9336 - val_accuracy: 0.6222\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9017 - accuracy: 0.6857 - val_loss: 0.9317 - val_accuracy: 0.6222\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8997 - accuracy: 0.6857 - val_loss: 0.9298 - val_accuracy: 0.6222\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8976 - accuracy: 0.6857 - val_loss: 0.9278 - val_accuracy: 0.6222\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8955 - accuracy: 0.6857 - val_loss: 0.9258 - val_accuracy: 0.6222\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8934 - accuracy: 0.6857 - val_loss: 0.9239 - val_accuracy: 0.6222\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8913 - accuracy: 0.6857 - val_loss: 0.9219 - val_accuracy: 0.6222\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8891 - accuracy: 0.6857 - val_loss: 0.9199 - val_accuracy: 0.6222\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8870 - accuracy: 0.6857 - val_loss: 0.9178 - val_accuracy: 0.6222\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8848 - accuracy: 0.6857 - val_loss: 0.9158 - val_accuracy: 0.6222\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8827 - accuracy: 0.6857 - val_loss: 0.9138 - val_accuracy: 0.6222\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8805 - accuracy: 0.6857 - val_loss: 0.9117 - val_accuracy: 0.6222\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8783 - accuracy: 0.6857 - val_loss: 0.9097 - val_accuracy: 0.6222\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8761 - accuracy: 0.6857 - val_loss: 0.9076 - val_accuracy: 0.6222\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8739 - accuracy: 0.6857 - val_loss: 0.9055 - val_accuracy: 0.6222\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8717 - accuracy: 0.6857 - val_loss: 0.9034 - val_accuracy: 0.6222\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8695 - accuracy: 0.6857 - val_loss: 0.9013 - val_accuracy: 0.6222\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8673 - accuracy: 0.6857 - val_loss: 0.8992 - val_accuracy: 0.6222\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8651 - accuracy: 0.6857 - val_loss: 0.8971 - val_accuracy: 0.6222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8628 - accuracy: 0.6857 - val_loss: 0.8950 - val_accuracy: 0.6222\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8606 - accuracy: 0.6857 - val_loss: 0.8929 - val_accuracy: 0.6222\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8583 - accuracy: 0.6857 - val_loss: 0.8908 - val_accuracy: 0.6222\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8560 - accuracy: 0.6857 - val_loss: 0.8887 - val_accuracy: 0.6222\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8538 - accuracy: 0.6857 - val_loss: 0.8866 - val_accuracy: 0.6222\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8515 - accuracy: 0.6857 - val_loss: 0.8845 - val_accuracy: 0.6222\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8492 - accuracy: 0.6857 - val_loss: 0.8823 - val_accuracy: 0.6222\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8470 - accuracy: 0.6857 - val_loss: 0.8802 - val_accuracy: 0.6222\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8447 - accuracy: 0.6857 - val_loss: 0.8780 - val_accuracy: 0.6222\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8424 - accuracy: 0.6857 - val_loss: 0.8759 - val_accuracy: 0.6222\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8401 - accuracy: 0.6857 - val_loss: 0.8737 - val_accuracy: 0.6222\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8378 - accuracy: 0.6857 - val_loss: 0.8716 - val_accuracy: 0.6222\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8355 - accuracy: 0.6857 - val_loss: 0.8694 - val_accuracy: 0.6222\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8332 - accuracy: 0.6857 - val_loss: 0.8672 - val_accuracy: 0.6222\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8309 - accuracy: 0.6857 - val_loss: 0.8650 - val_accuracy: 0.6222\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8285 - accuracy: 0.6857 - val_loss: 0.8628 - val_accuracy: 0.6222\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8262 - accuracy: 0.6857 - val_loss: 0.8607 - val_accuracy: 0.6222\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8239 - accuracy: 0.6857 - val_loss: 0.8585 - val_accuracy: 0.6222\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8216 - accuracy: 0.6857 - val_loss: 0.8563 - val_accuracy: 0.6222\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8192 - accuracy: 0.6857 - val_loss: 0.8540 - val_accuracy: 0.6222\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8169 - accuracy: 0.6857 - val_loss: 0.8518 - val_accuracy: 0.6222\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8145 - accuracy: 0.6857 - val_loss: 0.8496 - val_accuracy: 0.6222\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8122 - accuracy: 0.6857 - val_loss: 0.8474 - val_accuracy: 0.6222\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8099 - accuracy: 0.6857 - val_loss: 0.8451 - val_accuracy: 0.6222\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8075 - accuracy: 0.6857 - val_loss: 0.8429 - val_accuracy: 0.6222\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8052 - accuracy: 0.6857 - val_loss: 0.8406 - val_accuracy: 0.6222\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8028 - accuracy: 0.6857 - val_loss: 0.8384 - val_accuracy: 0.6222\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8005 - accuracy: 0.6857 - val_loss: 0.8361 - val_accuracy: 0.6222\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7981 - accuracy: 0.6857 - val_loss: 0.8339 - val_accuracy: 0.6222\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7957 - accuracy: 0.6857 - val_loss: 0.8316 - val_accuracy: 0.6222\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7934 - accuracy: 0.6857 - val_loss: 0.8294 - val_accuracy: 0.6222\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7910 - accuracy: 0.6857 - val_loss: 0.8272 - val_accuracy: 0.6222\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7887 - accuracy: 0.6857 - val_loss: 0.8249 - val_accuracy: 0.6444\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7863 - accuracy: 0.6857 - val_loss: 0.8227 - val_accuracy: 0.6444\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7840 - accuracy: 0.6857 - val_loss: 0.8205 - val_accuracy: 0.6444\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7816 - accuracy: 0.6857 - val_loss: 0.8183 - val_accuracy: 0.6444\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7792 - accuracy: 0.6857 - val_loss: 0.8160 - val_accuracy: 0.6444\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7769 - accuracy: 0.6857 - val_loss: 0.8138 - val_accuracy: 0.6444\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7745 - accuracy: 0.6857 - val_loss: 0.8116 - val_accuracy: 0.6444\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7722 - accuracy: 0.6857 - val_loss: 0.8093 - val_accuracy: 0.6444\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7698 - accuracy: 0.6857 - val_loss: 0.8071 - val_accuracy: 0.6444\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7675 - accuracy: 0.6857 - val_loss: 0.8048 - val_accuracy: 0.6444\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7651 - accuracy: 0.6857 - val_loss: 0.8026 - val_accuracy: 0.6444\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7628 - accuracy: 0.6952 - val_loss: 0.8004 - val_accuracy: 0.6444\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7604 - accuracy: 0.6952 - val_loss: 0.7982 - val_accuracy: 0.6444\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7581 - accuracy: 0.7048 - val_loss: 0.7959 - val_accuracy: 0.6444\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7557 - accuracy: 0.7048 - val_loss: 0.7937 - val_accuracy: 0.6444\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7534 - accuracy: 0.7048 - val_loss: 0.7915 - val_accuracy: 0.6444\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7511 - accuracy: 0.7048 - val_loss: 0.7893 - val_accuracy: 0.6444\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7487 - accuracy: 0.7048 - val_loss: 0.7871 - val_accuracy: 0.6444\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7464 - accuracy: 0.7048 - val_loss: 0.7849 - val_accuracy: 0.6444\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7441 - accuracy: 0.7048 - val_loss: 0.7827 - val_accuracy: 0.6444\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7418 - accuracy: 0.7048 - val_loss: 0.7806 - val_accuracy: 0.6444\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7394 - accuracy: 0.7048 - val_loss: 0.7784 - val_accuracy: 0.6444\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7371 - accuracy: 0.7048 - val_loss: 0.7762 - val_accuracy: 0.6444\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7348 - accuracy: 0.7048 - val_loss: 0.7740 - val_accuracy: 0.6444\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7325 - accuracy: 0.7048 - val_loss: 0.7718 - val_accuracy: 0.6444\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7302 - accuracy: 0.7048 - val_loss: 0.7695 - val_accuracy: 0.6444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7279 - accuracy: 0.7048 - val_loss: 0.7673 - val_accuracy: 0.6444\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7256 - accuracy: 0.7143 - val_loss: 0.7651 - val_accuracy: 0.6444\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7233 - accuracy: 0.7143 - val_loss: 0.7629 - val_accuracy: 0.6444\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7211 - accuracy: 0.7143 - val_loss: 0.7608 - val_accuracy: 0.6444\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7188 - accuracy: 0.7143 - val_loss: 0.7586 - val_accuracy: 0.6444\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7165 - accuracy: 0.7143 - val_loss: 0.7565 - val_accuracy: 0.6444\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7143 - accuracy: 0.7143 - val_loss: 0.7544 - val_accuracy: 0.6444\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7120 - accuracy: 0.7143 - val_loss: 0.7522 - val_accuracy: 0.6444\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7098 - accuracy: 0.7143 - val_loss: 0.7501 - val_accuracy: 0.6444\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7075 - accuracy: 0.7143 - val_loss: 0.7479 - val_accuracy: 0.6444\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.7053 - accuracy: 0.7143 - val_loss: 0.7458 - val_accuracy: 0.6444\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.7031 - accuracy: 0.7143 - val_loss: 0.7436 - val_accuracy: 0.6444\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7008 - accuracy: 0.7143 - val_loss: 0.7415 - val_accuracy: 0.6444\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6986 - accuracy: 0.7143 - val_loss: 0.7394 - val_accuracy: 0.6444\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6964 - accuracy: 0.7143 - val_loss: 0.7373 - val_accuracy: 0.6444\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6942 - accuracy: 0.7143 - val_loss: 0.7352 - val_accuracy: 0.6444\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6920 - accuracy: 0.7143 - val_loss: 0.7331 - val_accuracy: 0.6444\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6899 - accuracy: 0.7143 - val_loss: 0.7310 - val_accuracy: 0.6444\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6877 - accuracy: 0.7143 - val_loss: 0.7289 - val_accuracy: 0.6444\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6855 - accuracy: 0.7143 - val_loss: 0.7268 - val_accuracy: 0.6444\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6833 - accuracy: 0.7143 - val_loss: 0.7247 - val_accuracy: 0.6444\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6812 - accuracy: 0.7143 - val_loss: 0.7226 - val_accuracy: 0.6444\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6790 - accuracy: 0.7143 - val_loss: 0.7206 - val_accuracy: 0.6444\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6769 - accuracy: 0.7143 - val_loss: 0.7185 - val_accuracy: 0.6444\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6748 - accuracy: 0.7143 - val_loss: 0.7165 - val_accuracy: 0.6444\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6726 - accuracy: 0.7143 - val_loss: 0.7145 - val_accuracy: 0.6444\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6705 - accuracy: 0.7143 - val_loss: 0.7124 - val_accuracy: 0.6444\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6684 - accuracy: 0.7143 - val_loss: 0.7104 - val_accuracy: 0.6444\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6663 - accuracy: 0.7143 - val_loss: 0.7084 - val_accuracy: 0.6444\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6642 - accuracy: 0.7143 - val_loss: 0.7064 - val_accuracy: 0.6444\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6621 - accuracy: 0.7143 - val_loss: 0.7044 - val_accuracy: 0.6444\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6601 - accuracy: 0.7143 - val_loss: 0.7024 - val_accuracy: 0.6444\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6580 - accuracy: 0.7143 - val_loss: 0.7004 - val_accuracy: 0.6444\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6560 - accuracy: 0.7143 - val_loss: 0.6985 - val_accuracy: 0.6444\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6539 - accuracy: 0.7143 - val_loss: 0.6965 - val_accuracy: 0.6444\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6519 - accuracy: 0.7143 - val_loss: 0.6945 - val_accuracy: 0.6444\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6499 - accuracy: 0.7143 - val_loss: 0.6926 - val_accuracy: 0.6444\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6479 - accuracy: 0.7143 - val_loss: 0.6906 - val_accuracy: 0.6444\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6459 - accuracy: 0.7143 - val_loss: 0.6887 - val_accuracy: 0.6444\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6439 - accuracy: 0.7143 - val_loss: 0.6867 - val_accuracy: 0.6444\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6419 - accuracy: 0.7143 - val_loss: 0.6848 - val_accuracy: 0.6444\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6399 - accuracy: 0.7143 - val_loss: 0.6829 - val_accuracy: 0.6444\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6380 - accuracy: 0.7143 - val_loss: 0.6811 - val_accuracy: 0.6444\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6360 - accuracy: 0.7143 - val_loss: 0.6792 - val_accuracy: 0.6444\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6341 - accuracy: 0.7143 - val_loss: 0.6774 - val_accuracy: 0.6444\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6321 - accuracy: 0.7143 - val_loss: 0.6755 - val_accuracy: 0.6444\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6302 - accuracy: 0.7143 - val_loss: 0.6736 - val_accuracy: 0.6444\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6283 - accuracy: 0.7143 - val_loss: 0.6718 - val_accuracy: 0.6444\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6264 - accuracy: 0.7143 - val_loss: 0.6699 - val_accuracy: 0.6444\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6245 - accuracy: 0.7143 - val_loss: 0.6680 - val_accuracy: 0.6444\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6226 - accuracy: 0.7143 - val_loss: 0.6662 - val_accuracy: 0.6444\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6208 - accuracy: 0.7143 - val_loss: 0.6644 - val_accuracy: 0.6444\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6189 - accuracy: 0.7143 - val_loss: 0.6626 - val_accuracy: 0.6444\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6171 - accuracy: 0.7143 - val_loss: 0.6608 - val_accuracy: 0.6444\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6153 - accuracy: 0.7143 - val_loss: 0.6590 - val_accuracy: 0.6444\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6134 - accuracy: 0.7143 - val_loss: 0.6573 - val_accuracy: 0.6444\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6116 - accuracy: 0.7143 - val_loss: 0.6556 - val_accuracy: 0.6444\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6098 - accuracy: 0.7143 - val_loss: 0.6538 - val_accuracy: 0.6444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6081 - accuracy: 0.7143 - val_loss: 0.6521 - val_accuracy: 0.6444\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6063 - accuracy: 0.7143 - val_loss: 0.6504 - val_accuracy: 0.6444\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6045 - accuracy: 0.7143 - val_loss: 0.6487 - val_accuracy: 0.6444\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6028 - accuracy: 0.7143 - val_loss: 0.6470 - val_accuracy: 0.6444\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6010 - accuracy: 0.7143 - val_loss: 0.6454 - val_accuracy: 0.6444\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5993 - accuracy: 0.7143 - val_loss: 0.6437 - val_accuracy: 0.6444\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5976 - accuracy: 0.7143 - val_loss: 0.6421 - val_accuracy: 0.6444\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5959 - accuracy: 0.7143 - val_loss: 0.6404 - val_accuracy: 0.6444\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5942 - accuracy: 0.7143 - val_loss: 0.6388 - val_accuracy: 0.6444\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5925 - accuracy: 0.7143 - val_loss: 0.6371 - val_accuracy: 0.6444\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5908 - accuracy: 0.7143 - val_loss: 0.6355 - val_accuracy: 0.6444\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5891 - accuracy: 0.7143 - val_loss: 0.6339 - val_accuracy: 0.6444\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5875 - accuracy: 0.7238 - val_loss: 0.6322 - val_accuracy: 0.6444\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5858 - accuracy: 0.7238 - val_loss: 0.6306 - val_accuracy: 0.6444\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5842 - accuracy: 0.7333 - val_loss: 0.6290 - val_accuracy: 0.6444\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5826 - accuracy: 0.7333 - val_loss: 0.6274 - val_accuracy: 0.6444\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5810 - accuracy: 0.7333 - val_loss: 0.6258 - val_accuracy: 0.6444\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5794 - accuracy: 0.7333 - val_loss: 0.6242 - val_accuracy: 0.6444\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5778 - accuracy: 0.7333 - val_loss: 0.6227 - val_accuracy: 0.6444\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5762 - accuracy: 0.7333 - val_loss: 0.6211 - val_accuracy: 0.6444\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5746 - accuracy: 0.7333 - val_loss: 0.6195 - val_accuracy: 0.6444\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5731 - accuracy: 0.7333 - val_loss: 0.6179 - val_accuracy: 0.6444\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5715 - accuracy: 0.7333 - val_loss: 0.6164 - val_accuracy: 0.6444\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.5700 - accuracy: 0.7333 - val_loss: 0.6148 - val_accuracy: 0.6444\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5684 - accuracy: 0.7333 - val_loss: 0.6133 - val_accuracy: 0.6444\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5669 - accuracy: 0.7333 - val_loss: 0.6117 - val_accuracy: 0.6444\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5654 - accuracy: 0.7333 - val_loss: 0.6102 - val_accuracy: 0.6444\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5639 - accuracy: 0.7333 - val_loss: 0.6087 - val_accuracy: 0.6444\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5624 - accuracy: 0.7333 - val_loss: 0.6072 - val_accuracy: 0.6444\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5609 - accuracy: 0.7333 - val_loss: 0.6057 - val_accuracy: 0.6444\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5595 - accuracy: 0.7429 - val_loss: 0.6042 - val_accuracy: 0.6444\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5580 - accuracy: 0.7429 - val_loss: 0.6027 - val_accuracy: 0.6444\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5566 - accuracy: 0.7429 - val_loss: 0.6012 - val_accuracy: 0.6444\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5552 - accuracy: 0.7429 - val_loss: 0.5998 - val_accuracy: 0.6444\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5537 - accuracy: 0.7429 - val_loss: 0.5984 - val_accuracy: 0.6444\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5523 - accuracy: 0.7429 - val_loss: 0.5969 - val_accuracy: 0.6444\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5509 - accuracy: 0.7429 - val_loss: 0.5955 - val_accuracy: 0.6444\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5495 - accuracy: 0.7429 - val_loss: 0.5941 - val_accuracy: 0.6444\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5481 - accuracy: 0.7429 - val_loss: 0.5927 - val_accuracy: 0.6444\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.5468 - accuracy: 0.7429 - val_loss: 0.5913 - val_accuracy: 0.6444\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5454 - accuracy: 0.7429 - val_loss: 0.5899 - val_accuracy: 0.6444\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5440 - accuracy: 0.7429 - val_loss: 0.5886 - val_accuracy: 0.6444\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5427 - accuracy: 0.7429 - val_loss: 0.5872 - val_accuracy: 0.6444\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5414 - accuracy: 0.7429 - val_loss: 0.5858 - val_accuracy: 0.6444\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5400 - accuracy: 0.7429 - val_loss: 0.5845 - val_accuracy: 0.6444\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5387 - accuracy: 0.7429 - val_loss: 0.5831 - val_accuracy: 0.6444\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5374 - accuracy: 0.7429 - val_loss: 0.5818 - val_accuracy: 0.6444\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5361 - accuracy: 0.7429 - val_loss: 0.5805 - val_accuracy: 0.6444\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5348 - accuracy: 0.7429 - val_loss: 0.5792 - val_accuracy: 0.6444\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5336 - accuracy: 0.7429 - val_loss: 0.5779 - val_accuracy: 0.6444\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5323 - accuracy: 0.7429 - val_loss: 0.5766 - val_accuracy: 0.6444\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5310 - accuracy: 0.7429 - val_loss: 0.5754 - val_accuracy: 0.6444\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5298 - accuracy: 0.7524 - val_loss: 0.5741 - val_accuracy: 0.6444\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5286 - accuracy: 0.7524 - val_loss: 0.5729 - val_accuracy: 0.6444\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5273 - accuracy: 0.7524 - val_loss: 0.5716 - val_accuracy: 0.6444\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5261 - accuracy: 0.7524 - val_loss: 0.5704 - val_accuracy: 0.6444\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5249 - accuracy: 0.7524 - val_loss: 0.5692 - val_accuracy: 0.6444\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5237 - accuracy: 0.7524 - val_loss: 0.5680 - val_accuracy: 0.6444\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5225 - accuracy: 0.7524 - val_loss: 0.5668 - val_accuracy: 0.6444\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5213 - accuracy: 0.7524 - val_loss: 0.5656 - val_accuracy: 0.6444\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5202 - accuracy: 0.7524 - val_loss: 0.5644 - val_accuracy: 0.6444\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5190 - accuracy: 0.7619 - val_loss: 0.5632 - val_accuracy: 0.6667\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5178 - accuracy: 0.7619 - val_loss: 0.5620 - val_accuracy: 0.6667\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5167 - accuracy: 0.7619 - val_loss: 0.5609 - val_accuracy: 0.6667\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5156 - accuracy: 0.7619 - val_loss: 0.5598 - val_accuracy: 0.6667\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5144 - accuracy: 0.7619 - val_loss: 0.5587 - val_accuracy: 0.6667\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5133 - accuracy: 0.7619 - val_loss: 0.5576 - val_accuracy: 0.6667\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5122 - accuracy: 0.7619 - val_loss: 0.5565 - val_accuracy: 0.6667\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5111 - accuracy: 0.7619 - val_loss: 0.5554 - val_accuracy: 0.6667\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5100 - accuracy: 0.7619 - val_loss: 0.5543 - val_accuracy: 0.6667\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5089 - accuracy: 0.7619 - val_loss: 0.5533 - val_accuracy: 0.6667\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5078 - accuracy: 0.7619 - val_loss: 0.5522 - val_accuracy: 0.6667\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5068 - accuracy: 0.7619 - val_loss: 0.5512 - val_accuracy: 0.6667\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5057 - accuracy: 0.7619 - val_loss: 0.5501 - val_accuracy: 0.6667\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5047 - accuracy: 0.7619 - val_loss: 0.5491 - val_accuracy: 0.6667\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5036 - accuracy: 0.7619 - val_loss: 0.5481 - val_accuracy: 0.6667\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5026 - accuracy: 0.7619 - val_loss: 0.5470 - val_accuracy: 0.6667\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5015 - accuracy: 0.7619 - val_loss: 0.5460 - val_accuracy: 0.6667\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5005 - accuracy: 0.7619 - val_loss: 0.5449 - val_accuracy: 0.6667\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4995 - accuracy: 0.7619 - val_loss: 0.5439 - val_accuracy: 0.6667\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4985 - accuracy: 0.7619 - val_loss: 0.5429 - val_accuracy: 0.6667\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4975 - accuracy: 0.7619 - val_loss: 0.5418 - val_accuracy: 0.6667\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4965 - accuracy: 0.7619 - val_loss: 0.5408 - val_accuracy: 0.6667\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4955 - accuracy: 0.7619 - val_loss: 0.5398 - val_accuracy: 0.6667\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4945 - accuracy: 0.7619 - val_loss: 0.5388 - val_accuracy: 0.6667\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4936 - accuracy: 0.7619 - val_loss: 0.5378 - val_accuracy: 0.6667\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4926 - accuracy: 0.7619 - val_loss: 0.5369 - val_accuracy: 0.6667\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4916 - accuracy: 0.7619 - val_loss: 0.5359 - val_accuracy: 0.6667\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4907 - accuracy: 0.7619 - val_loss: 0.5349 - val_accuracy: 0.6667\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4898 - accuracy: 0.7619 - val_loss: 0.5339 - val_accuracy: 0.6667\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4888 - accuracy: 0.7619 - val_loss: 0.5329 - val_accuracy: 0.6667\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4879 - accuracy: 0.7619 - val_loss: 0.5320 - val_accuracy: 0.6667\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4870 - accuracy: 0.7619 - val_loss: 0.5310 - val_accuracy: 0.6667\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4860 - accuracy: 0.7619 - val_loss: 0.5300 - val_accuracy: 0.6667\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4851 - accuracy: 0.7619 - val_loss: 0.5291 - val_accuracy: 0.6667\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4842 - accuracy: 0.7619 - val_loss: 0.5281 - val_accuracy: 0.6667\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4833 - accuracy: 0.7619 - val_loss: 0.5272 - val_accuracy: 0.6667\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4824 - accuracy: 0.7619 - val_loss: 0.5263 - val_accuracy: 0.6667\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4815 - accuracy: 0.7619 - val_loss: 0.5253 - val_accuracy: 0.6667\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4807 - accuracy: 0.7810 - val_loss: 0.5244 - val_accuracy: 0.6667\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4798 - accuracy: 0.7810 - val_loss: 0.5235 - val_accuracy: 0.6667\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4789 - accuracy: 0.7810 - val_loss: 0.5226 - val_accuracy: 0.6667\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4781 - accuracy: 0.7810 - val_loss: 0.5217 - val_accuracy: 0.6667\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4772 - accuracy: 0.7905 - val_loss: 0.5208 - val_accuracy: 0.6667\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4763 - accuracy: 0.7905 - val_loss: 0.5199 - val_accuracy: 0.6667\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4755 - accuracy: 0.7905 - val_loss: 0.5190 - val_accuracy: 0.6667\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4746 - accuracy: 0.7905 - val_loss: 0.5182 - val_accuracy: 0.6667\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4738 - accuracy: 0.7905 - val_loss: 0.5173 - val_accuracy: 0.6667\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4730 - accuracy: 0.7905 - val_loss: 0.5165 - val_accuracy: 0.6667\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4722 - accuracy: 0.7905 - val_loss: 0.5156 - val_accuracy: 0.6667\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4713 - accuracy: 0.7905 - val_loss: 0.5148 - val_accuracy: 0.6667\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4705 - accuracy: 0.7905 - val_loss: 0.5140 - val_accuracy: 0.6667\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4697 - accuracy: 0.7905 - val_loss: 0.5132 - val_accuracy: 0.6667\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4689 - accuracy: 0.7905 - val_loss: 0.5124 - val_accuracy: 0.6667\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4681 - accuracy: 0.7905 - val_loss: 0.5116 - val_accuracy: 0.6667\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4673 - accuracy: 0.7905 - val_loss: 0.5108 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4665 - accuracy: 0.7905 - val_loss: 0.5100 - val_accuracy: 0.6889\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4657 - accuracy: 0.7905 - val_loss: 0.5093 - val_accuracy: 0.6889\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4649 - accuracy: 0.7905 - val_loss: 0.5085 - val_accuracy: 0.6889\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4642 - accuracy: 0.7905 - val_loss: 0.5077 - val_accuracy: 0.6889\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4634 - accuracy: 0.7905 - val_loss: 0.5070 - val_accuracy: 0.6889\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4626 - accuracy: 0.7905 - val_loss: 0.5062 - val_accuracy: 0.6889\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4619 - accuracy: 0.7905 - val_loss: 0.5055 - val_accuracy: 0.6889\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4611 - accuracy: 0.7905 - val_loss: 0.5047 - val_accuracy: 0.7111\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4604 - accuracy: 0.7905 - val_loss: 0.5040 - val_accuracy: 0.7111\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4596 - accuracy: 0.7905 - val_loss: 0.5032 - val_accuracy: 0.7111\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4589 - accuracy: 0.7905 - val_loss: 0.5025 - val_accuracy: 0.7111\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4581 - accuracy: 0.7905 - val_loss: 0.5017 - val_accuracy: 0.7111\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4574 - accuracy: 0.7905 - val_loss: 0.5010 - val_accuracy: 0.7111\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4567 - accuracy: 0.7905 - val_loss: 0.5003 - val_accuracy: 0.7111\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4560 - accuracy: 0.7905 - val_loss: 0.4995 - val_accuracy: 0.7111\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4552 - accuracy: 0.7905 - val_loss: 0.4988 - val_accuracy: 0.7111\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4545 - accuracy: 0.7905 - val_loss: 0.4981 - val_accuracy: 0.7111\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4538 - accuracy: 0.7905 - val_loss: 0.4973 - val_accuracy: 0.7111\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4531 - accuracy: 0.7905 - val_loss: 0.4966 - val_accuracy: 0.7111\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.4524 - accuracy: 0.7905 - val_loss: 0.4959 - val_accuracy: 0.7111\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4517 - accuracy: 0.7905 - val_loss: 0.4951 - val_accuracy: 0.7111\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4510 - accuracy: 0.7905 - val_loss: 0.4944 - val_accuracy: 0.7111\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4503 - accuracy: 0.7905 - val_loss: 0.4937 - val_accuracy: 0.7111\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4496 - accuracy: 0.7905 - val_loss: 0.4930 - val_accuracy: 0.7111\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4490 - accuracy: 0.7905 - val_loss: 0.4923 - val_accuracy: 0.7111\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4483 - accuracy: 0.7905 - val_loss: 0.4916 - val_accuracy: 0.7111\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4476 - accuracy: 0.7905 - val_loss: 0.4909 - val_accuracy: 0.7111\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4469 - accuracy: 0.7905 - val_loss: 0.4902 - val_accuracy: 0.7111\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4463 - accuracy: 0.7905 - val_loss: 0.4896 - val_accuracy: 0.7111\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4456 - accuracy: 0.7905 - val_loss: 0.4889 - val_accuracy: 0.7111\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4450 - accuracy: 0.7905 - val_loss: 0.4882 - val_accuracy: 0.7111\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4443 - accuracy: 0.7905 - val_loss: 0.4876 - val_accuracy: 0.7111\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4436 - accuracy: 0.8000 - val_loss: 0.4869 - val_accuracy: 0.7111\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4430 - accuracy: 0.8000 - val_loss: 0.4863 - val_accuracy: 0.7111\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4424 - accuracy: 0.8000 - val_loss: 0.4856 - val_accuracy: 0.7111\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4417 - accuracy: 0.8000 - val_loss: 0.4850 - val_accuracy: 0.7111\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4411 - accuracy: 0.8000 - val_loss: 0.4844 - val_accuracy: 0.7111\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4405 - accuracy: 0.8000 - val_loss: 0.4838 - val_accuracy: 0.7111\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4398 - accuracy: 0.8000 - val_loss: 0.4831 - val_accuracy: 0.7111\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4392 - accuracy: 0.8000 - val_loss: 0.4825 - val_accuracy: 0.7111\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4386 - accuracy: 0.8095 - val_loss: 0.4818 - val_accuracy: 0.7111\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4380 - accuracy: 0.8095 - val_loss: 0.4812 - val_accuracy: 0.7111\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4373 - accuracy: 0.8095 - val_loss: 0.4805 - val_accuracy: 0.7111\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4367 - accuracy: 0.8095 - val_loss: 0.4799 - val_accuracy: 0.7111\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4361 - accuracy: 0.8095 - val_loss: 0.4792 - val_accuracy: 0.7333\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4355 - accuracy: 0.8095 - val_loss: 0.4785 - val_accuracy: 0.7333\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4349 - accuracy: 0.8095 - val_loss: 0.4779 - val_accuracy: 0.7333\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4343 - accuracy: 0.8095 - val_loss: 0.4772 - val_accuracy: 0.7333\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.4337 - accuracy: 0.8095 - val_loss: 0.4766 - val_accuracy: 0.7333\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4331 - accuracy: 0.8095 - val_loss: 0.4760 - val_accuracy: 0.7333\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4325 - accuracy: 0.8095 - val_loss: 0.4754 - val_accuracy: 0.7556\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4319 - accuracy: 0.8095 - val_loss: 0.4748 - val_accuracy: 0.7556\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4314 - accuracy: 0.8095 - val_loss: 0.4742 - val_accuracy: 0.7556\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4308 - accuracy: 0.8095 - val_loss: 0.4736 - val_accuracy: 0.7556\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4302 - accuracy: 0.8095 - val_loss: 0.4730 - val_accuracy: 0.7556\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4296 - accuracy: 0.8095 - val_loss: 0.4724 - val_accuracy: 0.7556\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4290 - accuracy: 0.8095 - val_loss: 0.4718 - val_accuracy: 0.7556\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4285 - accuracy: 0.8095 - val_loss: 0.4713 - val_accuracy: 0.7556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4279 - accuracy: 0.8095 - val_loss: 0.4707 - val_accuracy: 0.7556\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4273 - accuracy: 0.8190 - val_loss: 0.4701 - val_accuracy: 0.7556\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4268 - accuracy: 0.8190 - val_loss: 0.4695 - val_accuracy: 0.7556\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4262 - accuracy: 0.8190 - val_loss: 0.4689 - val_accuracy: 0.7556\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4257 - accuracy: 0.8190 - val_loss: 0.4682 - val_accuracy: 0.7556\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4251 - accuracy: 0.8190 - val_loss: 0.4676 - val_accuracy: 0.7556\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4246 - accuracy: 0.8190 - val_loss: 0.4670 - val_accuracy: 0.7556\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4240 - accuracy: 0.8190 - val_loss: 0.4664 - val_accuracy: 0.7556\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4235 - accuracy: 0.8190 - val_loss: 0.4658 - val_accuracy: 0.7556\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4229 - accuracy: 0.8190 - val_loss: 0.4652 - val_accuracy: 0.7556\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4224 - accuracy: 0.8190 - val_loss: 0.4646 - val_accuracy: 0.7556\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4218 - accuracy: 0.8190 - val_loss: 0.4640 - val_accuracy: 0.7556\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4213 - accuracy: 0.8286 - val_loss: 0.4634 - val_accuracy: 0.7556\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4207 - accuracy: 0.8286 - val_loss: 0.4628 - val_accuracy: 0.7556\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4202 - accuracy: 0.8286 - val_loss: 0.4622 - val_accuracy: 0.7556\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4197 - accuracy: 0.8286 - val_loss: 0.4617 - val_accuracy: 0.7556\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4191 - accuracy: 0.8286 - val_loss: 0.4611 - val_accuracy: 0.7556\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4186 - accuracy: 0.8286 - val_loss: 0.4605 - val_accuracy: 0.7556\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4181 - accuracy: 0.8381 - val_loss: 0.4600 - val_accuracy: 0.7556\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4176 - accuracy: 0.8381 - val_loss: 0.4594 - val_accuracy: 0.7556\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4170 - accuracy: 0.8381 - val_loss: 0.4588 - val_accuracy: 0.7556\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4165 - accuracy: 0.8381 - val_loss: 0.4582 - val_accuracy: 0.7556\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4160 - accuracy: 0.8381 - val_loss: 0.4577 - val_accuracy: 0.7556\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4155 - accuracy: 0.8381 - val_loss: 0.4571 - val_accuracy: 0.7556\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4150 - accuracy: 0.8381 - val_loss: 0.4565 - val_accuracy: 0.7556\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4144 - accuracy: 0.8381 - val_loss: 0.4559 - val_accuracy: 0.7556\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4139 - accuracy: 0.8381 - val_loss: 0.4554 - val_accuracy: 0.7556\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4134 - accuracy: 0.8381 - val_loss: 0.4548 - val_accuracy: 0.7556\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4129 - accuracy: 0.8381 - val_loss: 0.4543 - val_accuracy: 0.7556\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4124 - accuracy: 0.8381 - val_loss: 0.4537 - val_accuracy: 0.7556\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4119 - accuracy: 0.8381 - val_loss: 0.4532 - val_accuracy: 0.7556\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4114 - accuracy: 0.8381 - val_loss: 0.4526 - val_accuracy: 0.7556\n",
      "2/2 [==============================] - 0s 6ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 10:24:11.736517: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-10 10:24:11.760647: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 10:24:11.760729: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2024-09-10 10:24:11.765459: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 10:24:11.765527: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2024-09-10 10:24:11.769317: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 10:24:11.769379: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=150, validation_data=(X_test, y_test))\n",
    "pred = model.predict(X_test)\n",
    "pred = pd.DataFrame(pred)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "964ea25a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "118dbb8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ef7eeeb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcbbd8f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "24b31512",
   "metadata": {},
   "source": [
    "# 함수형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "defa5f09",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4079061d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(X_train.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "42685ce9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "8265fcf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=(X_train.shape[1],))\n",
    "x = Dense(16, activation='relu')(inputs)\n",
    "x = Dense(8, activation='relu')(x)\n",
    "x = Dense(3, activation='softmax')(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "4c42e795",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_1 (InputLayer)        [(None, 4)]               0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 16)                80        \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 3)                 27        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 243\n",
      "Trainable params: 243\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(inputs, x)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "435f7373",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1911 - accuracy: 0.0286"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 10:24:33.064269: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-10 10:24:33.106575: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 10:24:33.106641: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 501ms/step - loss: 1.1911 - accuracy: 0.0286 - val_loss: 1.1864 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1870 - accuracy: 0.0286 - val_loss: 1.1827 - val_accuracy: 0.0000e+00\n",
      "Epoch 3/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.1829 - accuracy: 0.0190 - val_loss: 1.1789 - val_accuracy: 0.0000e+00\n",
      "Epoch 4/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.1789 - accuracy: 0.0190 - val_loss: 1.1750 - val_accuracy: 0.0000e+00\n",
      "Epoch 5/400\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.1748 - accuracy: 0.0190"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 10:24:33.288357: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-10 10:24:33.313276: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 10:24:33.313339: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 53ms/step - loss: 1.1748 - accuracy: 0.0190 - val_loss: 1.1711 - val_accuracy: 0.0000e+00\n",
      "Epoch 6/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1707 - accuracy: 0.0095 - val_loss: 1.1672 - val_accuracy: 0.0222\n",
      "Epoch 7/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1666 - accuracy: 0.0000e+00 - val_loss: 1.1634 - val_accuracy: 0.0222\n",
      "Epoch 8/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.1627 - accuracy: 0.0000e+00 - val_loss: 1.1597 - val_accuracy: 0.0222\n",
      "Epoch 9/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1587 - accuracy: 0.0000e+00 - val_loss: 1.1561 - val_accuracy: 0.0222\n",
      "Epoch 10/400\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1548 - accuracy: 0.0000e+00 - val_loss: 1.1526 - val_accuracy: 0.0000e+00\n",
      "Epoch 11/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.1510 - accuracy: 0.0000e+00 - val_loss: 1.1491 - val_accuracy: 0.0000e+00\n",
      "Epoch 12/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.1473 - accuracy: 0.0000e+00 - val_loss: 1.1458 - val_accuracy: 0.0000e+00\n",
      "Epoch 13/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.1437 - accuracy: 0.0000e+00 - val_loss: 1.1427 - val_accuracy: 0.0000e+00\n",
      "Epoch 14/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.1404 - accuracy: 0.0000e+00 - val_loss: 1.1399 - val_accuracy: 0.0000e+00\n",
      "Epoch 15/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.1375 - accuracy: 0.0000e+00 - val_loss: 1.1375 - val_accuracy: 0.0000e+00\n",
      "Epoch 16/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1350 - accuracy: 0.0000e+00 - val_loss: 1.1353 - val_accuracy: 0.0000e+00\n",
      "Epoch 17/400\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 1.1326 - accuracy: 0.0000e+00 - val_loss: 1.1333 - val_accuracy: 0.0000e+00\n",
      "Epoch 18/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.1304 - accuracy: 0.0000e+00 - val_loss: 1.1314 - val_accuracy: 0.0000e+00\n",
      "Epoch 19/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1283 - accuracy: 0.0000e+00 - val_loss: 1.1295 - val_accuracy: 0.0000e+00\n",
      "Epoch 20/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.1263 - accuracy: 0.0000e+00 - val_loss: 1.1277 - val_accuracy: 0.0000e+00\n",
      "Epoch 21/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.1244 - accuracy: 0.0095 - val_loss: 1.1259 - val_accuracy: 0.0000e+00\n",
      "Epoch 22/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.1226 - accuracy: 0.0095 - val_loss: 1.1242 - val_accuracy: 0.0000e+00\n",
      "Epoch 23/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.1209 - accuracy: 0.0095 - val_loss: 1.1225 - val_accuracy: 0.0000e+00\n",
      "Epoch 24/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1191 - accuracy: 0.0095 - val_loss: 1.1209 - val_accuracy: 0.0222\n",
      "Epoch 25/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.1174 - accuracy: 0.0095 - val_loss: 1.1192 - val_accuracy: 0.0222\n",
      "Epoch 26/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1157 - accuracy: 0.0286 - val_loss: 1.1175 - val_accuracy: 0.0222\n",
      "Epoch 27/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1140 - accuracy: 0.0286 - val_loss: 1.1158 - val_accuracy: 0.0444\n",
      "Epoch 28/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.1123 - accuracy: 0.0381 - val_loss: 1.1141 - val_accuracy: 0.0444\n",
      "Epoch 29/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1107 - accuracy: 0.0381 - val_loss: 1.1125 - val_accuracy: 0.0667\n",
      "Epoch 30/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1090 - accuracy: 0.0476 - val_loss: 1.1109 - val_accuracy: 0.0889\n",
      "Epoch 31/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1074 - accuracy: 0.0762 - val_loss: 1.1093 - val_accuracy: 0.1333\n",
      "Epoch 32/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.1057 - accuracy: 0.1333 - val_loss: 1.1077 - val_accuracy: 0.1333\n",
      "Epoch 33/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.1041 - accuracy: 0.1714 - val_loss: 1.1061 - val_accuracy: 0.1333\n",
      "Epoch 34/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.1025 - accuracy: 0.1905 - val_loss: 1.1046 - val_accuracy: 0.1556\n",
      "Epoch 35/400\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.1009 - accuracy: 0.2190 - val_loss: 1.1030 - val_accuracy: 0.2000\n",
      "Epoch 36/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0993 - accuracy: 0.2762 - val_loss: 1.1015 - val_accuracy: 0.2222\n",
      "Epoch 37/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0978 - accuracy: 0.2952 - val_loss: 1.1000 - val_accuracy: 0.2444\n",
      "Epoch 38/400\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0962 - accuracy: 0.2952 - val_loss: 1.0984 - val_accuracy: 0.2889\n",
      "Epoch 39/400\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0946 - accuracy: 0.3143 - val_loss: 1.0969 - val_accuracy: 0.2889\n",
      "Epoch 40/400\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0931 - accuracy: 0.3524 - val_loss: 1.0954 - val_accuracy: 0.3111\n",
      "Epoch 41/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0915 - accuracy: 0.3810 - val_loss: 1.0939 - val_accuracy: 0.3111\n",
      "Epoch 42/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0900 - accuracy: 0.4095 - val_loss: 1.0925 - val_accuracy: 0.3111\n",
      "Epoch 43/400\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 1.0884 - accuracy: 0.4095 - val_loss: 1.0910 - val_accuracy: 0.3333\n",
      "Epoch 44/400\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0869 - accuracy: 0.4286 - val_loss: 1.0895 - val_accuracy: 0.3333\n",
      "Epoch 45/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0854 - accuracy: 0.4286 - val_loss: 1.0881 - val_accuracy: 0.3333\n",
      "Epoch 46/400\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0838 - accuracy: 0.4571 - val_loss: 1.0866 - val_accuracy: 0.3333\n",
      "Epoch 47/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 1.0823 - accuracy: 0.4667 - val_loss: 1.0852 - val_accuracy: 0.3556\n",
      "Epoch 48/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0808 - accuracy: 0.4667 - val_loss: 1.0838 - val_accuracy: 0.3556\n",
      "Epoch 49/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0792 - accuracy: 0.4667 - val_loss: 1.0823 - val_accuracy: 0.3556\n",
      "Epoch 50/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0777 - accuracy: 0.4762 - val_loss: 1.0809 - val_accuracy: 0.3556\n",
      "Epoch 51/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0762 - accuracy: 0.4762 - val_loss: 1.0795 - val_accuracy: 0.3556\n",
      "Epoch 52/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0747 - accuracy: 0.4762 - val_loss: 1.0780 - val_accuracy: 0.3556\n",
      "Epoch 53/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0731 - accuracy: 0.4762 - val_loss: 1.0766 - val_accuracy: 0.3556\n",
      "Epoch 54/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0716 - accuracy: 0.4857 - val_loss: 1.0751 - val_accuracy: 0.3556\n",
      "Epoch 55/400\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 1.0701 - accuracy: 0.4952 - val_loss: 1.0737 - val_accuracy: 0.3556\n",
      "Epoch 56/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0685 - accuracy: 0.4952 - val_loss: 1.0723 - val_accuracy: 0.3556\n",
      "Epoch 57/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 1.0670 - accuracy: 0.4952 - val_loss: 1.0708 - val_accuracy: 0.3778\n",
      "Epoch 58/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0654 - accuracy: 0.5048 - val_loss: 1.0694 - val_accuracy: 0.3778\n",
      "Epoch 59/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0638 - accuracy: 0.5048 - val_loss: 1.0679 - val_accuracy: 0.3778\n",
      "Epoch 60/400\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 1.0623 - accuracy: 0.5143 - val_loss: 1.0664 - val_accuracy: 0.4222\n",
      "Epoch 61/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0607 - accuracy: 0.5143 - val_loss: 1.0650 - val_accuracy: 0.4444\n",
      "Epoch 62/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 1.0591 - accuracy: 0.5238 - val_loss: 1.0635 - val_accuracy: 0.4444\n",
      "Epoch 63/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0575 - accuracy: 0.5333 - val_loss: 1.0620 - val_accuracy: 0.4444\n",
      "Epoch 64/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0559 - accuracy: 0.5333 - val_loss: 1.0604 - val_accuracy: 0.4444\n",
      "Epoch 65/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0543 - accuracy: 0.5333 - val_loss: 1.0589 - val_accuracy: 0.4444\n",
      "Epoch 66/400\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0526 - accuracy: 0.5429 - val_loss: 1.0573 - val_accuracy: 0.4444\n",
      "Epoch 67/400\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0509 - accuracy: 0.5714 - val_loss: 1.0557 - val_accuracy: 0.4444\n",
      "Epoch 68/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0493 - accuracy: 0.5810 - val_loss: 1.0542 - val_accuracy: 0.4444\n",
      "Epoch 69/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0476 - accuracy: 0.5905 - val_loss: 1.0525 - val_accuracy: 0.4667\n",
      "Epoch 70/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0459 - accuracy: 0.5905 - val_loss: 1.0509 - val_accuracy: 0.4889\n",
      "Epoch 71/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0441 - accuracy: 0.6000 - val_loss: 1.0493 - val_accuracy: 0.5111\n",
      "Epoch 72/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0424 - accuracy: 0.6000 - val_loss: 1.0476 - val_accuracy: 0.5556\n",
      "Epoch 73/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0406 - accuracy: 0.6095 - val_loss: 1.0459 - val_accuracy: 0.5556\n",
      "Epoch 74/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0389 - accuracy: 0.6381 - val_loss: 1.0442 - val_accuracy: 0.5556\n",
      "Epoch 75/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0371 - accuracy: 0.6571 - val_loss: 1.0425 - val_accuracy: 0.5556\n",
      "Epoch 76/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0352 - accuracy: 0.6667 - val_loss: 1.0407 - val_accuracy: 0.5778\n",
      "Epoch 77/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0334 - accuracy: 0.6667 - val_loss: 1.0390 - val_accuracy: 0.5778\n",
      "Epoch 78/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0316 - accuracy: 0.6667 - val_loss: 1.0372 - val_accuracy: 0.6000\n",
      "Epoch 79/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0297 - accuracy: 0.6762 - val_loss: 1.0354 - val_accuracy: 0.6000\n",
      "Epoch 80/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0278 - accuracy: 0.6857 - val_loss: 1.0335 - val_accuracy: 0.6000\n",
      "Epoch 81/400\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 1.0259 - accuracy: 0.6857 - val_loss: 1.0317 - val_accuracy: 0.6000\n",
      "Epoch 82/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0240 - accuracy: 0.6857 - val_loss: 1.0298 - val_accuracy: 0.6000\n",
      "Epoch 83/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0221 - accuracy: 0.6857 - val_loss: 1.0280 - val_accuracy: 0.6000\n",
      "Epoch 84/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0201 - accuracy: 0.6857 - val_loss: 1.0261 - val_accuracy: 0.6000\n",
      "Epoch 85/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0182 - accuracy: 0.6857 - val_loss: 1.0241 - val_accuracy: 0.6000\n",
      "Epoch 86/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0162 - accuracy: 0.6857 - val_loss: 1.0222 - val_accuracy: 0.6000\n",
      "Epoch 87/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0142 - accuracy: 0.6857 - val_loss: 1.0203 - val_accuracy: 0.6000\n",
      "Epoch 88/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0121 - accuracy: 0.6857 - val_loss: 1.0183 - val_accuracy: 0.6000\n",
      "Epoch 89/400\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 1.0101 - accuracy: 0.6857 - val_loss: 1.0163 - val_accuracy: 0.6000\n",
      "Epoch 90/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0080 - accuracy: 0.6857 - val_loss: 1.0143 - val_accuracy: 0.6000\n",
      "Epoch 91/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0059 - accuracy: 0.6857 - val_loss: 1.0123 - val_accuracy: 0.6000\n",
      "Epoch 92/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0038 - accuracy: 0.6857 - val_loss: 1.0103 - val_accuracy: 0.6000\n",
      "Epoch 93/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0017 - accuracy: 0.6857 - val_loss: 1.0082 - val_accuracy: 0.6000\n",
      "Epoch 94/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9996 - accuracy: 0.6857 - val_loss: 1.0062 - val_accuracy: 0.6000\n",
      "Epoch 95/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9974 - accuracy: 0.6857 - val_loss: 1.0041 - val_accuracy: 0.6000\n",
      "Epoch 96/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9953 - accuracy: 0.6857 - val_loss: 1.0020 - val_accuracy: 0.6000\n",
      "Epoch 97/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9931 - accuracy: 0.6857 - val_loss: 0.9999 - val_accuracy: 0.6000\n",
      "Epoch 98/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9909 - accuracy: 0.6857 - val_loss: 0.9978 - val_accuracy: 0.6000\n",
      "Epoch 99/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9887 - accuracy: 0.6857 - val_loss: 0.9957 - val_accuracy: 0.6000\n",
      "Epoch 100/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9865 - accuracy: 0.6857 - val_loss: 0.9935 - val_accuracy: 0.6000\n",
      "Epoch 101/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9843 - accuracy: 0.6857 - val_loss: 0.9914 - val_accuracy: 0.6000\n",
      "Epoch 102/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9821 - accuracy: 0.6857 - val_loss: 0.9892 - val_accuracy: 0.6000\n",
      "Epoch 103/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9799 - accuracy: 0.6857 - val_loss: 0.9871 - val_accuracy: 0.6000\n",
      "Epoch 104/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9776 - accuracy: 0.6857 - val_loss: 0.9849 - val_accuracy: 0.6000\n",
      "Epoch 105/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9753 - accuracy: 0.6857 - val_loss: 0.9827 - val_accuracy: 0.6000\n",
      "Epoch 106/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9731 - accuracy: 0.6857 - val_loss: 0.9805 - val_accuracy: 0.6000\n",
      "Epoch 107/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9708 - accuracy: 0.6857 - val_loss: 0.9783 - val_accuracy: 0.6222\n",
      "Epoch 108/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9684 - accuracy: 0.6857 - val_loss: 0.9761 - val_accuracy: 0.6222\n",
      "Epoch 109/400\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.9661 - accuracy: 0.6857 - val_loss: 0.9738 - val_accuracy: 0.6222\n",
      "Epoch 110/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9638 - accuracy: 0.6857 - val_loss: 0.9716 - val_accuracy: 0.6222\n",
      "Epoch 111/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9614 - accuracy: 0.6857 - val_loss: 0.9693 - val_accuracy: 0.6222\n",
      "Epoch 112/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9590 - accuracy: 0.6857 - val_loss: 0.9670 - val_accuracy: 0.6222\n",
      "Epoch 113/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9566 - accuracy: 0.6857 - val_loss: 0.9648 - val_accuracy: 0.6222\n",
      "Epoch 114/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9542 - accuracy: 0.6857 - val_loss: 0.9625 - val_accuracy: 0.6222\n",
      "Epoch 115/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9518 - accuracy: 0.6857 - val_loss: 0.9601 - val_accuracy: 0.6222\n",
      "Epoch 116/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9493 - accuracy: 0.6857 - val_loss: 0.9578 - val_accuracy: 0.6222\n",
      "Epoch 117/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9469 - accuracy: 0.6857 - val_loss: 0.9555 - val_accuracy: 0.6222\n",
      "Epoch 118/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9444 - accuracy: 0.6857 - val_loss: 0.9531 - val_accuracy: 0.6222\n",
      "Epoch 119/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9419 - accuracy: 0.6857 - val_loss: 0.9507 - val_accuracy: 0.6222\n",
      "Epoch 120/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9394 - accuracy: 0.6857 - val_loss: 0.9484 - val_accuracy: 0.6222\n",
      "Epoch 121/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9368 - accuracy: 0.6857 - val_loss: 0.9459 - val_accuracy: 0.6222\n",
      "Epoch 122/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.9343 - accuracy: 0.6857 - val_loss: 0.9435 - val_accuracy: 0.6222\n",
      "Epoch 123/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9317 - accuracy: 0.6857 - val_loss: 0.9411 - val_accuracy: 0.6222\n",
      "Epoch 124/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9291 - accuracy: 0.6857 - val_loss: 0.9386 - val_accuracy: 0.6222\n",
      "Epoch 125/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9265 - accuracy: 0.6857 - val_loss: 0.9362 - val_accuracy: 0.6222\n",
      "Epoch 126/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9239 - accuracy: 0.6857 - val_loss: 0.9337 - val_accuracy: 0.6222\n",
      "Epoch 127/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9212 - accuracy: 0.6857 - val_loss: 0.9312 - val_accuracy: 0.6222\n",
      "Epoch 128/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.9186 - accuracy: 0.6857 - val_loss: 0.9287 - val_accuracy: 0.6222\n",
      "Epoch 129/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9159 - accuracy: 0.6857 - val_loss: 0.9262 - val_accuracy: 0.6222\n",
      "Epoch 130/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9132 - accuracy: 0.6857 - val_loss: 0.9237 - val_accuracy: 0.6222\n",
      "Epoch 131/400\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9105 - accuracy: 0.6857 - val_loss: 0.9211 - val_accuracy: 0.6222\n",
      "Epoch 132/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9078 - accuracy: 0.6857 - val_loss: 0.9186 - val_accuracy: 0.6222\n",
      "Epoch 133/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9050 - accuracy: 0.6857 - val_loss: 0.9160 - val_accuracy: 0.6222\n",
      "Epoch 134/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9023 - accuracy: 0.6857 - val_loss: 0.9134 - val_accuracy: 0.6222\n",
      "Epoch 135/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8995 - accuracy: 0.6857 - val_loss: 0.9108 - val_accuracy: 0.6222\n",
      "Epoch 136/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8967 - accuracy: 0.6857 - val_loss: 0.9082 - val_accuracy: 0.6222\n",
      "Epoch 137/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8939 - accuracy: 0.6857 - val_loss: 0.9056 - val_accuracy: 0.6222\n",
      "Epoch 138/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8911 - accuracy: 0.6857 - val_loss: 0.9030 - val_accuracy: 0.6222\n",
      "Epoch 139/400\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8883 - accuracy: 0.6857 - val_loss: 0.9004 - val_accuracy: 0.6222\n",
      "Epoch 140/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8855 - accuracy: 0.6857 - val_loss: 0.8977 - val_accuracy: 0.6222\n",
      "Epoch 141/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8826 - accuracy: 0.6857 - val_loss: 0.8951 - val_accuracy: 0.6222\n",
      "Epoch 142/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8798 - accuracy: 0.6857 - val_loss: 0.8924 - val_accuracy: 0.6222\n",
      "Epoch 143/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8769 - accuracy: 0.6857 - val_loss: 0.8897 - val_accuracy: 0.6222\n",
      "Epoch 144/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8741 - accuracy: 0.6857 - val_loss: 0.8871 - val_accuracy: 0.6222\n",
      "Epoch 145/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8712 - accuracy: 0.6857 - val_loss: 0.8844 - val_accuracy: 0.6222\n",
      "Epoch 146/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8683 - accuracy: 0.6857 - val_loss: 0.8817 - val_accuracy: 0.6222\n",
      "Epoch 147/400\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8654 - accuracy: 0.6857 - val_loss: 0.8789 - val_accuracy: 0.6222\n",
      "Epoch 148/400\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8625 - accuracy: 0.6857 - val_loss: 0.8762 - val_accuracy: 0.6222\n",
      "Epoch 149/400\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8596 - accuracy: 0.6857 - val_loss: 0.8735 - val_accuracy: 0.6222\n",
      "Epoch 150/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8567 - accuracy: 0.6857 - val_loss: 0.8708 - val_accuracy: 0.6222\n",
      "Epoch 151/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8538 - accuracy: 0.6857 - val_loss: 0.8681 - val_accuracy: 0.6222\n",
      "Epoch 152/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8508 - accuracy: 0.6857 - val_loss: 0.8654 - val_accuracy: 0.6222\n",
      "Epoch 153/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8479 - accuracy: 0.6857 - val_loss: 0.8626 - val_accuracy: 0.6222\n",
      "Epoch 154/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8449 - accuracy: 0.6857 - val_loss: 0.8599 - val_accuracy: 0.6222\n",
      "Epoch 155/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.8420 - accuracy: 0.6857 - val_loss: 0.8572 - val_accuracy: 0.6222\n",
      "Epoch 156/400\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.8391 - accuracy: 0.6857 - val_loss: 0.8545 - val_accuracy: 0.6222\n",
      "Epoch 157/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.8361 - accuracy: 0.6857 - val_loss: 0.8517 - val_accuracy: 0.6222\n",
      "Epoch 158/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8332 - accuracy: 0.6857 - val_loss: 0.8490 - val_accuracy: 0.6222\n",
      "Epoch 159/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8302 - accuracy: 0.6857 - val_loss: 0.8463 - val_accuracy: 0.6222\n",
      "Epoch 160/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8273 - accuracy: 0.6857 - val_loss: 0.8435 - val_accuracy: 0.6222\n",
      "Epoch 161/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8243 - accuracy: 0.6857 - val_loss: 0.8408 - val_accuracy: 0.6222\n",
      "Epoch 162/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8214 - accuracy: 0.6857 - val_loss: 0.8380 - val_accuracy: 0.6222\n",
      "Epoch 163/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8184 - accuracy: 0.6857 - val_loss: 0.8353 - val_accuracy: 0.6222\n",
      "Epoch 164/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8155 - accuracy: 0.6857 - val_loss: 0.8326 - val_accuracy: 0.6222\n",
      "Epoch 165/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8125 - accuracy: 0.6857 - val_loss: 0.8298 - val_accuracy: 0.6222\n",
      "Epoch 166/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8095 - accuracy: 0.6857 - val_loss: 0.8271 - val_accuracy: 0.6222\n",
      "Epoch 167/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8066 - accuracy: 0.6857 - val_loss: 0.8244 - val_accuracy: 0.6222\n",
      "Epoch 168/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8036 - accuracy: 0.6857 - val_loss: 0.8217 - val_accuracy: 0.6222\n",
      "Epoch 169/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.8007 - accuracy: 0.6857 - val_loss: 0.8189 - val_accuracy: 0.6222\n",
      "Epoch 170/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7978 - accuracy: 0.6857 - val_loss: 0.8162 - val_accuracy: 0.6222\n",
      "Epoch 171/400\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7948 - accuracy: 0.6857 - val_loss: 0.8135 - val_accuracy: 0.6222\n",
      "Epoch 172/400\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.7919 - accuracy: 0.6857 - val_loss: 0.8108 - val_accuracy: 0.6222\n",
      "Epoch 173/400\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.7889 - accuracy: 0.6857 - val_loss: 0.8081 - val_accuracy: 0.6222\n",
      "Epoch 174/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7860 - accuracy: 0.6857 - val_loss: 0.8054 - val_accuracy: 0.6222\n",
      "Epoch 175/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7831 - accuracy: 0.6857 - val_loss: 0.8027 - val_accuracy: 0.6222\n",
      "Epoch 176/400\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7802 - accuracy: 0.6857 - val_loss: 0.8001 - val_accuracy: 0.6222\n",
      "Epoch 177/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7773 - accuracy: 0.6857 - val_loss: 0.7974 - val_accuracy: 0.6222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 178/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7744 - accuracy: 0.6857 - val_loss: 0.7947 - val_accuracy: 0.6222\n",
      "Epoch 179/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7715 - accuracy: 0.6857 - val_loss: 0.7920 - val_accuracy: 0.6222\n",
      "Epoch 180/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7686 - accuracy: 0.6857 - val_loss: 0.7894 - val_accuracy: 0.6222\n",
      "Epoch 181/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7657 - accuracy: 0.6857 - val_loss: 0.7867 - val_accuracy: 0.6222\n",
      "Epoch 182/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.7628 - accuracy: 0.6857 - val_loss: 0.7841 - val_accuracy: 0.6222\n",
      "Epoch 183/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7600 - accuracy: 0.6857 - val_loss: 0.7815 - val_accuracy: 0.6222\n",
      "Epoch 184/400\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.7571 - accuracy: 0.6857 - val_loss: 0.7789 - val_accuracy: 0.6222\n",
      "Epoch 185/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7543 - accuracy: 0.6857 - val_loss: 0.7763 - val_accuracy: 0.6222\n",
      "Epoch 186/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7514 - accuracy: 0.6857 - val_loss: 0.7737 - val_accuracy: 0.6222\n",
      "Epoch 187/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7486 - accuracy: 0.6857 - val_loss: 0.7711 - val_accuracy: 0.6222\n",
      "Epoch 188/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7458 - accuracy: 0.6857 - val_loss: 0.7685 - val_accuracy: 0.6222\n",
      "Epoch 189/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7429 - accuracy: 0.6857 - val_loss: 0.7659 - val_accuracy: 0.6222\n",
      "Epoch 190/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7401 - accuracy: 0.6857 - val_loss: 0.7633 - val_accuracy: 0.6222\n",
      "Epoch 191/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7373 - accuracy: 0.6857 - val_loss: 0.7608 - val_accuracy: 0.6222\n",
      "Epoch 192/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7346 - accuracy: 0.6857 - val_loss: 0.7582 - val_accuracy: 0.6222\n",
      "Epoch 193/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7318 - accuracy: 0.6857 - val_loss: 0.7557 - val_accuracy: 0.6222\n",
      "Epoch 194/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7290 - accuracy: 0.6857 - val_loss: 0.7531 - val_accuracy: 0.6222\n",
      "Epoch 195/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7263 - accuracy: 0.6857 - val_loss: 0.7506 - val_accuracy: 0.6222\n",
      "Epoch 196/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7235 - accuracy: 0.6857 - val_loss: 0.7481 - val_accuracy: 0.6222\n",
      "Epoch 197/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7208 - accuracy: 0.6857 - val_loss: 0.7456 - val_accuracy: 0.6222\n",
      "Epoch 198/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.7181 - accuracy: 0.6857 - val_loss: 0.7431 - val_accuracy: 0.6222\n",
      "Epoch 199/400\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.7153 - accuracy: 0.6857 - val_loss: 0.7405 - val_accuracy: 0.6222\n",
      "Epoch 200/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7126 - accuracy: 0.6857 - val_loss: 0.7381 - val_accuracy: 0.6222\n",
      "Epoch 201/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7100 - accuracy: 0.6857 - val_loss: 0.7356 - val_accuracy: 0.6222\n",
      "Epoch 202/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.7073 - accuracy: 0.6857 - val_loss: 0.7331 - val_accuracy: 0.6222\n",
      "Epoch 203/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7046 - accuracy: 0.6857 - val_loss: 0.7306 - val_accuracy: 0.6222\n",
      "Epoch 204/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.7020 - accuracy: 0.6857 - val_loss: 0.7282 - val_accuracy: 0.6222\n",
      "Epoch 205/400\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6993 - accuracy: 0.6857 - val_loss: 0.7257 - val_accuracy: 0.6222\n",
      "Epoch 206/400\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6967 - accuracy: 0.6857 - val_loss: 0.7233 - val_accuracy: 0.6222\n",
      "Epoch 207/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6941 - accuracy: 0.6857 - val_loss: 0.7209 - val_accuracy: 0.6222\n",
      "Epoch 208/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6915 - accuracy: 0.6857 - val_loss: 0.7185 - val_accuracy: 0.6222\n",
      "Epoch 209/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6889 - accuracy: 0.6857 - val_loss: 0.7160 - val_accuracy: 0.6222\n",
      "Epoch 210/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6863 - accuracy: 0.6857 - val_loss: 0.7137 - val_accuracy: 0.6222\n",
      "Epoch 211/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6837 - accuracy: 0.6857 - val_loss: 0.7113 - val_accuracy: 0.6222\n",
      "Epoch 212/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6812 - accuracy: 0.6857 - val_loss: 0.7089 - val_accuracy: 0.6222\n",
      "Epoch 213/400\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6786 - accuracy: 0.6857 - val_loss: 0.7065 - val_accuracy: 0.6222\n",
      "Epoch 214/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6761 - accuracy: 0.6857 - val_loss: 0.7042 - val_accuracy: 0.6222\n",
      "Epoch 215/400\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6736 - accuracy: 0.6857 - val_loss: 0.7018 - val_accuracy: 0.6222\n",
      "Epoch 216/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6711 - accuracy: 0.6857 - val_loss: 0.6995 - val_accuracy: 0.6222\n",
      "Epoch 217/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6686 - accuracy: 0.6857 - val_loss: 0.6972 - val_accuracy: 0.6222\n",
      "Epoch 218/400\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6662 - accuracy: 0.6857 - val_loss: 0.6949 - val_accuracy: 0.6222\n",
      "Epoch 219/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6637 - accuracy: 0.6857 - val_loss: 0.6926 - val_accuracy: 0.6222\n",
      "Epoch 220/400\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.6613 - accuracy: 0.6857 - val_loss: 0.6903 - val_accuracy: 0.6222\n",
      "Epoch 221/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6588 - accuracy: 0.6857 - val_loss: 0.6880 - val_accuracy: 0.6222\n",
      "Epoch 222/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6564 - accuracy: 0.6857 - val_loss: 0.6857 - val_accuracy: 0.6222\n",
      "Epoch 223/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6540 - accuracy: 0.6857 - val_loss: 0.6835 - val_accuracy: 0.6222\n",
      "Epoch 224/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6516 - accuracy: 0.6857 - val_loss: 0.6813 - val_accuracy: 0.6222\n",
      "Epoch 225/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6493 - accuracy: 0.6857 - val_loss: 0.6791 - val_accuracy: 0.6222\n",
      "Epoch 226/400\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6469 - accuracy: 0.6857 - val_loss: 0.6769 - val_accuracy: 0.6222\n",
      "Epoch 227/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6446 - accuracy: 0.6857 - val_loss: 0.6747 - val_accuracy: 0.6222\n",
      "Epoch 228/400\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.6422 - accuracy: 0.6857 - val_loss: 0.6725 - val_accuracy: 0.6222\n",
      "Epoch 229/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6399 - accuracy: 0.6857 - val_loss: 0.6703 - val_accuracy: 0.6222\n",
      "Epoch 230/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.6376 - accuracy: 0.6857 - val_loss: 0.6681 - val_accuracy: 0.6222\n",
      "Epoch 231/400\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.6353 - accuracy: 0.6857 - val_loss: 0.6659 - val_accuracy: 0.6222\n",
      "Epoch 232/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6330 - accuracy: 0.6857 - val_loss: 0.6638 - val_accuracy: 0.6222\n",
      "Epoch 233/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6308 - accuracy: 0.6857 - val_loss: 0.6616 - val_accuracy: 0.6222\n",
      "Epoch 234/400\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.6285 - accuracy: 0.6857 - val_loss: 0.6595 - val_accuracy: 0.6222\n",
      "Epoch 235/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6263 - accuracy: 0.6857 - val_loss: 0.6573 - val_accuracy: 0.6222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 236/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6241 - accuracy: 0.6857 - val_loss: 0.6552 - val_accuracy: 0.6222\n",
      "Epoch 237/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6218 - accuracy: 0.6857 - val_loss: 0.6531 - val_accuracy: 0.6222\n",
      "Epoch 238/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6196 - accuracy: 0.6857 - val_loss: 0.6510 - val_accuracy: 0.6222\n",
      "Epoch 239/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6175 - accuracy: 0.6857 - val_loss: 0.6489 - val_accuracy: 0.6222\n",
      "Epoch 240/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.6153 - accuracy: 0.6857 - val_loss: 0.6468 - val_accuracy: 0.6222\n",
      "Epoch 241/400\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6131 - accuracy: 0.6857 - val_loss: 0.6447 - val_accuracy: 0.6222\n",
      "Epoch 242/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6110 - accuracy: 0.6857 - val_loss: 0.6426 - val_accuracy: 0.6222\n",
      "Epoch 243/400\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6088 - accuracy: 0.6857 - val_loss: 0.6406 - val_accuracy: 0.6222\n",
      "Epoch 244/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6067 - accuracy: 0.6857 - val_loss: 0.6385 - val_accuracy: 0.6444\n",
      "Epoch 245/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6046 - accuracy: 0.6857 - val_loss: 0.6365 - val_accuracy: 0.6444\n",
      "Epoch 246/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6025 - accuracy: 0.6857 - val_loss: 0.6345 - val_accuracy: 0.6444\n",
      "Epoch 247/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6004 - accuracy: 0.6857 - val_loss: 0.6325 - val_accuracy: 0.6444\n",
      "Epoch 248/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5983 - accuracy: 0.6857 - val_loss: 0.6305 - val_accuracy: 0.6444\n",
      "Epoch 249/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5963 - accuracy: 0.6857 - val_loss: 0.6285 - val_accuracy: 0.6444\n",
      "Epoch 250/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5942 - accuracy: 0.6857 - val_loss: 0.6265 - val_accuracy: 0.6444\n",
      "Epoch 251/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5922 - accuracy: 0.6857 - val_loss: 0.6246 - val_accuracy: 0.6444\n",
      "Epoch 252/400\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5902 - accuracy: 0.6857 - val_loss: 0.6226 - val_accuracy: 0.6444\n",
      "Epoch 253/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5882 - accuracy: 0.6857 - val_loss: 0.6207 - val_accuracy: 0.6444\n",
      "Epoch 254/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5861 - accuracy: 0.6857 - val_loss: 0.6187 - val_accuracy: 0.6444\n",
      "Epoch 255/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5842 - accuracy: 0.6857 - val_loss: 0.6168 - val_accuracy: 0.6444\n",
      "Epoch 256/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5822 - accuracy: 0.6857 - val_loss: 0.6149 - val_accuracy: 0.6444\n",
      "Epoch 257/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5802 - accuracy: 0.6857 - val_loss: 0.6130 - val_accuracy: 0.6444\n",
      "Epoch 258/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5783 - accuracy: 0.6857 - val_loss: 0.6111 - val_accuracy: 0.6444\n",
      "Epoch 259/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5763 - accuracy: 0.6857 - val_loss: 0.6092 - val_accuracy: 0.6444\n",
      "Epoch 260/400\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5744 - accuracy: 0.6857 - val_loss: 0.6074 - val_accuracy: 0.6444\n",
      "Epoch 261/400\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5725 - accuracy: 0.6857 - val_loss: 0.6055 - val_accuracy: 0.6444\n",
      "Epoch 262/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5705 - accuracy: 0.6857 - val_loss: 0.6036 - val_accuracy: 0.6444\n",
      "Epoch 263/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5686 - accuracy: 0.6857 - val_loss: 0.6018 - val_accuracy: 0.6444\n",
      "Epoch 264/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5668 - accuracy: 0.6857 - val_loss: 0.5999 - val_accuracy: 0.6444\n",
      "Epoch 265/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5649 - accuracy: 0.6952 - val_loss: 0.5981 - val_accuracy: 0.6444\n",
      "Epoch 266/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5630 - accuracy: 0.6952 - val_loss: 0.5962 - val_accuracy: 0.6444\n",
      "Epoch 267/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5612 - accuracy: 0.6952 - val_loss: 0.5944 - val_accuracy: 0.6444\n",
      "Epoch 268/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5593 - accuracy: 0.6952 - val_loss: 0.5926 - val_accuracy: 0.6444\n",
      "Epoch 269/400\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5575 - accuracy: 0.6952 - val_loss: 0.5908 - val_accuracy: 0.6444\n",
      "Epoch 270/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5556 - accuracy: 0.6952 - val_loss: 0.5890 - val_accuracy: 0.6444\n",
      "Epoch 271/400\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5538 - accuracy: 0.6952 - val_loss: 0.5872 - val_accuracy: 0.6444\n",
      "Epoch 272/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5520 - accuracy: 0.7048 - val_loss: 0.5854 - val_accuracy: 0.6444\n",
      "Epoch 273/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5502 - accuracy: 0.7048 - val_loss: 0.5836 - val_accuracy: 0.6444\n",
      "Epoch 274/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5484 - accuracy: 0.7238 - val_loss: 0.5818 - val_accuracy: 0.6444\n",
      "Epoch 275/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5467 - accuracy: 0.7238 - val_loss: 0.5801 - val_accuracy: 0.6444\n",
      "Epoch 276/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5449 - accuracy: 0.7238 - val_loss: 0.5783 - val_accuracy: 0.6444\n",
      "Epoch 277/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5432 - accuracy: 0.7238 - val_loss: 0.5766 - val_accuracy: 0.6444\n",
      "Epoch 278/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5414 - accuracy: 0.7238 - val_loss: 0.5748 - val_accuracy: 0.6444\n",
      "Epoch 279/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5397 - accuracy: 0.7238 - val_loss: 0.5731 - val_accuracy: 0.6444\n",
      "Epoch 280/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5380 - accuracy: 0.7238 - val_loss: 0.5714 - val_accuracy: 0.6444\n",
      "Epoch 281/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5362 - accuracy: 0.7238 - val_loss: 0.5697 - val_accuracy: 0.6444\n",
      "Epoch 282/400\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5345 - accuracy: 0.7238 - val_loss: 0.5680 - val_accuracy: 0.6444\n",
      "Epoch 283/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5329 - accuracy: 0.7333 - val_loss: 0.5663 - val_accuracy: 0.6444\n",
      "Epoch 284/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5312 - accuracy: 0.7429 - val_loss: 0.5646 - val_accuracy: 0.6444\n",
      "Epoch 285/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5295 - accuracy: 0.7524 - val_loss: 0.5630 - val_accuracy: 0.6444\n",
      "Epoch 286/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5279 - accuracy: 0.7524 - val_loss: 0.5613 - val_accuracy: 0.6444\n",
      "Epoch 287/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5262 - accuracy: 0.7524 - val_loss: 0.5597 - val_accuracy: 0.6444\n",
      "Epoch 288/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5246 - accuracy: 0.7524 - val_loss: 0.5581 - val_accuracy: 0.6444\n",
      "Epoch 289/400\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.5229 - accuracy: 0.7524 - val_loss: 0.5564 - val_accuracy: 0.6444\n",
      "Epoch 290/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5213 - accuracy: 0.7619 - val_loss: 0.5548 - val_accuracy: 0.6444\n",
      "Epoch 291/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5197 - accuracy: 0.7619 - val_loss: 0.5532 - val_accuracy: 0.6444\n",
      "Epoch 292/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5181 - accuracy: 0.7619 - val_loss: 0.5516 - val_accuracy: 0.6667\n",
      "Epoch 293/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5165 - accuracy: 0.7619 - val_loss: 0.5500 - val_accuracy: 0.6667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 294/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5149 - accuracy: 0.7619 - val_loss: 0.5484 - val_accuracy: 0.6667\n",
      "Epoch 295/400\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5133 - accuracy: 0.7619 - val_loss: 0.5468 - val_accuracy: 0.6667\n",
      "Epoch 296/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5117 - accuracy: 0.7619 - val_loss: 0.5452 - val_accuracy: 0.6667\n",
      "Epoch 297/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5102 - accuracy: 0.7619 - val_loss: 0.5436 - val_accuracy: 0.6667\n",
      "Epoch 298/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5086 - accuracy: 0.7619 - val_loss: 0.5420 - val_accuracy: 0.6667\n",
      "Epoch 299/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.5070 - accuracy: 0.7619 - val_loss: 0.5404 - val_accuracy: 0.6667\n",
      "Epoch 300/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5055 - accuracy: 0.7619 - val_loss: 0.5389 - val_accuracy: 0.6667\n",
      "Epoch 301/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5040 - accuracy: 0.7619 - val_loss: 0.5373 - val_accuracy: 0.6667\n",
      "Epoch 302/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5024 - accuracy: 0.7619 - val_loss: 0.5357 - val_accuracy: 0.6667\n",
      "Epoch 303/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.5009 - accuracy: 0.7619 - val_loss: 0.5341 - val_accuracy: 0.6667\n",
      "Epoch 304/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4994 - accuracy: 0.7619 - val_loss: 0.5326 - val_accuracy: 0.6667\n",
      "Epoch 305/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4979 - accuracy: 0.7619 - val_loss: 0.5310 - val_accuracy: 0.6667\n",
      "Epoch 306/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4964 - accuracy: 0.7619 - val_loss: 0.5294 - val_accuracy: 0.6667\n",
      "Epoch 307/400\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4949 - accuracy: 0.7619 - val_loss: 0.5278 - val_accuracy: 0.6667\n",
      "Epoch 308/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4934 - accuracy: 0.7619 - val_loss: 0.5263 - val_accuracy: 0.6889\n",
      "Epoch 309/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4919 - accuracy: 0.7619 - val_loss: 0.5247 - val_accuracy: 0.6889\n",
      "Epoch 310/400\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4904 - accuracy: 0.7619 - val_loss: 0.5232 - val_accuracy: 0.7111\n",
      "Epoch 311/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4889 - accuracy: 0.7619 - val_loss: 0.5216 - val_accuracy: 0.7111\n",
      "Epoch 312/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4875 - accuracy: 0.7619 - val_loss: 0.5201 - val_accuracy: 0.7111\n",
      "Epoch 313/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4860 - accuracy: 0.7714 - val_loss: 0.5185 - val_accuracy: 0.7111\n",
      "Epoch 314/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4845 - accuracy: 0.7714 - val_loss: 0.5170 - val_accuracy: 0.7111\n",
      "Epoch 315/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4831 - accuracy: 0.7714 - val_loss: 0.5155 - val_accuracy: 0.7111\n",
      "Epoch 316/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4816 - accuracy: 0.7714 - val_loss: 0.5139 - val_accuracy: 0.7111\n",
      "Epoch 317/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4802 - accuracy: 0.7810 - val_loss: 0.5124 - val_accuracy: 0.7111\n",
      "Epoch 318/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4788 - accuracy: 0.7810 - val_loss: 0.5109 - val_accuracy: 0.7111\n",
      "Epoch 319/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4773 - accuracy: 0.7905 - val_loss: 0.5094 - val_accuracy: 0.7111\n",
      "Epoch 320/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4759 - accuracy: 0.7905 - val_loss: 0.5079 - val_accuracy: 0.7111\n",
      "Epoch 321/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4745 - accuracy: 0.7905 - val_loss: 0.5064 - val_accuracy: 0.7111\n",
      "Epoch 322/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4730 - accuracy: 0.7905 - val_loss: 0.5049 - val_accuracy: 0.7111\n",
      "Epoch 323/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4716 - accuracy: 0.7905 - val_loss: 0.5034 - val_accuracy: 0.7111\n",
      "Epoch 324/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4702 - accuracy: 0.7905 - val_loss: 0.5018 - val_accuracy: 0.7111\n",
      "Epoch 325/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4688 - accuracy: 0.7905 - val_loss: 0.5003 - val_accuracy: 0.7111\n",
      "Epoch 326/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4674 - accuracy: 0.7905 - val_loss: 0.4988 - val_accuracy: 0.7111\n",
      "Epoch 327/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4660 - accuracy: 0.7905 - val_loss: 0.4973 - val_accuracy: 0.7111\n",
      "Epoch 328/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4646 - accuracy: 0.7905 - val_loss: 0.4958 - val_accuracy: 0.7111\n",
      "Epoch 329/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4632 - accuracy: 0.7905 - val_loss: 0.4944 - val_accuracy: 0.7111\n",
      "Epoch 330/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4618 - accuracy: 0.8095 - val_loss: 0.4929 - val_accuracy: 0.7111\n",
      "Epoch 331/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4604 - accuracy: 0.8095 - val_loss: 0.4914 - val_accuracy: 0.7111\n",
      "Epoch 332/400\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4590 - accuracy: 0.8095 - val_loss: 0.4899 - val_accuracy: 0.7111\n",
      "Epoch 333/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4576 - accuracy: 0.8190 - val_loss: 0.4884 - val_accuracy: 0.7111\n",
      "Epoch 334/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4562 - accuracy: 0.8190 - val_loss: 0.4869 - val_accuracy: 0.7333\n",
      "Epoch 335/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4549 - accuracy: 0.8286 - val_loss: 0.4854 - val_accuracy: 0.7556\n",
      "Epoch 336/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4535 - accuracy: 0.8286 - val_loss: 0.4839 - val_accuracy: 0.7778\n",
      "Epoch 337/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4521 - accuracy: 0.8286 - val_loss: 0.4824 - val_accuracy: 0.8000\n",
      "Epoch 338/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4507 - accuracy: 0.8381 - val_loss: 0.4809 - val_accuracy: 0.8000\n",
      "Epoch 339/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4494 - accuracy: 0.8381 - val_loss: 0.4794 - val_accuracy: 0.8000\n",
      "Epoch 340/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4480 - accuracy: 0.8381 - val_loss: 0.4779 - val_accuracy: 0.8000\n",
      "Epoch 341/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4466 - accuracy: 0.8381 - val_loss: 0.4765 - val_accuracy: 0.8000\n",
      "Epoch 342/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4453 - accuracy: 0.8381 - val_loss: 0.4750 - val_accuracy: 0.8000\n",
      "Epoch 343/400\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4439 - accuracy: 0.8476 - val_loss: 0.4735 - val_accuracy: 0.8000\n",
      "Epoch 344/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4425 - accuracy: 0.8476 - val_loss: 0.4720 - val_accuracy: 0.8000\n",
      "Epoch 345/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4412 - accuracy: 0.8571 - val_loss: 0.4705 - val_accuracy: 0.8000\n",
      "Epoch 346/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4398 - accuracy: 0.8571 - val_loss: 0.4690 - val_accuracy: 0.8000\n",
      "Epoch 347/400\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4385 - accuracy: 0.8571 - val_loss: 0.4675 - val_accuracy: 0.8000\n",
      "Epoch 348/400\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4371 - accuracy: 0.8571 - val_loss: 0.4661 - val_accuracy: 0.8000\n",
      "Epoch 349/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4357 - accuracy: 0.8571 - val_loss: 0.4646 - val_accuracy: 0.8222\n",
      "Epoch 350/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4344 - accuracy: 0.8571 - val_loss: 0.4631 - val_accuracy: 0.8222\n",
      "Epoch 351/400\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4330 - accuracy: 0.8571 - val_loss: 0.4616 - val_accuracy: 0.8222\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 352/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4317 - accuracy: 0.8571 - val_loss: 0.4601 - val_accuracy: 0.8222\n",
      "Epoch 353/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4304 - accuracy: 0.8571 - val_loss: 0.4587 - val_accuracy: 0.8222\n",
      "Epoch 354/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4290 - accuracy: 0.8571 - val_loss: 0.4572 - val_accuracy: 0.8222\n",
      "Epoch 355/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4277 - accuracy: 0.8667 - val_loss: 0.4557 - val_accuracy: 0.8222\n",
      "Epoch 356/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4263 - accuracy: 0.8667 - val_loss: 0.4543 - val_accuracy: 0.8222\n",
      "Epoch 357/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4250 - accuracy: 0.8667 - val_loss: 0.4528 - val_accuracy: 0.8222\n",
      "Epoch 358/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4236 - accuracy: 0.8667 - val_loss: 0.4514 - val_accuracy: 0.8222\n",
      "Epoch 359/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4223 - accuracy: 0.8667 - val_loss: 0.4499 - val_accuracy: 0.8222\n",
      "Epoch 360/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4210 - accuracy: 0.8667 - val_loss: 0.4484 - val_accuracy: 0.8222\n",
      "Epoch 361/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4196 - accuracy: 0.8667 - val_loss: 0.4469 - val_accuracy: 0.8222\n",
      "Epoch 362/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4183 - accuracy: 0.8667 - val_loss: 0.4455 - val_accuracy: 0.8222\n",
      "Epoch 363/400\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4170 - accuracy: 0.8667 - val_loss: 0.4440 - val_accuracy: 0.8444\n",
      "Epoch 364/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4157 - accuracy: 0.8667 - val_loss: 0.4425 - val_accuracy: 0.8444\n",
      "Epoch 365/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4143 - accuracy: 0.8667 - val_loss: 0.4411 - val_accuracy: 0.8444\n",
      "Epoch 366/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4130 - accuracy: 0.8667 - val_loss: 0.4396 - val_accuracy: 0.8444\n",
      "Epoch 367/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4117 - accuracy: 0.8667 - val_loss: 0.4381 - val_accuracy: 0.8444\n",
      "Epoch 368/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4104 - accuracy: 0.8667 - val_loss: 0.4367 - val_accuracy: 0.8444\n",
      "Epoch 369/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4090 - accuracy: 0.8667 - val_loss: 0.4352 - val_accuracy: 0.8444\n",
      "Epoch 370/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4077 - accuracy: 0.8667 - val_loss: 0.4338 - val_accuracy: 0.8444\n",
      "Epoch 371/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4064 - accuracy: 0.8667 - val_loss: 0.4323 - val_accuracy: 0.8444\n",
      "Epoch 372/400\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.4051 - accuracy: 0.8667 - val_loss: 0.4309 - val_accuracy: 0.8444\n",
      "Epoch 373/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4038 - accuracy: 0.8667 - val_loss: 0.4294 - val_accuracy: 0.8444\n",
      "Epoch 374/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4024 - accuracy: 0.8667 - val_loss: 0.4279 - val_accuracy: 0.8444\n",
      "Epoch 375/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4011 - accuracy: 0.8667 - val_loss: 0.4265 - val_accuracy: 0.8667\n",
      "Epoch 376/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3998 - accuracy: 0.8667 - val_loss: 0.4250 - val_accuracy: 0.8667\n",
      "Epoch 377/400\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3985 - accuracy: 0.8762 - val_loss: 0.4235 - val_accuracy: 0.8667\n",
      "Epoch 378/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3972 - accuracy: 0.8762 - val_loss: 0.4221 - val_accuracy: 0.8667\n",
      "Epoch 379/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3959 - accuracy: 0.8762 - val_loss: 0.4206 - val_accuracy: 0.8667\n",
      "Epoch 380/400\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3945 - accuracy: 0.8762 - val_loss: 0.4191 - val_accuracy: 0.8667\n",
      "Epoch 381/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3932 - accuracy: 0.8857 - val_loss: 0.4177 - val_accuracy: 0.8667\n",
      "Epoch 382/400\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3919 - accuracy: 0.8857 - val_loss: 0.4162 - val_accuracy: 0.8667\n",
      "Epoch 383/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3906 - accuracy: 0.8857 - val_loss: 0.4147 - val_accuracy: 0.8667\n",
      "Epoch 384/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3893 - accuracy: 0.8857 - val_loss: 0.4133 - val_accuracy: 0.8667\n",
      "Epoch 385/400\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3880 - accuracy: 0.8857 - val_loss: 0.4118 - val_accuracy: 0.8889\n",
      "Epoch 386/400\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3867 - accuracy: 0.8952 - val_loss: 0.4103 - val_accuracy: 0.8889\n",
      "Epoch 387/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3854 - accuracy: 0.8952 - val_loss: 0.4089 - val_accuracy: 0.9111\n",
      "Epoch 388/400\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3841 - accuracy: 0.8952 - val_loss: 0.4074 - val_accuracy: 0.9111\n",
      "Epoch 389/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3828 - accuracy: 0.9048 - val_loss: 0.4059 - val_accuracy: 0.9111\n",
      "Epoch 390/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3815 - accuracy: 0.9048 - val_loss: 0.4045 - val_accuracy: 0.9111\n",
      "Epoch 391/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3802 - accuracy: 0.9048 - val_loss: 0.4030 - val_accuracy: 0.9111\n",
      "Epoch 392/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3789 - accuracy: 0.9048 - val_loss: 0.4015 - val_accuracy: 0.9111\n",
      "Epoch 393/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3776 - accuracy: 0.9048 - val_loss: 0.4001 - val_accuracy: 0.9111\n",
      "Epoch 394/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3763 - accuracy: 0.9048 - val_loss: 0.3986 - val_accuracy: 0.9111\n",
      "Epoch 395/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3750 - accuracy: 0.9048 - val_loss: 0.3971 - val_accuracy: 0.9111\n",
      "Epoch 396/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3737 - accuracy: 0.9048 - val_loss: 0.3956 - val_accuracy: 0.9111\n",
      "Epoch 397/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3724 - accuracy: 0.9048 - val_loss: 0.3942 - val_accuracy: 0.9111\n",
      "Epoch 398/400\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3711 - accuracy: 0.9048 - val_loss: 0.3927 - val_accuracy: 0.9111\n",
      "Epoch 399/400\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3698 - accuracy: 0.9048 - val_loss: 0.3912 - val_accuracy: 0.9111\n",
      "Epoch 400/400\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3685 - accuracy: 0.9143 - val_loss: 0.3897 - val_accuracy: 0.9111\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=400, batch_size=150, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1ca8b1ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85ac1195",
   "metadata": {},
   "source": [
    "# 클래스형"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "955687c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5da33bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Iris(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Iris, self).__init__()\n",
    "        self.dense1 = tf.keras.layers.Dense(32, activation='relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(64, activation='relu')\n",
    "        self.classifier = tf.keras.layers.Dense(3, activation='softmax')\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "aeed4de1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Iris-setosa</th>\n",
       "      <th>Iris-versicolor</th>\n",
       "      <th>Iris-virginica</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>121</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>113</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>64</th>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>125</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Iris-setosa  Iris-versicolor  Iris-virginica\n",
       "32          True            False           False\n",
       "52         False             True           False\n",
       "70         False             True           False\n",
       "121        False            False            True\n",
       "144        False            False            True\n",
       "..           ...              ...             ...\n",
       "113        False            False            True\n",
       "64         False             True           False\n",
       "15          True            False           False\n",
       "125        False            False            True\n",
       "9           True            False           False\n",
       "\n",
       "[105 rows x 3 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5373d353",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 10:24:53.627528: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-10 10:24:53.670303: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 10:24:53.670369: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 690ms/step - loss: 1.0579 - accuracy: 0.6667 - val_loss: 1.0763 - val_accuracy: 0.6000\n",
      "Epoch 2/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 1.0512 - accuracy: 0.6857 - val_loss: 1.0697 - val_accuracy: 0.6000\n",
      "Epoch 3/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0444 - accuracy: 0.6857 - val_loss: 1.0629 - val_accuracy: 0.6222\n",
      "Epoch 4/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0374 - accuracy: 0.6857 - val_loss: 1.0561 - val_accuracy: 0.6222\n",
      "Epoch 5/500\n",
      "1/1 [==============================] - ETA: 0s - loss: 1.0304 - accuracy: 0.6857"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-10 10:24:53.997551: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-10 10:24:54.021378: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-10 10:24:54.021465: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0304 - accuracy: 0.6857 - val_loss: 1.0493 - val_accuracy: 0.6222\n",
      "Epoch 6/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 1.0233 - accuracy: 0.6857 - val_loss: 1.0425 - val_accuracy: 0.6222\n",
      "Epoch 7/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 1.0162 - accuracy: 0.6857 - val_loss: 1.0357 - val_accuracy: 0.6222\n",
      "Epoch 8/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 1.0091 - accuracy: 0.6857 - val_loss: 1.0290 - val_accuracy: 0.6222\n",
      "Epoch 9/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 1.0020 - accuracy: 0.6857 - val_loss: 1.0223 - val_accuracy: 0.6222\n",
      "Epoch 10/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.9949 - accuracy: 0.6857 - val_loss: 1.0156 - val_accuracy: 0.6222\n",
      "Epoch 11/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9878 - accuracy: 0.6857 - val_loss: 1.0090 - val_accuracy: 0.6222\n",
      "Epoch 12/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.9807 - accuracy: 0.6857 - val_loss: 1.0026 - val_accuracy: 0.6222\n",
      "Epoch 13/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9736 - accuracy: 0.6857 - val_loss: 0.9961 - val_accuracy: 0.6222\n",
      "Epoch 14/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9665 - accuracy: 0.6857 - val_loss: 0.9897 - val_accuracy: 0.6222\n",
      "Epoch 15/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9595 - accuracy: 0.6857 - val_loss: 0.9833 - val_accuracy: 0.6222\n",
      "Epoch 16/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9524 - accuracy: 0.6857 - val_loss: 0.9768 - val_accuracy: 0.6222\n",
      "Epoch 17/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.9454 - accuracy: 0.6857 - val_loss: 0.9704 - val_accuracy: 0.6222\n",
      "Epoch 18/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9383 - accuracy: 0.6857 - val_loss: 0.9640 - val_accuracy: 0.6222\n",
      "Epoch 19/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.9312 - accuracy: 0.6857 - val_loss: 0.9577 - val_accuracy: 0.6222\n",
      "Epoch 20/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.9241 - accuracy: 0.6857 - val_loss: 0.9514 - val_accuracy: 0.6222\n",
      "Epoch 21/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.9170 - accuracy: 0.6857 - val_loss: 0.9450 - val_accuracy: 0.6222\n",
      "Epoch 22/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.9099 - accuracy: 0.6857 - val_loss: 0.9386 - val_accuracy: 0.6222\n",
      "Epoch 23/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.9027 - accuracy: 0.6857 - val_loss: 0.9321 - val_accuracy: 0.6222\n",
      "Epoch 24/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.8955 - accuracy: 0.6857 - val_loss: 0.9256 - val_accuracy: 0.6222\n",
      "Epoch 25/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8883 - accuracy: 0.6857 - val_loss: 0.9190 - val_accuracy: 0.6222\n",
      "Epoch 26/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.8810 - accuracy: 0.6857 - val_loss: 0.9122 - val_accuracy: 0.6222\n",
      "Epoch 27/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.8736 - accuracy: 0.6857 - val_loss: 0.9053 - val_accuracy: 0.6222\n",
      "Epoch 28/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.8661 - accuracy: 0.6857 - val_loss: 0.8984 - val_accuracy: 0.6222\n",
      "Epoch 29/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.8584 - accuracy: 0.6857 - val_loss: 0.8913 - val_accuracy: 0.6222\n",
      "Epoch 30/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.8507 - accuracy: 0.6857 - val_loss: 0.8841 - val_accuracy: 0.6222\n",
      "Epoch 31/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8428 - accuracy: 0.6857 - val_loss: 0.8768 - val_accuracy: 0.6222\n",
      "Epoch 32/500\n",
      "1/1 [==============================] - 0s 65ms/step - loss: 0.8347 - accuracy: 0.6857 - val_loss: 0.8694 - val_accuracy: 0.6222\n",
      "Epoch 33/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.8266 - accuracy: 0.6857 - val_loss: 0.8618 - val_accuracy: 0.6222\n",
      "Epoch 34/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.8182 - accuracy: 0.6857 - val_loss: 0.8542 - val_accuracy: 0.6222\n",
      "Epoch 35/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.8098 - accuracy: 0.6857 - val_loss: 0.8465 - val_accuracy: 0.6222\n",
      "Epoch 36/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.8013 - accuracy: 0.6857 - val_loss: 0.8388 - val_accuracy: 0.6222\n",
      "Epoch 37/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7927 - accuracy: 0.6857 - val_loss: 0.8310 - val_accuracy: 0.6222\n",
      "Epoch 38/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7840 - accuracy: 0.6857 - val_loss: 0.8232 - val_accuracy: 0.6222\n",
      "Epoch 39/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7753 - accuracy: 0.6857 - val_loss: 0.8152 - val_accuracy: 0.6222\n",
      "Epoch 40/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.7665 - accuracy: 0.6857 - val_loss: 0.8072 - val_accuracy: 0.6222\n",
      "Epoch 41/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7577 - accuracy: 0.6857 - val_loss: 0.7992 - val_accuracy: 0.6222\n",
      "Epoch 42/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7489 - accuracy: 0.6857 - val_loss: 0.7912 - val_accuracy: 0.6222\n",
      "Epoch 43/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7402 - accuracy: 0.6857 - val_loss: 0.7832 - val_accuracy: 0.6222\n",
      "Epoch 44/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7314 - accuracy: 0.6857 - val_loss: 0.7752 - val_accuracy: 0.6222\n",
      "Epoch 45/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.7228 - accuracy: 0.6857 - val_loss: 0.7672 - val_accuracy: 0.6222\n",
      "Epoch 46/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7142 - accuracy: 0.6857 - val_loss: 0.7593 - val_accuracy: 0.6222\n",
      "Epoch 47/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.7056 - accuracy: 0.6857 - val_loss: 0.7512 - val_accuracy: 0.6222\n",
      "Epoch 48/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6970 - accuracy: 0.6857 - val_loss: 0.7432 - val_accuracy: 0.6222\n",
      "Epoch 49/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6885 - accuracy: 0.6857 - val_loss: 0.7351 - val_accuracy: 0.6222\n",
      "Epoch 50/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6800 - accuracy: 0.6857 - val_loss: 0.7271 - val_accuracy: 0.6222\n",
      "Epoch 51/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.6716 - accuracy: 0.6857 - val_loss: 0.7191 - val_accuracy: 0.6222\n",
      "Epoch 52/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6632 - accuracy: 0.6857 - val_loss: 0.7111 - val_accuracy: 0.6222\n",
      "Epoch 53/500\n",
      "1/1 [==============================] - 0s 70ms/step - loss: 0.6550 - accuracy: 0.6857 - val_loss: 0.7032 - val_accuracy: 0.6222\n",
      "Epoch 54/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.6469 - accuracy: 0.6857 - val_loss: 0.6953 - val_accuracy: 0.6222\n",
      "Epoch 55/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6388 - accuracy: 0.6857 - val_loss: 0.6875 - val_accuracy: 0.6222\n",
      "Epoch 56/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.6309 - accuracy: 0.6857 - val_loss: 0.6798 - val_accuracy: 0.6222\n",
      "Epoch 57/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6231 - accuracy: 0.6857 - val_loss: 0.6722 - val_accuracy: 0.6222\n",
      "Epoch 58/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6154 - accuracy: 0.6857 - val_loss: 0.6647 - val_accuracy: 0.6222\n",
      "Epoch 59/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.6078 - accuracy: 0.6857 - val_loss: 0.6573 - val_accuracy: 0.6222\n",
      "Epoch 60/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.6003 - accuracy: 0.6857 - val_loss: 0.6500 - val_accuracy: 0.6222\n",
      "Epoch 61/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5930 - accuracy: 0.6857 - val_loss: 0.6427 - val_accuracy: 0.6222\n",
      "Epoch 62/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5858 - accuracy: 0.6857 - val_loss: 0.6356 - val_accuracy: 0.6222\n",
      "Epoch 63/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5788 - accuracy: 0.6857 - val_loss: 0.6286 - val_accuracy: 0.6222\n",
      "Epoch 64/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5718 - accuracy: 0.6857 - val_loss: 0.6218 - val_accuracy: 0.6222\n",
      "Epoch 65/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5651 - accuracy: 0.6857 - val_loss: 0.6150 - val_accuracy: 0.6222\n",
      "Epoch 66/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.5584 - accuracy: 0.6857 - val_loss: 0.6083 - val_accuracy: 0.6222\n",
      "Epoch 67/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5519 - accuracy: 0.6857 - val_loss: 0.6017 - val_accuracy: 0.6222\n",
      "Epoch 68/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5455 - accuracy: 0.6857 - val_loss: 0.5953 - val_accuracy: 0.6222\n",
      "Epoch 69/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5393 - accuracy: 0.6857 - val_loss: 0.5889 - val_accuracy: 0.6222\n",
      "Epoch 70/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5332 - accuracy: 0.6857 - val_loss: 0.5826 - val_accuracy: 0.6222\n",
      "Epoch 71/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5272 - accuracy: 0.6857 - val_loss: 0.5764 - val_accuracy: 0.6222\n",
      "Epoch 72/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5214 - accuracy: 0.6857 - val_loss: 0.5703 - val_accuracy: 0.6222\n",
      "Epoch 73/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.5156 - accuracy: 0.6857 - val_loss: 0.5643 - val_accuracy: 0.6222\n",
      "Epoch 74/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.5101 - accuracy: 0.6857 - val_loss: 0.5584 - val_accuracy: 0.6222\n",
      "Epoch 75/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5046 - accuracy: 0.6857 - val_loss: 0.5526 - val_accuracy: 0.6222\n",
      "Epoch 76/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4993 - accuracy: 0.6857 - val_loss: 0.5469 - val_accuracy: 0.6222\n",
      "Epoch 77/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.4941 - accuracy: 0.6857 - val_loss: 0.5412 - val_accuracy: 0.6222\n",
      "Epoch 78/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4890 - accuracy: 0.6952 - val_loss: 0.5356 - val_accuracy: 0.6222\n",
      "Epoch 79/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4840 - accuracy: 0.6952 - val_loss: 0.5301 - val_accuracy: 0.6222\n",
      "Epoch 80/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4791 - accuracy: 0.7048 - val_loss: 0.5248 - val_accuracy: 0.6222\n",
      "Epoch 81/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4742 - accuracy: 0.7143 - val_loss: 0.5194 - val_accuracy: 0.6444\n",
      "Epoch 82/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4695 - accuracy: 0.7238 - val_loss: 0.5142 - val_accuracy: 0.6444\n",
      "Epoch 83/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.4649 - accuracy: 0.7333 - val_loss: 0.5091 - val_accuracy: 0.6667\n",
      "Epoch 84/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.4604 - accuracy: 0.7333 - val_loss: 0.5041 - val_accuracy: 0.6667\n",
      "Epoch 85/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.4559 - accuracy: 0.7333 - val_loss: 0.4991 - val_accuracy: 0.6667\n",
      "Epoch 86/500\n",
      "1/1 [==============================] - 0s 74ms/step - loss: 0.4515 - accuracy: 0.7429 - val_loss: 0.4942 - val_accuracy: 0.6889\n",
      "Epoch 87/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.4472 - accuracy: 0.7429 - val_loss: 0.4894 - val_accuracy: 0.6889\n",
      "Epoch 88/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4430 - accuracy: 0.7524 - val_loss: 0.4846 - val_accuracy: 0.6889\n",
      "Epoch 89/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.4389 - accuracy: 0.7714 - val_loss: 0.4799 - val_accuracy: 0.6889\n",
      "Epoch 90/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4348 - accuracy: 0.7714 - val_loss: 0.4753 - val_accuracy: 0.6889\n",
      "Epoch 91/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4307 - accuracy: 0.7714 - val_loss: 0.4707 - val_accuracy: 0.7111\n",
      "Epoch 92/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4268 - accuracy: 0.8095 - val_loss: 0.4661 - val_accuracy: 0.7111\n",
      "Epoch 93/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4228 - accuracy: 0.8381 - val_loss: 0.4616 - val_accuracy: 0.7333\n",
      "Epoch 94/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4189 - accuracy: 0.8381 - val_loss: 0.4572 - val_accuracy: 0.7333\n",
      "Epoch 95/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4151 - accuracy: 0.8381 - val_loss: 0.4528 - val_accuracy: 0.7778\n",
      "Epoch 96/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4113 - accuracy: 0.8476 - val_loss: 0.4485 - val_accuracy: 0.7778\n",
      "Epoch 97/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4075 - accuracy: 0.8667 - val_loss: 0.4442 - val_accuracy: 0.7778\n",
      "Epoch 98/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4038 - accuracy: 0.8857 - val_loss: 0.4400 - val_accuracy: 0.8444\n",
      "Epoch 99/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.4002 - accuracy: 0.8857 - val_loss: 0.4358 - val_accuracy: 0.8667\n",
      "Epoch 100/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3965 - accuracy: 0.8952 - val_loss: 0.4317 - val_accuracy: 0.8667\n",
      "Epoch 101/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3929 - accuracy: 0.8952 - val_loss: 0.4276 - val_accuracy: 0.8667\n",
      "Epoch 102/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3894 - accuracy: 0.9048 - val_loss: 0.4235 - val_accuracy: 0.8889\n",
      "Epoch 103/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3858 - accuracy: 0.9048 - val_loss: 0.4195 - val_accuracy: 0.9111\n",
      "Epoch 104/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3823 - accuracy: 0.9048 - val_loss: 0.4155 - val_accuracy: 0.9111\n",
      "Epoch 105/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3788 - accuracy: 0.9048 - val_loss: 0.4116 - val_accuracy: 0.9111\n",
      "Epoch 106/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3753 - accuracy: 0.9143 - val_loss: 0.4077 - val_accuracy: 0.9111\n",
      "Epoch 107/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3719 - accuracy: 0.9238 - val_loss: 0.4039 - val_accuracy: 0.9111\n",
      "Epoch 108/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3684 - accuracy: 0.9238 - val_loss: 0.4000 - val_accuracy: 0.9111\n",
      "Epoch 109/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3650 - accuracy: 0.9238 - val_loss: 0.3963 - val_accuracy: 0.9111\n",
      "Epoch 110/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.3616 - accuracy: 0.9238 - val_loss: 0.3925 - val_accuracy: 0.9111\n",
      "Epoch 111/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3582 - accuracy: 0.9238 - val_loss: 0.3888 - val_accuracy: 0.9111\n",
      "Epoch 112/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.3548 - accuracy: 0.9333 - val_loss: 0.3851 - val_accuracy: 0.9111\n",
      "Epoch 113/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3515 - accuracy: 0.9429 - val_loss: 0.3814 - val_accuracy: 0.9111\n",
      "Epoch 114/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3481 - accuracy: 0.9429 - val_loss: 0.3777 - val_accuracy: 0.9111\n",
      "Epoch 115/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3448 - accuracy: 0.9429 - val_loss: 0.3741 - val_accuracy: 0.9111\n",
      "Epoch 116/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3415 - accuracy: 0.9524 - val_loss: 0.3706 - val_accuracy: 0.9111\n",
      "Epoch 117/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3382 - accuracy: 0.9524 - val_loss: 0.3670 - val_accuracy: 0.9111\n",
      "Epoch 118/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3350 - accuracy: 0.9524 - val_loss: 0.3635 - val_accuracy: 0.9111\n",
      "Epoch 119/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3318 - accuracy: 0.9524 - val_loss: 0.3599 - val_accuracy: 0.9111\n",
      "Epoch 120/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3286 - accuracy: 0.9524 - val_loss: 0.3563 - val_accuracy: 0.9111\n",
      "Epoch 121/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3253 - accuracy: 0.9524 - val_loss: 0.3527 - val_accuracy: 0.9111\n",
      "Epoch 122/500\n",
      "1/1 [==============================] - 0s 67ms/step - loss: 0.3222 - accuracy: 0.9524 - val_loss: 0.3491 - val_accuracy: 0.9111\n",
      "Epoch 123/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3190 - accuracy: 0.9524 - val_loss: 0.3455 - val_accuracy: 0.9111\n",
      "Epoch 124/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.3158 - accuracy: 0.9524 - val_loss: 0.3419 - val_accuracy: 0.9111\n",
      "Epoch 125/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.3127 - accuracy: 0.9524 - val_loss: 0.3384 - val_accuracy: 0.9111\n",
      "Epoch 126/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3095 - accuracy: 0.9524 - val_loss: 0.3349 - val_accuracy: 0.9111\n",
      "Epoch 127/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3064 - accuracy: 0.9524 - val_loss: 0.3315 - val_accuracy: 0.9111\n",
      "Epoch 128/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3033 - accuracy: 0.9524 - val_loss: 0.3281 - val_accuracy: 0.9333\n",
      "Epoch 129/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3002 - accuracy: 0.9524 - val_loss: 0.3247 - val_accuracy: 0.9333\n",
      "Epoch 130/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.2972 - accuracy: 0.9619 - val_loss: 0.3214 - val_accuracy: 0.9333\n",
      "Epoch 131/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.2941 - accuracy: 0.9619 - val_loss: 0.3182 - val_accuracy: 0.9333\n",
      "Epoch 132/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2911 - accuracy: 0.9619 - val_loss: 0.3149 - val_accuracy: 0.9333\n",
      "Epoch 133/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2880 - accuracy: 0.9619 - val_loss: 0.3117 - val_accuracy: 0.9333\n",
      "Epoch 134/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2850 - accuracy: 0.9619 - val_loss: 0.3084 - val_accuracy: 0.9333\n",
      "Epoch 135/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2821 - accuracy: 0.9619 - val_loss: 0.3051 - val_accuracy: 0.9333\n",
      "Epoch 136/500\n",
      "1/1 [==============================] - 0s 64ms/step - loss: 0.2791 - accuracy: 0.9619 - val_loss: 0.3018 - val_accuracy: 0.9333\n",
      "Epoch 137/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2761 - accuracy: 0.9619 - val_loss: 0.2985 - val_accuracy: 0.9333\n",
      "Epoch 138/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2732 - accuracy: 0.9619 - val_loss: 0.2952 - val_accuracy: 0.9333\n",
      "Epoch 139/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2703 - accuracy: 0.9619 - val_loss: 0.2920 - val_accuracy: 0.9333\n",
      "Epoch 140/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2674 - accuracy: 0.9714 - val_loss: 0.2888 - val_accuracy: 0.9333\n",
      "Epoch 141/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2646 - accuracy: 0.9714 - val_loss: 0.2856 - val_accuracy: 0.9333\n",
      "Epoch 142/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.2617 - accuracy: 0.9714 - val_loss: 0.2825 - val_accuracy: 0.9333\n",
      "Epoch 143/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2589 - accuracy: 0.9714 - val_loss: 0.2793 - val_accuracy: 0.9333\n",
      "Epoch 144/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.2561 - accuracy: 0.9714 - val_loss: 0.2762 - val_accuracy: 0.9333\n",
      "Epoch 145/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.2534 - accuracy: 0.9714 - val_loss: 0.2731 - val_accuracy: 0.9333\n",
      "Epoch 146/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2506 - accuracy: 0.9714 - val_loss: 0.2701 - val_accuracy: 0.9333\n",
      "Epoch 147/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2479 - accuracy: 0.9714 - val_loss: 0.2670 - val_accuracy: 0.9333\n",
      "Epoch 148/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2452 - accuracy: 0.9714 - val_loss: 0.2641 - val_accuracy: 0.9333\n",
      "Epoch 149/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2425 - accuracy: 0.9714 - val_loss: 0.2611 - val_accuracy: 0.9333\n",
      "Epoch 150/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2398 - accuracy: 0.9714 - val_loss: 0.2582 - val_accuracy: 0.9333\n",
      "Epoch 151/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2372 - accuracy: 0.9714 - val_loss: 0.2553 - val_accuracy: 0.9333\n",
      "Epoch 152/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2346 - accuracy: 0.9714 - val_loss: 0.2525 - val_accuracy: 0.9333\n",
      "Epoch 153/500\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.2320 - accuracy: 0.9714 - val_loss: 0.2496 - val_accuracy: 0.9333\n",
      "Epoch 154/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2295 - accuracy: 0.9714 - val_loss: 0.2468 - val_accuracy: 0.9333\n",
      "Epoch 155/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2270 - accuracy: 0.9714 - val_loss: 0.2440 - val_accuracy: 0.9333\n",
      "Epoch 156/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.2245 - accuracy: 0.9714 - val_loss: 0.2413 - val_accuracy: 0.9333\n",
      "Epoch 157/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2221 - accuracy: 0.9714 - val_loss: 0.2385 - val_accuracy: 0.9333\n",
      "Epoch 158/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2196 - accuracy: 0.9714 - val_loss: 0.2357 - val_accuracy: 0.9556\n",
      "Epoch 159/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2172 - accuracy: 0.9714 - val_loss: 0.2329 - val_accuracy: 0.9556\n",
      "Epoch 160/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2149 - accuracy: 0.9714 - val_loss: 0.2301 - val_accuracy: 0.9556\n",
      "Epoch 161/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2125 - accuracy: 0.9714 - val_loss: 0.2275 - val_accuracy: 0.9556\n",
      "Epoch 162/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2102 - accuracy: 0.9714 - val_loss: 0.2249 - val_accuracy: 0.9556\n",
      "Epoch 163/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2079 - accuracy: 0.9714 - val_loss: 0.2223 - val_accuracy: 0.9556\n",
      "Epoch 164/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.2057 - accuracy: 0.9714 - val_loss: 0.2198 - val_accuracy: 0.9556\n",
      "Epoch 165/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2035 - accuracy: 0.9714 - val_loss: 0.2173 - val_accuracy: 0.9556\n",
      "Epoch 166/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.2013 - accuracy: 0.9714 - val_loss: 0.2148 - val_accuracy: 0.9556\n",
      "Epoch 167/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1991 - accuracy: 0.9714 - val_loss: 0.2124 - val_accuracy: 0.9556\n",
      "Epoch 168/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1970 - accuracy: 0.9714 - val_loss: 0.2099 - val_accuracy: 0.9556\n",
      "Epoch 169/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1949 - accuracy: 0.9714 - val_loss: 0.2075 - val_accuracy: 0.9556\n",
      "Epoch 170/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1928 - accuracy: 0.9714 - val_loss: 0.2051 - val_accuracy: 0.9556\n",
      "Epoch 171/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1908 - accuracy: 0.9714 - val_loss: 0.2027 - val_accuracy: 0.9556\n",
      "Epoch 172/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1888 - accuracy: 0.9714 - val_loss: 0.2004 - val_accuracy: 0.9556\n",
      "Epoch 173/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1868 - accuracy: 0.9714 - val_loss: 0.1982 - val_accuracy: 0.9556\n",
      "Epoch 174/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1848 - accuracy: 0.9714 - val_loss: 0.1959 - val_accuracy: 0.9556\n",
      "Epoch 175/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1829 - accuracy: 0.9714 - val_loss: 0.1937 - val_accuracy: 0.9556\n",
      "Epoch 176/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1810 - accuracy: 0.9714 - val_loss: 0.1916 - val_accuracy: 0.9556\n",
      "Epoch 177/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1791 - accuracy: 0.9714 - val_loss: 0.1894 - val_accuracy: 0.9556\n",
      "Epoch 178/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1773 - accuracy: 0.9714 - val_loss: 0.1872 - val_accuracy: 0.9556\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1755 - accuracy: 0.9714 - val_loss: 0.1850 - val_accuracy: 0.9556\n",
      "Epoch 180/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.1737 - accuracy: 0.9714 - val_loss: 0.1829 - val_accuracy: 0.9556\n",
      "Epoch 181/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1720 - accuracy: 0.9714 - val_loss: 0.1808 - val_accuracy: 0.9556\n",
      "Epoch 182/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1703 - accuracy: 0.9714 - val_loss: 0.1787 - val_accuracy: 0.9556\n",
      "Epoch 183/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1686 - accuracy: 0.9714 - val_loss: 0.1767 - val_accuracy: 0.9556\n",
      "Epoch 184/500\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.1669 - accuracy: 0.9714 - val_loss: 0.1748 - val_accuracy: 0.9556\n",
      "Epoch 185/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.1653 - accuracy: 0.9714 - val_loss: 0.1729 - val_accuracy: 0.9556\n",
      "Epoch 186/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1637 - accuracy: 0.9714 - val_loss: 0.1710 - val_accuracy: 0.9556\n",
      "Epoch 187/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1621 - accuracy: 0.9714 - val_loss: 0.1691 - val_accuracy: 0.9778\n",
      "Epoch 188/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.1605 - accuracy: 0.9714 - val_loss: 0.1671 - val_accuracy: 0.9778\n",
      "Epoch 189/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1589 - accuracy: 0.9714 - val_loss: 0.1652 - val_accuracy: 0.9778\n",
      "Epoch 190/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1574 - accuracy: 0.9714 - val_loss: 0.1633 - val_accuracy: 0.9778\n",
      "Epoch 191/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1559 - accuracy: 0.9714 - val_loss: 0.1614 - val_accuracy: 0.9778\n",
      "Epoch 192/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1544 - accuracy: 0.9714 - val_loss: 0.1596 - val_accuracy: 0.9778\n",
      "Epoch 193/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1530 - accuracy: 0.9714 - val_loss: 0.1579 - val_accuracy: 0.9778\n",
      "Epoch 194/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1516 - accuracy: 0.9714 - val_loss: 0.1562 - val_accuracy: 0.9778\n",
      "Epoch 195/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1502 - accuracy: 0.9714 - val_loss: 0.1546 - val_accuracy: 0.9778\n",
      "Epoch 196/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1488 - accuracy: 0.9714 - val_loss: 0.1530 - val_accuracy: 0.9778\n",
      "Epoch 197/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1474 - accuracy: 0.9714 - val_loss: 0.1514 - val_accuracy: 0.9778\n",
      "Epoch 198/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1461 - accuracy: 0.9714 - val_loss: 0.1498 - val_accuracy: 0.9778\n",
      "Epoch 199/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1448 - accuracy: 0.9714 - val_loss: 0.1482 - val_accuracy: 0.9778\n",
      "Epoch 200/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1435 - accuracy: 0.9714 - val_loss: 0.1466 - val_accuracy: 0.9778\n",
      "Epoch 201/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1423 - accuracy: 0.9714 - val_loss: 0.1450 - val_accuracy: 0.9778\n",
      "Epoch 202/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1411 - accuracy: 0.9714 - val_loss: 0.1435 - val_accuracy: 0.9778\n",
      "Epoch 203/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.1398 - accuracy: 0.9714 - val_loss: 0.1419 - val_accuracy: 0.9778\n",
      "Epoch 204/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1387 - accuracy: 0.9714 - val_loss: 0.1404 - val_accuracy: 0.9778\n",
      "Epoch 205/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.1375 - accuracy: 0.9714 - val_loss: 0.1390 - val_accuracy: 0.9778\n",
      "Epoch 206/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1363 - accuracy: 0.9714 - val_loss: 0.1376 - val_accuracy: 0.9778\n",
      "Epoch 207/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.1352 - accuracy: 0.9714 - val_loss: 0.1362 - val_accuracy: 0.9778\n",
      "Epoch 208/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1341 - accuracy: 0.9714 - val_loss: 0.1348 - val_accuracy: 0.9778\n",
      "Epoch 209/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1330 - accuracy: 0.9714 - val_loss: 0.1335 - val_accuracy: 0.9778\n",
      "Epoch 210/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1319 - accuracy: 0.9714 - val_loss: 0.1322 - val_accuracy: 0.9778\n",
      "Epoch 211/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1309 - accuracy: 0.9714 - val_loss: 0.1308 - val_accuracy: 0.9778\n",
      "Epoch 212/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1298 - accuracy: 0.9714 - val_loss: 0.1295 - val_accuracy: 0.9778\n",
      "Epoch 213/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1288 - accuracy: 0.9619 - val_loss: 0.1282 - val_accuracy: 0.9778\n",
      "Epoch 214/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1278 - accuracy: 0.9619 - val_loss: 0.1269 - val_accuracy: 0.9778\n",
      "Epoch 215/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1268 - accuracy: 0.9619 - val_loss: 0.1256 - val_accuracy: 0.9778\n",
      "Epoch 216/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1259 - accuracy: 0.9619 - val_loss: 0.1243 - val_accuracy: 0.9778\n",
      "Epoch 217/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1249 - accuracy: 0.9619 - val_loss: 0.1231 - val_accuracy: 0.9778\n",
      "Epoch 218/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.1240 - accuracy: 0.9619 - val_loss: 0.1220 - val_accuracy: 0.9778\n",
      "Epoch 219/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1230 - accuracy: 0.9619 - val_loss: 0.1209 - val_accuracy: 0.9778\n",
      "Epoch 220/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.1221 - accuracy: 0.9619 - val_loss: 0.1197 - val_accuracy: 0.9778\n",
      "Epoch 221/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1212 - accuracy: 0.9619 - val_loss: 0.1186 - val_accuracy: 0.9778\n",
      "Epoch 222/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1203 - accuracy: 0.9619 - val_loss: 0.1174 - val_accuracy: 0.9778\n",
      "Epoch 223/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1195 - accuracy: 0.9619 - val_loss: 0.1162 - val_accuracy: 0.9778\n",
      "Epoch 224/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.1186 - accuracy: 0.9619 - val_loss: 0.1150 - val_accuracy: 0.9778\n",
      "Epoch 225/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1178 - accuracy: 0.9619 - val_loss: 0.1139 - val_accuracy: 0.9778\n",
      "Epoch 226/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1169 - accuracy: 0.9619 - val_loss: 0.1128 - val_accuracy: 0.9778\n",
      "Epoch 227/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1161 - accuracy: 0.9619 - val_loss: 0.1117 - val_accuracy: 0.9778\n",
      "Epoch 228/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1153 - accuracy: 0.9619 - val_loss: 0.1107 - val_accuracy: 0.9778\n",
      "Epoch 229/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1145 - accuracy: 0.9619 - val_loss: 0.1096 - val_accuracy: 0.9778\n",
      "Epoch 230/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1138 - accuracy: 0.9619 - val_loss: 0.1086 - val_accuracy: 0.9778\n",
      "Epoch 231/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1130 - accuracy: 0.9619 - val_loss: 0.1076 - val_accuracy: 0.9778\n",
      "Epoch 232/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1122 - accuracy: 0.9619 - val_loss: 0.1065 - val_accuracy: 0.9778\n",
      "Epoch 233/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1115 - accuracy: 0.9619 - val_loss: 0.1055 - val_accuracy: 0.9778\n",
      "Epoch 234/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1108 - accuracy: 0.9619 - val_loss: 0.1045 - val_accuracy: 0.9778\n",
      "Epoch 235/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.1101 - accuracy: 0.9619 - val_loss: 0.1035 - val_accuracy: 0.9778\n",
      "Epoch 236/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.1094 - accuracy: 0.9619 - val_loss: 0.1026 - val_accuracy: 0.9778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 237/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1087 - accuracy: 0.9619 - val_loss: 0.1017 - val_accuracy: 0.9778\n",
      "Epoch 238/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.1080 - accuracy: 0.9619 - val_loss: 0.1008 - val_accuracy: 0.9778\n",
      "Epoch 239/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1074 - accuracy: 0.9619 - val_loss: 0.0999 - val_accuracy: 0.9778\n",
      "Epoch 240/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1067 - accuracy: 0.9619 - val_loss: 0.0991 - val_accuracy: 0.9778\n",
      "Epoch 241/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.1061 - accuracy: 0.9619 - val_loss: 0.0982 - val_accuracy: 0.9778\n",
      "Epoch 242/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.1054 - accuracy: 0.9619 - val_loss: 0.0973 - val_accuracy: 0.9778\n",
      "Epoch 243/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.1048 - accuracy: 0.9619 - val_loss: 0.0964 - val_accuracy: 0.9778\n",
      "Epoch 244/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1042 - accuracy: 0.9619 - val_loss: 0.0955 - val_accuracy: 0.9778\n",
      "Epoch 245/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.1036 - accuracy: 0.9619 - val_loss: 0.0947 - val_accuracy: 0.9778\n",
      "Epoch 246/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.1030 - accuracy: 0.9619 - val_loss: 0.0939 - val_accuracy: 0.9778\n",
      "Epoch 247/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1024 - accuracy: 0.9619 - val_loss: 0.0931 - val_accuracy: 0.9778\n",
      "Epoch 248/500\n",
      "1/1 [==============================] - 0s 66ms/step - loss: 0.1018 - accuracy: 0.9619 - val_loss: 0.0924 - val_accuracy: 0.9778\n",
      "Epoch 249/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.1012 - accuracy: 0.9619 - val_loss: 0.0916 - val_accuracy: 0.9778\n",
      "Epoch 250/500\n",
      "1/1 [==============================] - 0s 57ms/step - loss: 0.1007 - accuracy: 0.9619 - val_loss: 0.0908 - val_accuracy: 0.9778\n",
      "Epoch 251/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.1001 - accuracy: 0.9619 - val_loss: 0.0900 - val_accuracy: 0.9778\n",
      "Epoch 252/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0996 - accuracy: 0.9619 - val_loss: 0.0893 - val_accuracy: 0.9778\n",
      "Epoch 253/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0991 - accuracy: 0.9619 - val_loss: 0.0885 - val_accuracy: 0.9778\n",
      "Epoch 254/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0985 - accuracy: 0.9619 - val_loss: 0.0878 - val_accuracy: 0.9778\n",
      "Epoch 255/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0980 - accuracy: 0.9619 - val_loss: 0.0871 - val_accuracy: 0.9778\n",
      "Epoch 256/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0975 - accuracy: 0.9619 - val_loss: 0.0864 - val_accuracy: 0.9778\n",
      "Epoch 257/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0970 - accuracy: 0.9619 - val_loss: 0.0857 - val_accuracy: 0.9778\n",
      "Epoch 258/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0965 - accuracy: 0.9619 - val_loss: 0.0850 - val_accuracy: 0.9778\n",
      "Epoch 259/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0960 - accuracy: 0.9619 - val_loss: 0.0844 - val_accuracy: 0.9778\n",
      "Epoch 260/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0955 - accuracy: 0.9619 - val_loss: 0.0837 - val_accuracy: 0.9778\n",
      "Epoch 261/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0950 - accuracy: 0.9619 - val_loss: 0.0831 - val_accuracy: 0.9778\n",
      "Epoch 262/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0946 - accuracy: 0.9619 - val_loss: 0.0824 - val_accuracy: 0.9778\n",
      "Epoch 263/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0941 - accuracy: 0.9619 - val_loss: 0.0818 - val_accuracy: 0.9778\n",
      "Epoch 264/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0936 - accuracy: 0.9619 - val_loss: 0.0812 - val_accuracy: 0.9778\n",
      "Epoch 265/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0932 - accuracy: 0.9619 - val_loss: 0.0805 - val_accuracy: 0.9778\n",
      "Epoch 266/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0928 - accuracy: 0.9619 - val_loss: 0.0799 - val_accuracy: 0.9778\n",
      "Epoch 267/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0923 - accuracy: 0.9619 - val_loss: 0.0792 - val_accuracy: 0.9778\n",
      "Epoch 268/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0919 - accuracy: 0.9619 - val_loss: 0.0787 - val_accuracy: 0.9778\n",
      "Epoch 269/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0915 - accuracy: 0.9619 - val_loss: 0.0781 - val_accuracy: 0.9778\n",
      "Epoch 270/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0910 - accuracy: 0.9619 - val_loss: 0.0776 - val_accuracy: 0.9778\n",
      "Epoch 271/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0906 - accuracy: 0.9619 - val_loss: 0.0770 - val_accuracy: 0.9778\n",
      "Epoch 272/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0902 - accuracy: 0.9619 - val_loss: 0.0765 - val_accuracy: 0.9778\n",
      "Epoch 273/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0898 - accuracy: 0.9619 - val_loss: 0.0760 - val_accuracy: 0.9778\n",
      "Epoch 274/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0894 - accuracy: 0.9619 - val_loss: 0.0755 - val_accuracy: 0.9778\n",
      "Epoch 275/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0890 - accuracy: 0.9619 - val_loss: 0.0749 - val_accuracy: 0.9778\n",
      "Epoch 276/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0886 - accuracy: 0.9619 - val_loss: 0.0743 - val_accuracy: 0.9778\n",
      "Epoch 277/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0883 - accuracy: 0.9619 - val_loss: 0.0738 - val_accuracy: 0.9778\n",
      "Epoch 278/500\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.0879 - accuracy: 0.9619 - val_loss: 0.0732 - val_accuracy: 0.9778\n",
      "Epoch 279/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0875 - accuracy: 0.9619 - val_loss: 0.0727 - val_accuracy: 0.9778\n",
      "Epoch 280/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0872 - accuracy: 0.9619 - val_loss: 0.0723 - val_accuracy: 0.9778\n",
      "Epoch 281/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0868 - accuracy: 0.9619 - val_loss: 0.0718 - val_accuracy: 0.9778\n",
      "Epoch 282/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0864 - accuracy: 0.9619 - val_loss: 0.0713 - val_accuracy: 0.9778\n",
      "Epoch 283/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0861 - accuracy: 0.9619 - val_loss: 0.0708 - val_accuracy: 0.9778\n",
      "Epoch 284/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0857 - accuracy: 0.9619 - val_loss: 0.0703 - val_accuracy: 0.9778\n",
      "Epoch 285/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0854 - accuracy: 0.9619 - val_loss: 0.0698 - val_accuracy: 0.9778\n",
      "Epoch 286/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0851 - accuracy: 0.9619 - val_loss: 0.0693 - val_accuracy: 0.9778\n",
      "Epoch 287/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0847 - accuracy: 0.9619 - val_loss: 0.0688 - val_accuracy: 0.9778\n",
      "Epoch 288/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0844 - accuracy: 0.9619 - val_loss: 0.0684 - val_accuracy: 0.9778\n",
      "Epoch 289/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0841 - accuracy: 0.9619 - val_loss: 0.0680 - val_accuracy: 0.9778\n",
      "Epoch 290/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0838 - accuracy: 0.9619 - val_loss: 0.0676 - val_accuracy: 0.9778\n",
      "Epoch 291/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0834 - accuracy: 0.9619 - val_loss: 0.0672 - val_accuracy: 0.9778\n",
      "Epoch 292/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0831 - accuracy: 0.9619 - val_loss: 0.0667 - val_accuracy: 0.9778\n",
      "Epoch 293/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0828 - accuracy: 0.9619 - val_loss: 0.0662 - val_accuracy: 0.9778\n",
      "Epoch 294/500\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.0825 - accuracy: 0.9714 - val_loss: 0.0657 - val_accuracy: 0.9778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 295/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0822 - accuracy: 0.9714 - val_loss: 0.0653 - val_accuracy: 0.9778\n",
      "Epoch 296/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0819 - accuracy: 0.9714 - val_loss: 0.0649 - val_accuracy: 0.9778\n",
      "Epoch 297/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0816 - accuracy: 0.9714 - val_loss: 0.0645 - val_accuracy: 0.9778\n",
      "Epoch 298/500\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.0813 - accuracy: 0.9714 - val_loss: 0.0641 - val_accuracy: 0.9778\n",
      "Epoch 299/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0810 - accuracy: 0.9714 - val_loss: 0.0638 - val_accuracy: 0.9778\n",
      "Epoch 300/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0808 - accuracy: 0.9714 - val_loss: 0.0634 - val_accuracy: 0.9778\n",
      "Epoch 301/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0805 - accuracy: 0.9714 - val_loss: 0.0631 - val_accuracy: 0.9778\n",
      "Epoch 302/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0802 - accuracy: 0.9714 - val_loss: 0.0626 - val_accuracy: 0.9778\n",
      "Epoch 303/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0799 - accuracy: 0.9714 - val_loss: 0.0622 - val_accuracy: 0.9778\n",
      "Epoch 304/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0797 - accuracy: 0.9714 - val_loss: 0.0618 - val_accuracy: 0.9778\n",
      "Epoch 305/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0794 - accuracy: 0.9714 - val_loss: 0.0614 - val_accuracy: 0.9778\n",
      "Epoch 306/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0791 - accuracy: 0.9714 - val_loss: 0.0611 - val_accuracy: 0.9778\n",
      "Epoch 307/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0789 - accuracy: 0.9714 - val_loss: 0.0607 - val_accuracy: 0.9778\n",
      "Epoch 308/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0786 - accuracy: 0.9714 - val_loss: 0.0604 - val_accuracy: 0.9778\n",
      "Epoch 309/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0784 - accuracy: 0.9714 - val_loss: 0.0601 - val_accuracy: 0.9778\n",
      "Epoch 310/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0781 - accuracy: 0.9714 - val_loss: 0.0597 - val_accuracy: 0.9778\n",
      "Epoch 311/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0779 - accuracy: 0.9714 - val_loss: 0.0594 - val_accuracy: 0.9778\n",
      "Epoch 312/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0776 - accuracy: 0.9714 - val_loss: 0.0590 - val_accuracy: 0.9778\n",
      "Epoch 313/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0774 - accuracy: 0.9714 - val_loss: 0.0586 - val_accuracy: 0.9778\n",
      "Epoch 314/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0771 - accuracy: 0.9714 - val_loss: 0.0583 - val_accuracy: 0.9778\n",
      "Epoch 315/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0769 - accuracy: 0.9714 - val_loss: 0.0580 - val_accuracy: 0.9778\n",
      "Epoch 316/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0766 - accuracy: 0.9714 - val_loss: 0.0577 - val_accuracy: 0.9778\n",
      "Epoch 317/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0764 - accuracy: 0.9714 - val_loss: 0.0574 - val_accuracy: 0.9778\n",
      "Epoch 318/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0762 - accuracy: 0.9714 - val_loss: 0.0571 - val_accuracy: 0.9778\n",
      "Epoch 319/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0760 - accuracy: 0.9714 - val_loss: 0.0568 - val_accuracy: 0.9778\n",
      "Epoch 320/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0757 - accuracy: 0.9714 - val_loss: 0.0564 - val_accuracy: 0.9778\n",
      "Epoch 321/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0755 - accuracy: 0.9714 - val_loss: 0.0561 - val_accuracy: 0.9778\n",
      "Epoch 322/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0753 - accuracy: 0.9714 - val_loss: 0.0558 - val_accuracy: 0.9778\n",
      "Epoch 323/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0751 - accuracy: 0.9810 - val_loss: 0.0555 - val_accuracy: 0.9778\n",
      "Epoch 324/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0749 - accuracy: 0.9810 - val_loss: 0.0552 - val_accuracy: 0.9778\n",
      "Epoch 325/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0746 - accuracy: 0.9810 - val_loss: 0.0549 - val_accuracy: 0.9778\n",
      "Epoch 326/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0744 - accuracy: 0.9810 - val_loss: 0.0546 - val_accuracy: 0.9778\n",
      "Epoch 327/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0742 - accuracy: 0.9810 - val_loss: 0.0544 - val_accuracy: 0.9778\n",
      "Epoch 328/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0740 - accuracy: 0.9810 - val_loss: 0.0541 - val_accuracy: 0.9778\n",
      "Epoch 329/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0738 - accuracy: 0.9810 - val_loss: 0.0538 - val_accuracy: 0.9778\n",
      "Epoch 330/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0736 - accuracy: 0.9810 - val_loss: 0.0536 - val_accuracy: 0.9778\n",
      "Epoch 331/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0734 - accuracy: 0.9810 - val_loss: 0.0533 - val_accuracy: 0.9778\n",
      "Epoch 332/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0732 - accuracy: 0.9810 - val_loss: 0.0530 - val_accuracy: 0.9778\n",
      "Epoch 333/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0730 - accuracy: 0.9810 - val_loss: 0.0527 - val_accuracy: 0.9778\n",
      "Epoch 334/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0728 - accuracy: 0.9810 - val_loss: 0.0525 - val_accuracy: 0.9778\n",
      "Epoch 335/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0727 - accuracy: 0.9810 - val_loss: 0.0522 - val_accuracy: 0.9778\n",
      "Epoch 336/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0725 - accuracy: 0.9810 - val_loss: 0.0520 - val_accuracy: 0.9778\n",
      "Epoch 337/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0723 - accuracy: 0.9810 - val_loss: 0.0517 - val_accuracy: 0.9778\n",
      "Epoch 338/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0721 - accuracy: 0.9810 - val_loss: 0.0515 - val_accuracy: 0.9778\n",
      "Epoch 339/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0719 - accuracy: 0.9810 - val_loss: 0.0512 - val_accuracy: 0.9778\n",
      "Epoch 340/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0717 - accuracy: 0.9810 - val_loss: 0.0509 - val_accuracy: 0.9778\n",
      "Epoch 341/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0715 - accuracy: 0.9810 - val_loss: 0.0507 - val_accuracy: 0.9778\n",
      "Epoch 342/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0714 - accuracy: 0.9810 - val_loss: 0.0504 - val_accuracy: 0.9778\n",
      "Epoch 343/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0712 - accuracy: 0.9810 - val_loss: 0.0502 - val_accuracy: 0.9778\n",
      "Epoch 344/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0710 - accuracy: 0.9810 - val_loss: 0.0500 - val_accuracy: 0.9778\n",
      "Epoch 345/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0709 - accuracy: 0.9810 - val_loss: 0.0498 - val_accuracy: 0.9778\n",
      "Epoch 346/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0707 - accuracy: 0.9810 - val_loss: 0.0496 - val_accuracy: 0.9778\n",
      "Epoch 347/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0705 - accuracy: 0.9810 - val_loss: 0.0494 - val_accuracy: 0.9778\n",
      "Epoch 348/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0704 - accuracy: 0.9810 - val_loss: 0.0491 - val_accuracy: 0.9778\n",
      "Epoch 349/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0702 - accuracy: 0.9810 - val_loss: 0.0489 - val_accuracy: 0.9778\n",
      "Epoch 350/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0700 - accuracy: 0.9810 - val_loss: 0.0486 - val_accuracy: 0.9778\n",
      "Epoch 351/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0699 - accuracy: 0.9810 - val_loss: 0.0484 - val_accuracy: 0.9778\n",
      "Epoch 352/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0697 - accuracy: 0.9810 - val_loss: 0.0482 - val_accuracy: 0.9778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 353/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0695 - accuracy: 0.9810 - val_loss: 0.0480 - val_accuracy: 0.9778\n",
      "Epoch 354/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0694 - accuracy: 0.9810 - val_loss: 0.0478 - val_accuracy: 0.9778\n",
      "Epoch 355/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0692 - accuracy: 0.9810 - val_loss: 0.0476 - val_accuracy: 0.9778\n",
      "Epoch 356/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0691 - accuracy: 0.9810 - val_loss: 0.0474 - val_accuracy: 0.9778\n",
      "Epoch 357/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0689 - accuracy: 0.9810 - val_loss: 0.0472 - val_accuracy: 0.9778\n",
      "Epoch 358/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0688 - accuracy: 0.9810 - val_loss: 0.0470 - val_accuracy: 0.9778\n",
      "Epoch 359/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0686 - accuracy: 0.9810 - val_loss: 0.0468 - val_accuracy: 0.9778\n",
      "Epoch 360/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0685 - accuracy: 0.9810 - val_loss: 0.0466 - val_accuracy: 0.9778\n",
      "Epoch 361/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0683 - accuracy: 0.9810 - val_loss: 0.0464 - val_accuracy: 0.9778\n",
      "Epoch 362/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0682 - accuracy: 0.9810 - val_loss: 0.0462 - val_accuracy: 0.9778\n",
      "Epoch 363/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0680 - accuracy: 0.9810 - val_loss: 0.0460 - val_accuracy: 0.9778\n",
      "Epoch 364/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0679 - accuracy: 0.9810 - val_loss: 0.0458 - val_accuracy: 0.9778\n",
      "Epoch 365/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0678 - accuracy: 0.9810 - val_loss: 0.0456 - val_accuracy: 0.9778\n",
      "Epoch 366/500\n",
      "1/1 [==============================] - 0s 34ms/step - loss: 0.0676 - accuracy: 0.9810 - val_loss: 0.0454 - val_accuracy: 0.9778\n",
      "Epoch 367/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0675 - accuracy: 0.9810 - val_loss: 0.0452 - val_accuracy: 0.9778\n",
      "Epoch 368/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0674 - accuracy: 0.9810 - val_loss: 0.0450 - val_accuracy: 0.9778\n",
      "Epoch 369/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0672 - accuracy: 0.9810 - val_loss: 0.0449 - val_accuracy: 0.9778\n",
      "Epoch 370/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0671 - accuracy: 0.9810 - val_loss: 0.0447 - val_accuracy: 0.9778\n",
      "Epoch 371/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0670 - accuracy: 0.9810 - val_loss: 0.0445 - val_accuracy: 0.9778\n",
      "Epoch 372/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0668 - accuracy: 0.9810 - val_loss: 0.0443 - val_accuracy: 0.9778\n",
      "Epoch 373/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0667 - accuracy: 0.9810 - val_loss: 0.0441 - val_accuracy: 0.9778\n",
      "Epoch 374/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0666 - accuracy: 0.9810 - val_loss: 0.0439 - val_accuracy: 0.9778\n",
      "Epoch 375/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0664 - accuracy: 0.9810 - val_loss: 0.0438 - val_accuracy: 0.9778\n",
      "Epoch 376/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0663 - accuracy: 0.9810 - val_loss: 0.0436 - val_accuracy: 0.9778\n",
      "Epoch 377/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0662 - accuracy: 0.9810 - val_loss: 0.0435 - val_accuracy: 0.9778\n",
      "Epoch 378/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0661 - accuracy: 0.9810 - val_loss: 0.0433 - val_accuracy: 0.9778\n",
      "Epoch 379/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0659 - accuracy: 0.9810 - val_loss: 0.0431 - val_accuracy: 0.9778\n",
      "Epoch 380/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0658 - accuracy: 0.9810 - val_loss: 0.0429 - val_accuracy: 0.9778\n",
      "Epoch 381/500\n",
      "1/1 [==============================] - 0s 38ms/step - loss: 0.0657 - accuracy: 0.9810 - val_loss: 0.0428 - val_accuracy: 0.9778\n",
      "Epoch 382/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0656 - accuracy: 0.9810 - val_loss: 0.0426 - val_accuracy: 0.9778\n",
      "Epoch 383/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0655 - accuracy: 0.9810 - val_loss: 0.0425 - val_accuracy: 0.9778\n",
      "Epoch 384/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0653 - accuracy: 0.9810 - val_loss: 0.0423 - val_accuracy: 0.9778\n",
      "Epoch 385/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0652 - accuracy: 0.9810 - val_loss: 0.0422 - val_accuracy: 0.9778\n",
      "Epoch 386/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0651 - accuracy: 0.9810 - val_loss: 0.0420 - val_accuracy: 0.9778\n",
      "Epoch 387/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0650 - accuracy: 0.9810 - val_loss: 0.0419 - val_accuracy: 0.9778\n",
      "Epoch 388/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0649 - accuracy: 0.9810 - val_loss: 0.0417 - val_accuracy: 0.9778\n",
      "Epoch 389/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0648 - accuracy: 0.9810 - val_loss: 0.0416 - val_accuracy: 0.9778\n",
      "Epoch 390/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0647 - accuracy: 0.9810 - val_loss: 0.0414 - val_accuracy: 0.9778\n",
      "Epoch 391/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0646 - accuracy: 0.9810 - val_loss: 0.0413 - val_accuracy: 0.9778\n",
      "Epoch 392/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0644 - accuracy: 0.9810 - val_loss: 0.0412 - val_accuracy: 0.9778\n",
      "Epoch 393/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0643 - accuracy: 0.9810 - val_loss: 0.0410 - val_accuracy: 0.9778\n",
      "Epoch 394/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0642 - accuracy: 0.9810 - val_loss: 0.0409 - val_accuracy: 0.9778\n",
      "Epoch 395/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0641 - accuracy: 0.9810 - val_loss: 0.0407 - val_accuracy: 0.9778\n",
      "Epoch 396/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0640 - accuracy: 0.9810 - val_loss: 0.0406 - val_accuracy: 0.9778\n",
      "Epoch 397/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0639 - accuracy: 0.9810 - val_loss: 0.0404 - val_accuracy: 0.9778\n",
      "Epoch 398/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0638 - accuracy: 0.9810 - val_loss: 0.0403 - val_accuracy: 0.9778\n",
      "Epoch 399/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0637 - accuracy: 0.9810 - val_loss: 0.0401 - val_accuracy: 0.9778\n",
      "Epoch 400/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0636 - accuracy: 0.9810 - val_loss: 0.0400 - val_accuracy: 0.9778\n",
      "Epoch 401/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0635 - accuracy: 0.9810 - val_loss: 0.0399 - val_accuracy: 0.9778\n",
      "Epoch 402/500\n",
      "1/1 [==============================] - 0s 63ms/step - loss: 0.0634 - accuracy: 0.9810 - val_loss: 0.0398 - val_accuracy: 0.9778\n",
      "Epoch 403/500\n",
      "1/1 [==============================] - 0s 71ms/step - loss: 0.0633 - accuracy: 0.9810 - val_loss: 0.0397 - val_accuracy: 0.9778\n",
      "Epoch 404/500\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.0632 - accuracy: 0.9810 - val_loss: 0.0396 - val_accuracy: 0.9778\n",
      "Epoch 405/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0631 - accuracy: 0.9810 - val_loss: 0.0394 - val_accuracy: 0.9778\n",
      "Epoch 406/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0630 - accuracy: 0.9810 - val_loss: 0.0393 - val_accuracy: 0.9778\n",
      "Epoch 407/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0629 - accuracy: 0.9810 - val_loss: 0.0392 - val_accuracy: 0.9778\n",
      "Epoch 408/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0628 - accuracy: 0.9810 - val_loss: 0.0390 - val_accuracy: 0.9778\n",
      "Epoch 409/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0628 - accuracy: 0.9810 - val_loss: 0.0389 - val_accuracy: 0.9778\n",
      "Epoch 410/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0627 - accuracy: 0.9810 - val_loss: 0.0388 - val_accuracy: 0.9778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 411/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0626 - accuracy: 0.9810 - val_loss: 0.0387 - val_accuracy: 0.9778\n",
      "Epoch 412/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0625 - accuracy: 0.9810 - val_loss: 0.0385 - val_accuracy: 0.9778\n",
      "Epoch 413/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0624 - accuracy: 0.9810 - val_loss: 0.0384 - val_accuracy: 0.9778\n",
      "Epoch 414/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0623 - accuracy: 0.9810 - val_loss: 0.0383 - val_accuracy: 0.9778\n",
      "Epoch 415/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0622 - accuracy: 0.9810 - val_loss: 0.0382 - val_accuracy: 0.9778\n",
      "Epoch 416/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0621 - accuracy: 0.9810 - val_loss: 0.0381 - val_accuracy: 0.9778\n",
      "Epoch 417/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0620 - accuracy: 0.9810 - val_loss: 0.0380 - val_accuracy: 0.9778\n",
      "Epoch 418/500\n",
      "1/1 [==============================] - 0s 61ms/step - loss: 0.0620 - accuracy: 0.9810 - val_loss: 0.0379 - val_accuracy: 0.9778\n",
      "Epoch 419/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0619 - accuracy: 0.9810 - val_loss: 0.0378 - val_accuracy: 0.9778\n",
      "Epoch 420/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0618 - accuracy: 0.9810 - val_loss: 0.0377 - val_accuracy: 0.9778\n",
      "Epoch 421/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0617 - accuracy: 0.9810 - val_loss: 0.0375 - val_accuracy: 0.9778\n",
      "Epoch 422/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0616 - accuracy: 0.9810 - val_loss: 0.0374 - val_accuracy: 0.9778\n",
      "Epoch 423/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0615 - accuracy: 0.9810 - val_loss: 0.0373 - val_accuracy: 0.9778\n",
      "Epoch 424/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0615 - accuracy: 0.9810 - val_loss: 0.0372 - val_accuracy: 0.9778\n",
      "Epoch 425/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0614 - accuracy: 0.9810 - val_loss: 0.0371 - val_accuracy: 0.9778\n",
      "Epoch 426/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0613 - accuracy: 0.9810 - val_loss: 0.0370 - val_accuracy: 0.9778\n",
      "Epoch 427/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0612 - accuracy: 0.9810 - val_loss: 0.0369 - val_accuracy: 0.9778\n",
      "Epoch 428/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0611 - accuracy: 0.9810 - val_loss: 0.0368 - val_accuracy: 0.9778\n",
      "Epoch 429/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0611 - accuracy: 0.9810 - val_loss: 0.0367 - val_accuracy: 0.9778\n",
      "Epoch 430/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0610 - accuracy: 0.9810 - val_loss: 0.0365 - val_accuracy: 0.9778\n",
      "Epoch 431/500\n",
      "1/1 [==============================] - 0s 36ms/step - loss: 0.0609 - accuracy: 0.9810 - val_loss: 0.0364 - val_accuracy: 0.9778\n",
      "Epoch 432/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0608 - accuracy: 0.9810 - val_loss: 0.0363 - val_accuracy: 0.9778\n",
      "Epoch 433/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0608 - accuracy: 0.9810 - val_loss: 0.0362 - val_accuracy: 0.9778\n",
      "Epoch 434/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0607 - accuracy: 0.9810 - val_loss: 0.0361 - val_accuracy: 0.9778\n",
      "Epoch 435/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0606 - accuracy: 0.9810 - val_loss: 0.0360 - val_accuracy: 0.9778\n",
      "Epoch 436/500\n",
      "1/1 [==============================] - 0s 35ms/step - loss: 0.0605 - accuracy: 0.9810 - val_loss: 0.0360 - val_accuracy: 0.9778\n",
      "Epoch 437/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0605 - accuracy: 0.9810 - val_loss: 0.0359 - val_accuracy: 0.9778\n",
      "Epoch 438/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0604 - accuracy: 0.9810 - val_loss: 0.0358 - val_accuracy: 0.9778\n",
      "Epoch 439/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0603 - accuracy: 0.9810 - val_loss: 0.0356 - val_accuracy: 0.9778\n",
      "Epoch 440/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0602 - accuracy: 0.9810 - val_loss: 0.0355 - val_accuracy: 0.9778\n",
      "Epoch 441/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0602 - accuracy: 0.9810 - val_loss: 0.0354 - val_accuracy: 0.9778\n",
      "Epoch 442/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0601 - accuracy: 0.9810 - val_loss: 0.0354 - val_accuracy: 0.9778\n",
      "Epoch 443/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0600 - accuracy: 0.9810 - val_loss: 0.0353 - val_accuracy: 0.9778\n",
      "Epoch 444/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0600 - accuracy: 0.9810 - val_loss: 0.0352 - val_accuracy: 0.9778\n",
      "Epoch 445/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0599 - accuracy: 0.9810 - val_loss: 0.0351 - val_accuracy: 0.9778\n",
      "Epoch 446/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0598 - accuracy: 0.9810 - val_loss: 0.0350 - val_accuracy: 0.9778\n",
      "Epoch 447/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0598 - accuracy: 0.9810 - val_loss: 0.0349 - val_accuracy: 0.9778\n",
      "Epoch 448/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0597 - accuracy: 0.9810 - val_loss: 0.0348 - val_accuracy: 0.9778\n",
      "Epoch 449/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0596 - accuracy: 0.9810 - val_loss: 0.0347 - val_accuracy: 0.9778\n",
      "Epoch 450/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0596 - accuracy: 0.9810 - val_loss: 0.0346 - val_accuracy: 0.9778\n",
      "Epoch 451/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0595 - accuracy: 0.9810 - val_loss: 0.0346 - val_accuracy: 0.9778\n",
      "Epoch 452/500\n",
      "1/1 [==============================] - 0s 37ms/step - loss: 0.0594 - accuracy: 0.9810 - val_loss: 0.0345 - val_accuracy: 0.9778\n",
      "Epoch 453/500\n",
      "1/1 [==============================] - 0s 39ms/step - loss: 0.0594 - accuracy: 0.9810 - val_loss: 0.0344 - val_accuracy: 0.9778\n",
      "Epoch 454/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0593 - accuracy: 0.9810 - val_loss: 0.0343 - val_accuracy: 0.9778\n",
      "Epoch 455/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0593 - accuracy: 0.9810 - val_loss: 0.0342 - val_accuracy: 0.9778\n",
      "Epoch 456/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0592 - accuracy: 0.9810 - val_loss: 0.0341 - val_accuracy: 0.9778\n",
      "Epoch 457/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0591 - accuracy: 0.9810 - val_loss: 0.0340 - val_accuracy: 0.9778\n",
      "Epoch 458/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0591 - accuracy: 0.9810 - val_loss: 0.0340 - val_accuracy: 0.9778\n",
      "Epoch 459/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0590 - accuracy: 0.9810 - val_loss: 0.0339 - val_accuracy: 0.9778\n",
      "Epoch 460/500\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.0589 - accuracy: 0.9810 - val_loss: 0.0338 - val_accuracy: 0.9778\n",
      "Epoch 461/500\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.0589 - accuracy: 0.9810 - val_loss: 0.0337 - val_accuracy: 0.9778\n",
      "Epoch 462/500\n",
      "1/1 [==============================] - 0s 60ms/step - loss: 0.0588 - accuracy: 0.9810 - val_loss: 0.0337 - val_accuracy: 0.9778\n",
      "Epoch 463/500\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.0588 - accuracy: 0.9810 - val_loss: 0.0336 - val_accuracy: 0.9778\n",
      "Epoch 464/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0587 - accuracy: 0.9810 - val_loss: 0.0335 - val_accuracy: 0.9778\n",
      "Epoch 465/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0587 - accuracy: 0.9810 - val_loss: 0.0334 - val_accuracy: 0.9778\n",
      "Epoch 466/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0586 - accuracy: 0.9810 - val_loss: 0.0334 - val_accuracy: 0.9778\n",
      "Epoch 467/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0585 - accuracy: 0.9810 - val_loss: 0.0333 - val_accuracy: 0.9778\n",
      "Epoch 468/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0585 - accuracy: 0.9810 - val_loss: 0.0332 - val_accuracy: 0.9778\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 469/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0584 - accuracy: 0.9810 - val_loss: 0.0331 - val_accuracy: 0.9778\n",
      "Epoch 470/500\n",
      "1/1 [==============================] - 0s 40ms/step - loss: 0.0584 - accuracy: 0.9810 - val_loss: 0.0330 - val_accuracy: 0.9778\n",
      "Epoch 471/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0583 - accuracy: 0.9810 - val_loss: 0.0330 - val_accuracy: 0.9778\n",
      "Epoch 472/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0583 - accuracy: 0.9810 - val_loss: 0.0329 - val_accuracy: 0.9778\n",
      "Epoch 473/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0582 - accuracy: 0.9810 - val_loss: 0.0328 - val_accuracy: 0.9778\n",
      "Epoch 474/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0582 - accuracy: 0.9810 - val_loss: 0.0328 - val_accuracy: 0.9778\n",
      "Epoch 475/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0581 - accuracy: 0.9810 - val_loss: 0.0327 - val_accuracy: 0.9778\n",
      "Epoch 476/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0581 - accuracy: 0.9810 - val_loss: 0.0326 - val_accuracy: 0.9778\n",
      "Epoch 477/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0580 - accuracy: 0.9810 - val_loss: 0.0325 - val_accuracy: 0.9778\n",
      "Epoch 478/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0580 - accuracy: 0.9810 - val_loss: 0.0325 - val_accuracy: 0.9778\n",
      "Epoch 479/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0579 - accuracy: 0.9810 - val_loss: 0.0324 - val_accuracy: 0.9778\n",
      "Epoch 480/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0579 - accuracy: 0.9810 - val_loss: 0.0323 - val_accuracy: 0.9778\n",
      "Epoch 481/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0578 - accuracy: 0.9810 - val_loss: 0.0323 - val_accuracy: 0.9778\n",
      "Epoch 482/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0578 - accuracy: 0.9810 - val_loss: 0.0322 - val_accuracy: 0.9778\n",
      "Epoch 483/500\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.0577 - accuracy: 0.9810 - val_loss: 0.0321 - val_accuracy: 0.9778\n",
      "Epoch 484/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0577 - accuracy: 0.9810 - val_loss: 0.0321 - val_accuracy: 0.9778\n",
      "Epoch 485/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0576 - accuracy: 0.9810 - val_loss: 0.0320 - val_accuracy: 0.9778\n",
      "Epoch 486/500\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.0576 - accuracy: 0.9810 - val_loss: 0.0319 - val_accuracy: 0.9778\n",
      "Epoch 487/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0575 - accuracy: 0.9810 - val_loss: 0.0319 - val_accuracy: 0.9778\n",
      "Epoch 488/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0575 - accuracy: 0.9810 - val_loss: 0.0318 - val_accuracy: 0.9778\n",
      "Epoch 489/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0574 - accuracy: 0.9810 - val_loss: 0.0317 - val_accuracy: 0.9778\n",
      "Epoch 490/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0574 - accuracy: 0.9810 - val_loss: 0.0317 - val_accuracy: 0.9778\n",
      "Epoch 491/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0573 - accuracy: 0.9810 - val_loss: 0.0316 - val_accuracy: 0.9778\n",
      "Epoch 492/500\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.0573 - accuracy: 0.9810 - val_loss: 0.0316 - val_accuracy: 0.9778\n",
      "Epoch 493/500\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.0572 - accuracy: 0.9810 - val_loss: 0.0315 - val_accuracy: 0.9778\n",
      "Epoch 494/500\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.0572 - accuracy: 0.9810 - val_loss: 0.0315 - val_accuracy: 0.9778\n",
      "Epoch 495/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0571 - accuracy: 0.9810 - val_loss: 0.0314 - val_accuracy: 0.9778\n",
      "Epoch 496/500\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.0571 - accuracy: 0.9810 - val_loss: 0.0313 - val_accuracy: 0.9778\n",
      "Epoch 497/500\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.0571 - accuracy: 0.9810 - val_loss: 0.0313 - val_accuracy: 0.9778\n",
      "Epoch 498/500\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.0570 - accuracy: 0.9810 - val_loss: 0.0312 - val_accuracy: 0.9778\n",
      "Epoch 499/500\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.0570 - accuracy: 0.9810 - val_loss: 0.0311 - val_accuracy: 0.9778\n",
      "Epoch 500/500\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.0569 - accuracy: 0.9810 - val_loss: 0.0311 - val_accuracy: 0.9778\n"
     ]
    }
   ],
   "source": [
    "model = Iris()\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=500, batch_size=150, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "adaa84e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefa35b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bce2701",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6de7f7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ca7b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=50, validation_data=(X_test,y_test))\n",
    "pred=model.predict(X_test)\n",
    "pred=pd.DataFrame(pred)\n",
    "pred=pred[0].apply(lambda x: 1 if x > 5 else 0)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "128e1fb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,5))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train','val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15787d92",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "909d9cbb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbb16a21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d5b306c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f54f9db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f653e4ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711dacc3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52c2da5e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bcc0e3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8b584d",
   "metadata": {},
   "source": [
    "1) Alcohol\n",
    "2) Malic acid\n",
    "3) Ash\n",
    "4) Alcalinity of ash  \n",
    "5) Magnesium\n",
    "6) Total phenols\n",
    "7) Flavanoids\n",
    "8) Nonflavanoid phenols\n",
    "9) Proanthocyanins\n",
    "10) Color intensity\n",
    "11) Hue\n",
    "12) OD280/OD315 of diluted wines\n",
    "13) Proline            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "74fffd01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6492</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.29</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.039</td>\n",
       "      <td>24.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0.99114</td>\n",
       "      <td>3.27</td>\n",
       "      <td>0.50</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6493</th>\n",
       "      <td>6.6</td>\n",
       "      <td>0.32</td>\n",
       "      <td>0.36</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.047</td>\n",
       "      <td>57.0</td>\n",
       "      <td>168.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.15</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.6</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6494</th>\n",
       "      <td>6.5</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.19</td>\n",
       "      <td>1.2</td>\n",
       "      <td>0.041</td>\n",
       "      <td>30.0</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.99254</td>\n",
       "      <td>2.99</td>\n",
       "      <td>0.46</td>\n",
       "      <td>9.4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6495</th>\n",
       "      <td>5.5</td>\n",
       "      <td>0.29</td>\n",
       "      <td>0.30</td>\n",
       "      <td>1.1</td>\n",
       "      <td>0.022</td>\n",
       "      <td>20.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>0.98869</td>\n",
       "      <td>3.34</td>\n",
       "      <td>0.38</td>\n",
       "      <td>12.8</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6496</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.21</td>\n",
       "      <td>0.38</td>\n",
       "      <td>0.8</td>\n",
       "      <td>0.020</td>\n",
       "      <td>22.0</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0.98941</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.32</td>\n",
       "      <td>11.8</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6497 rows × 13 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        0     1     2    3      4     5      6        7     8     9     10  \\\n",
       "0      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
       "1      7.8  0.88  0.00  2.6  0.098  25.0   67.0  0.99680  3.20  0.68   9.8   \n",
       "2      7.8  0.76  0.04  2.3  0.092  15.0   54.0  0.99700  3.26  0.65   9.8   \n",
       "3     11.2  0.28  0.56  1.9  0.075  17.0   60.0  0.99800  3.16  0.58   9.8   \n",
       "4      7.4  0.70  0.00  1.9  0.076  11.0   34.0  0.99780  3.51  0.56   9.4   \n",
       "...    ...   ...   ...  ...    ...   ...    ...      ...   ...   ...   ...   \n",
       "6492   6.2  0.21  0.29  1.6  0.039  24.0   92.0  0.99114  3.27  0.50  11.2   \n",
       "6493   6.6  0.32  0.36  8.0  0.047  57.0  168.0  0.99490  3.15  0.46   9.6   \n",
       "6494   6.5  0.24  0.19  1.2  0.041  30.0  111.0  0.99254  2.99  0.46   9.4   \n",
       "6495   5.5  0.29  0.30  1.1  0.022  20.0  110.0  0.98869  3.34  0.38  12.8   \n",
       "6496   6.0  0.21  0.38  0.8  0.020  22.0   98.0  0.98941  3.26  0.32  11.8   \n",
       "\n",
       "      11  12  \n",
       "0      5   1  \n",
       "1      5   1  \n",
       "2      5   1  \n",
       "3      6   1  \n",
       "4      5   1  \n",
       "...   ..  ..  \n",
       "6492   6   0  \n",
       "6493   5   0  \n",
       "6494   6   0  \n",
       "6495   7   0  \n",
       "6496   6   0  \n",
       "\n",
       "[6497 rows x 13 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/haram4th/ADsP/main/wine.csv\", header=None)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "feb8d625",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6497 entries, 0 to 6496\n",
      "Data columns (total 13 columns):\n",
      " #   Column  Non-Null Count  Dtype  \n",
      "---  ------  --------------  -----  \n",
      " 0   0       6497 non-null   float64\n",
      " 1   1       6497 non-null   float64\n",
      " 2   2       6497 non-null   float64\n",
      " 3   3       6497 non-null   float64\n",
      " 4   4       6497 non-null   float64\n",
      " 5   5       6497 non-null   float64\n",
      " 6   6       6497 non-null   float64\n",
      " 7   7       6497 non-null   float64\n",
      " 8   8       6497 non-null   float64\n",
      " 9   9       6497 non-null   float64\n",
      " 10  10      6497 non-null   float64\n",
      " 11  11      6497 non-null   int64  \n",
      " 12  12      6497 non-null   int64  \n",
      "dtypes: float64(11), int64(2)\n",
      "memory usage: 660.0 KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "864d5747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(data.iloc[:,0:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f29150f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12\n",
       "0    4898\n",
       "1    1599\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[12].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ac1fe001",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.drop(12, axis=1)\n",
    "y = data[12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "15029dfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5996e7f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.30769231,  2.41176471, -2.21428571, ...,  0.29411765,\n",
       "        -0.5       , -1.        ],\n",
       "       [ 0.61538462,  3.47058824, -2.21428571, ...,  1.        ,\n",
       "        -0.27777778, -1.        ],\n",
       "       [ 0.61538462,  2.76470588, -1.92857143, ...,  0.82352941,\n",
       "        -0.27777778, -1.        ],\n",
       "       ...,\n",
       "       [-0.38461538, -0.29411765, -0.85714286, ..., -0.29411765,\n",
       "        -0.5       ,  0.        ],\n",
       "       [-1.15384615,  0.        , -0.07142857, ..., -0.76470588,\n",
       "         1.38888889,  1.        ],\n",
       "       [-0.76923077, -0.47058824,  0.5       , ..., -1.11764706,\n",
       "         0.83333333,  0.        ]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rs = RobustScaler()\n",
    "X_scaled = rs.fit_transform(X)\n",
    "X_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f688b5a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       1\n",
       "1       1\n",
       "2       1\n",
       "3       1\n",
       "4       1\n",
       "       ..\n",
       "6492    0\n",
       "6493    0\n",
       "6494    0\n",
       "6495    0\n",
       "6496    0\n",
       "Name: 12, Length: 6497, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "02bb04ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0e693adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_scaled, y, test_size=0.4, stratify=y, random_state=10)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5, stratify=y_valid, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1f026a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 09:22:06.282687: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-11 09:22:08.007247: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libdirectml.d6f03b303ac3c4f2eeb8ca631688c9757b361310.so\n",
      "2024-09-11 09:22:08.007388: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libdxcore.so\n",
      "2024-09-11 09:22:08.010898: I tensorflow/c/logging.cc:34] Successfully opened dynamic library libd3d12.so\n",
      "2024-09-11 09:22:08.558428: I tensorflow/c/logging.cc:34] DirectML device enumeration: found 1 compatible adapters.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "2d715f4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 32)                416       \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 8)                 136       \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 1)                 9         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,089\n",
      "Trainable params: 1,089\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 09:22:08.866911: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-09-11 09:22:08.868111: I tensorflow/c/logging.cc:34] DirectML: creating device on adapter 0 (AMD Radeon(TM) Graphics)\n",
      "2024-09-11 09:22:08.947804: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-11 09:22:08.947851: W tensorflow/core/common_runtime/pluggable_device/pluggable_device_bfc_allocator.cc:28] Overriding allow_growth setting because force_memory_growth was requested by the device.\n",
      "2024-09-11 09:22:08.947873: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(8, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdfeb8cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 09:22:09.656680: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-11 09:22:09.717951: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-11 09:22:09.718012: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 1s 74ms/step - loss: 0.6707 - accuracy: 0.6193 - val_loss: 0.6526 - val_accuracy: 0.7475\n",
      "Epoch 2/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.6374 - accuracy: 0.8184 - val_loss: 0.6174 - val_accuracy: 0.8814\n",
      "Epoch 3/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 09:22:10.528176: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-11 09:22:10.552993: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-11 09:22:10.553061: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5992 - accuracy: 0.9066 - val_loss: 0.5765 - val_accuracy: 0.9323\n",
      "Epoch 4/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5558 - accuracy: 0.9438 - val_loss: 0.5309 - val_accuracy: 0.9546\n",
      "Epoch 5/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.5083 - accuracy: 0.9649 - val_loss: 0.4814 - val_accuracy: 0.9707\n",
      "Epoch 6/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.4568 - accuracy: 0.9767 - val_loss: 0.4286 - val_accuracy: 0.9769\n",
      "Epoch 7/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.4024 - accuracy: 0.9805 - val_loss: 0.3738 - val_accuracy: 0.9815\n",
      "Epoch 8/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.3467 - accuracy: 0.9828 - val_loss: 0.3183 - val_accuracy: 0.9831\n",
      "Epoch 9/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.2908 - accuracy: 0.9833 - val_loss: 0.2651 - val_accuracy: 0.9846\n",
      "Epoch 10/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.2389 - accuracy: 0.9844 - val_loss: 0.2179 - val_accuracy: 0.9869\n",
      "Epoch 11/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1941 - accuracy: 0.9867 - val_loss: 0.1784 - val_accuracy: 0.9877\n",
      "Epoch 12/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1573 - accuracy: 0.9882 - val_loss: 0.1467 - val_accuracy: 0.9892\n",
      "Epoch 13/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1288 - accuracy: 0.9887 - val_loss: 0.1218 - val_accuracy: 0.9908\n",
      "Epoch 14/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.1065 - accuracy: 0.9900 - val_loss: 0.1028 - val_accuracy: 0.9908\n",
      "Epoch 15/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0895 - accuracy: 0.9915 - val_loss: 0.0883 - val_accuracy: 0.9908\n",
      "Epoch 16/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0768 - accuracy: 0.9918 - val_loss: 0.0771 - val_accuracy: 0.9923\n",
      "Epoch 17/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0669 - accuracy: 0.9920 - val_loss: 0.0686 - val_accuracy: 0.9931\n",
      "Epoch 18/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0593 - accuracy: 0.9918 - val_loss: 0.0619 - val_accuracy: 0.9931\n",
      "Epoch 19/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0533 - accuracy: 0.9926 - val_loss: 0.0568 - val_accuracy: 0.9931\n",
      "Epoch 20/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0484 - accuracy: 0.9931 - val_loss: 0.0526 - val_accuracy: 0.9931\n",
      "Epoch 21/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0446 - accuracy: 0.9933 - val_loss: 0.0493 - val_accuracy: 0.9931\n",
      "Epoch 22/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0414 - accuracy: 0.9938 - val_loss: 0.0466 - val_accuracy: 0.9931\n",
      "Epoch 23/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0387 - accuracy: 0.9941 - val_loss: 0.0443 - val_accuracy: 0.9931\n",
      "Epoch 24/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0365 - accuracy: 0.9938 - val_loss: 0.0425 - val_accuracy: 0.9938\n",
      "Epoch 25/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0346 - accuracy: 0.9941 - val_loss: 0.0409 - val_accuracy: 0.9938\n",
      "Epoch 26/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0329 - accuracy: 0.9941 - val_loss: 0.0395 - val_accuracy: 0.9938\n",
      "Epoch 27/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0314 - accuracy: 0.9941 - val_loss: 0.0384 - val_accuracy: 0.9938\n",
      "Epoch 28/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0301 - accuracy: 0.9944 - val_loss: 0.0375 - val_accuracy: 0.9938\n",
      "Epoch 29/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0290 - accuracy: 0.9951 - val_loss: 0.0367 - val_accuracy: 0.9946\n",
      "Epoch 30/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0280 - accuracy: 0.9951 - val_loss: 0.0360 - val_accuracy: 0.9946\n",
      "Epoch 31/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0271 - accuracy: 0.9956 - val_loss: 0.0353 - val_accuracy: 0.9946\n",
      "Epoch 32/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0263 - accuracy: 0.9956 - val_loss: 0.0347 - val_accuracy: 0.9946\n",
      "Epoch 33/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0255 - accuracy: 0.9964 - val_loss: 0.0342 - val_accuracy: 0.9946\n",
      "Epoch 34/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0248 - accuracy: 0.9964 - val_loss: 0.0338 - val_accuracy: 0.9946\n",
      "Epoch 35/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0242 - accuracy: 0.9964 - val_loss: 0.0334 - val_accuracy: 0.9946\n",
      "Epoch 36/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0236 - accuracy: 0.9964 - val_loss: 0.0330 - val_accuracy: 0.9946\n",
      "Epoch 37/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0230 - accuracy: 0.9964 - val_loss: 0.0327 - val_accuracy: 0.9954\n",
      "Epoch 38/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0225 - accuracy: 0.9964 - val_loss: 0.0324 - val_accuracy: 0.9954\n",
      "Epoch 39/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0220 - accuracy: 0.9964 - val_loss: 0.0322 - val_accuracy: 0.9946\n",
      "Epoch 40/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0216 - accuracy: 0.9964 - val_loss: 0.0319 - val_accuracy: 0.9946\n",
      "Epoch 41/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0212 - accuracy: 0.9967 - val_loss: 0.0317 - val_accuracy: 0.9954\n",
      "Epoch 42/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0208 - accuracy: 0.9967 - val_loss: 0.0315 - val_accuracy: 0.9954\n",
      "Epoch 43/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0205 - accuracy: 0.9967 - val_loss: 0.0313 - val_accuracy: 0.9962\n",
      "Epoch 44/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0201 - accuracy: 0.9967 - val_loss: 0.0311 - val_accuracy: 0.9962\n",
      "Epoch 45/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0198 - accuracy: 0.9967 - val_loss: 0.0310 - val_accuracy: 0.9962\n",
      "Epoch 46/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0194 - accuracy: 0.9967 - val_loss: 0.0308 - val_accuracy: 0.9962\n",
      "Epoch 47/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0191 - accuracy: 0.9967 - val_loss: 0.0307 - val_accuracy: 0.9962\n",
      "Epoch 48/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0189 - accuracy: 0.9967 - val_loss: 0.0305 - val_accuracy: 0.9962\n",
      "Epoch 49/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0186 - accuracy: 0.9969 - val_loss: 0.0304 - val_accuracy: 0.9962\n",
      "Epoch 50/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0183 - accuracy: 0.9969 - val_loss: 0.0303 - val_accuracy: 0.9962\n",
      "Epoch 51/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0181 - accuracy: 0.9969 - val_loss: 0.0302 - val_accuracy: 0.9962\n",
      "Epoch 52/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0178 - accuracy: 0.9969 - val_loss: 0.0301 - val_accuracy: 0.9962\n",
      "Epoch 53/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0176 - accuracy: 0.9969 - val_loss: 0.0300 - val_accuracy: 0.9962\n",
      "Epoch 54/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0174 - accuracy: 0.9969 - val_loss: 0.0299 - val_accuracy: 0.9962\n",
      "Epoch 55/100\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0171 - accuracy: 0.9969 - val_loss: 0.0298 - val_accuracy: 0.9962\n",
      "Epoch 56/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0169 - accuracy: 0.9969 - val_loss: 0.0297 - val_accuracy: 0.9962\n",
      "Epoch 57/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0167 - accuracy: 0.9969 - val_loss: 0.0297 - val_accuracy: 0.9962\n",
      "Epoch 58/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0164 - accuracy: 0.9969 - val_loss: 0.0296 - val_accuracy: 0.9962\n",
      "Epoch 59/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0163 - accuracy: 0.9969 - val_loss: 0.0295 - val_accuracy: 0.9962\n",
      "Epoch 60/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0160 - accuracy: 0.9969 - val_loss: 0.0294 - val_accuracy: 0.9962\n",
      "Epoch 61/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0158 - accuracy: 0.9969 - val_loss: 0.0294 - val_accuracy: 0.9962\n",
      "Epoch 62/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0156 - accuracy: 0.9969 - val_loss: 0.0294 - val_accuracy: 0.9962\n",
      "Epoch 63/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0155 - accuracy: 0.9969 - val_loss: 0.0293 - val_accuracy: 0.9962\n",
      "Epoch 64/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0153 - accuracy: 0.9969 - val_loss: 0.0293 - val_accuracy: 0.9962\n",
      "Epoch 65/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0151 - accuracy: 0.9972 - val_loss: 0.0293 - val_accuracy: 0.9962\n",
      "Epoch 66/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0149 - accuracy: 0.9972 - val_loss: 0.0292 - val_accuracy: 0.9962\n",
      "Epoch 67/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0147 - accuracy: 0.9972 - val_loss: 0.0292 - val_accuracy: 0.9962\n",
      "Epoch 68/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0146 - accuracy: 0.9974 - val_loss: 0.0292 - val_accuracy: 0.9962\n",
      "Epoch 69/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0144 - accuracy: 0.9972 - val_loss: 0.0292 - val_accuracy: 0.9962\n",
      "Epoch 70/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0142 - accuracy: 0.9972 - val_loss: 0.0292 - val_accuracy: 0.9962\n",
      "Epoch 71/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0141 - accuracy: 0.9974 - val_loss: 0.0290 - val_accuracy: 0.9962\n",
      "Epoch 72/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0139 - accuracy: 0.9974 - val_loss: 0.0291 - val_accuracy: 0.9962\n",
      "Epoch 73/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0137 - accuracy: 0.9974 - val_loss: 0.0291 - val_accuracy: 0.9962\n",
      "Epoch 74/100\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0136 - accuracy: 0.9974 - val_loss: 0.0291 - val_accuracy: 0.9962\n",
      "Epoch 75/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0135 - accuracy: 0.9977 - val_loss: 0.0291 - val_accuracy: 0.9962\n",
      "Epoch 76/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0133 - accuracy: 0.9977 - val_loss: 0.0290 - val_accuracy: 0.9962\n",
      "Epoch 77/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0132 - accuracy: 0.9974 - val_loss: 0.0289 - val_accuracy: 0.9962\n",
      "Epoch 78/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0130 - accuracy: 0.9974 - val_loss: 0.0288 - val_accuracy: 0.9962\n",
      "Epoch 79/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0129 - accuracy: 0.9977 - val_loss: 0.0289 - val_accuracy: 0.9962\n",
      "Epoch 80/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0128 - accuracy: 0.9977 - val_loss: 0.0289 - val_accuracy: 0.9962\n",
      "Epoch 81/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0127 - accuracy: 0.9977 - val_loss: 0.0289 - val_accuracy: 0.9962\n",
      "Epoch 82/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0125 - accuracy: 0.9977 - val_loss: 0.0288 - val_accuracy: 0.9962\n",
      "Epoch 83/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0124 - accuracy: 0.9977 - val_loss: 0.0288 - val_accuracy: 0.9962\n",
      "Epoch 84/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0123 - accuracy: 0.9977 - val_loss: 0.0287 - val_accuracy: 0.9962\n",
      "Epoch 85/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0122 - accuracy: 0.9977 - val_loss: 0.0287 - val_accuracy: 0.9962\n",
      "Epoch 86/100\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0121 - accuracy: 0.9977 - val_loss: 0.0286 - val_accuracy: 0.9962\n",
      "Epoch 87/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0119 - accuracy: 0.9977 - val_loss: 0.0286 - val_accuracy: 0.9962\n",
      "Epoch 88/100\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0118 - accuracy: 0.9979 - val_loss: 0.0288 - val_accuracy: 0.9962\n",
      "Epoch 89/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0117 - accuracy: 0.9979 - val_loss: 0.0287 - val_accuracy: 0.9962\n",
      "Epoch 90/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0116 - accuracy: 0.9977 - val_loss: 0.0285 - val_accuracy: 0.9962\n",
      "Epoch 91/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0115 - accuracy: 0.9977 - val_loss: 0.0286 - val_accuracy: 0.9962\n",
      "Epoch 92/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0114 - accuracy: 0.9979 - val_loss: 0.0286 - val_accuracy: 0.9962\n",
      "Epoch 93/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0113 - accuracy: 0.9979 - val_loss: 0.0287 - val_accuracy: 0.9962\n",
      "Epoch 94/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0112 - accuracy: 0.9979 - val_loss: 0.0286 - val_accuracy: 0.9962\n",
      "Epoch 95/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0111 - accuracy: 0.9979 - val_loss: 0.0285 - val_accuracy: 0.9962\n",
      "Epoch 96/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0110 - accuracy: 0.9979 - val_loss: 0.0285 - val_accuracy: 0.9962\n",
      "Epoch 97/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0109 - accuracy: 0.9979 - val_loss: 0.0283 - val_accuracy: 0.9962\n",
      "Epoch 98/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0108 - accuracy: 0.9979 - val_loss: 0.0284 - val_accuracy: 0.9962\n",
      "Epoch 99/100\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0107 - accuracy: 0.9979 - val_loss: 0.0284 - val_accuracy: 0.9962\n",
      "Epoch 100/100\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0106 - accuracy: 0.9979 - val_loss: 0.0285 - val_accuracy: 0.9962\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=100, batch_size=500, validation_data=(X_valid, y_valid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ab09803e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 4ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 09:22:23.303143: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-11 09:22:23.487750: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-11 09:22:23.487829: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       980\n",
      "           1       0.99      0.98      0.99       320\n",
      "\n",
      "    accuracy                           0.99      1300\n",
      "   macro avg       0.99      0.99      0.99      1300\n",
      "weighted avg       0.99      0.99      0.99      1300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 09:22:23.507540: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-11 09:22:23.507642: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n",
      "2024-09-11 09:22:23.513790: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-11 09:22:23.513868: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred = pd.DataFrame(pred)\n",
    "pred = pred[0].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d9ad6447",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "786dafa8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8, 4))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel(\"epochs\")\n",
    "plt.ylabel(\"loss\")\n",
    "plt.legend(['train', 'valid'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da023ad7",
   "metadata": {},
   "source": [
    "# EarlyStopping으로 학습 조기 중단 및 저장하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8c95e43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "01b8d40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fd4b0bf",
   "metadata": {},
   "source": [
    "# ModelCheckpoint\n",
    "* 모델을 중간에 저장하는 옵션"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bc53574e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory /model already exists.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "if not os.path.exists(\"./model\"):\n",
    "    os.makedirs(\"./model\")\n",
    "    print(f\"Directory /model created.\")\n",
    "else:\n",
    "    print(f\"Directory /model already exists.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2a04dae8",
   "metadata": {},
   "outputs": [],
   "source": [
    "modelpath = \"./model/{epoch:03d}--{val_loss:.4f}.keras\"\n",
    "checkpointer = ModelCheckpoint(filepath=modelpath, monitor='val_loss', verbose=0, save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "28ab4eab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "8/8 [==============================] - 0s 28ms/step - loss: 0.0105 - accuracy: 0.9979 - val_loss: 0.0286 - val_accuracy: 0.9962\n",
      "Epoch 2/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0104 - accuracy: 0.9982 - val_loss: 0.0285 - val_accuracy: 0.9962\n",
      "Epoch 3/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0104 - accuracy: 0.9982 - val_loss: 0.0284 - val_accuracy: 0.9962\n",
      "Epoch 4/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0103 - accuracy: 0.9982 - val_loss: 0.0282 - val_accuracy: 0.9962\n",
      "Epoch 5/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0102 - accuracy: 0.9982 - val_loss: 0.0283 - val_accuracy: 0.9962\n",
      "Epoch 6/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0101 - accuracy: 0.9982 - val_loss: 0.0284 - val_accuracy: 0.9962\n",
      "Epoch 7/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0101 - accuracy: 0.9982 - val_loss: 0.0284 - val_accuracy: 0.9962\n",
      "Epoch 8/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0100 - accuracy: 0.9982 - val_loss: 0.0283 - val_accuracy: 0.9962\n",
      "Epoch 9/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0099 - accuracy: 0.9982 - val_loss: 0.0283 - val_accuracy: 0.9962\n",
      "Epoch 10/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0099 - accuracy: 0.9982 - val_loss: 0.0283 - val_accuracy: 0.9962\n",
      "Epoch 11/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0098 - accuracy: 0.9982 - val_loss: 0.0283 - val_accuracy: 0.9954\n",
      "Epoch 12/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0097 - accuracy: 0.9982 - val_loss: 0.0283 - val_accuracy: 0.9954\n",
      "Epoch 13/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0096 - accuracy: 0.9982 - val_loss: 0.0284 - val_accuracy: 0.9954\n",
      "Epoch 14/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0096 - accuracy: 0.9982 - val_loss: 0.0283 - val_accuracy: 0.9954\n",
      "Epoch 15/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0095 - accuracy: 0.9985 - val_loss: 0.0282 - val_accuracy: 0.9962\n",
      "Epoch 16/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0095 - accuracy: 0.9985 - val_loss: 0.0283 - val_accuracy: 0.9954\n",
      "Epoch 17/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0094 - accuracy: 0.9985 - val_loss: 0.0283 - val_accuracy: 0.9954\n",
      "Epoch 18/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0093 - accuracy: 0.9985 - val_loss: 0.0283 - val_accuracy: 0.9954\n",
      "Epoch 19/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0092 - accuracy: 0.9985 - val_loss: 0.0282 - val_accuracy: 0.9954\n",
      "Epoch 20/1000\n",
      "8/8 [==============================] - 0s 25ms/step - loss: 0.0092 - accuracy: 0.9985 - val_loss: 0.0281 - val_accuracy: 0.9962\n",
      "Epoch 21/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0091 - accuracy: 0.9985 - val_loss: 0.0283 - val_accuracy: 0.9954\n",
      "Epoch 22/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0091 - accuracy: 0.9985 - val_loss: 0.0285 - val_accuracy: 0.9954\n",
      "Epoch 23/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0090 - accuracy: 0.9985 - val_loss: 0.0282 - val_accuracy: 0.9954\n",
      "Epoch 24/1000\n",
      "8/8 [==============================] - 0s 26ms/step - loss: 0.0090 - accuracy: 0.9985 - val_loss: 0.0281 - val_accuracy: 0.9954\n",
      "Epoch 25/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0089 - accuracy: 0.9985 - val_loss: 0.0281 - val_accuracy: 0.9954\n",
      "Epoch 26/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0088 - accuracy: 0.9985 - val_loss: 0.0282 - val_accuracy: 0.9954\n",
      "Epoch 27/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0088 - accuracy: 0.9985 - val_loss: 0.0281 - val_accuracy: 0.9954\n",
      "Epoch 28/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0087 - accuracy: 0.9985 - val_loss: 0.0282 - val_accuracy: 0.9954\n",
      "Epoch 29/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0087 - accuracy: 0.9985 - val_loss: 0.0282 - val_accuracy: 0.9954\n",
      "Epoch 30/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0086 - accuracy: 0.9985 - val_loss: 0.0280 - val_accuracy: 0.9954\n",
      "Epoch 31/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0086 - accuracy: 0.9985 - val_loss: 0.0281 - val_accuracy: 0.9954\n",
      "Epoch 32/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0085 - accuracy: 0.9985 - val_loss: 0.0281 - val_accuracy: 0.9954\n",
      "Epoch 33/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0085 - accuracy: 0.9985 - val_loss: 0.0281 - val_accuracy: 0.9954\n",
      "Epoch 34/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0084 - accuracy: 0.9985 - val_loss: 0.0282 - val_accuracy: 0.9954\n",
      "Epoch 35/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0083 - accuracy: 0.9985 - val_loss: 0.0282 - val_accuracy: 0.9954\n",
      "Epoch 36/1000\n",
      "8/8 [==============================] - 0s 24ms/step - loss: 0.0083 - accuracy: 0.9985 - val_loss: 0.0280 - val_accuracy: 0.9954\n",
      "Epoch 37/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0082 - accuracy: 0.9985 - val_loss: 0.0281 - val_accuracy: 0.9954\n",
      "Epoch 38/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0082 - accuracy: 0.9985 - val_loss: 0.0281 - val_accuracy: 0.9954\n",
      "Epoch 39/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 0.0281 - val_accuracy: 0.9954\n",
      "Epoch 40/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 0.0282 - val_accuracy: 0.9954\n",
      "Epoch 41/1000\n",
      "8/8 [==============================] - 0s 23ms/step - loss: 0.0081 - accuracy: 0.9985 - val_loss: 0.0279 - val_accuracy: 0.9954\n",
      "Epoch 42/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0080 - accuracy: 0.9985 - val_loss: 0.0282 - val_accuracy: 0.9954\n",
      "Epoch 43/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0080 - accuracy: 0.9987 - val_loss: 0.0284 - val_accuracy: 0.9954\n",
      "Epoch 44/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0079 - accuracy: 0.9985 - val_loss: 0.0279 - val_accuracy: 0.9954\n",
      "Epoch 45/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0079 - accuracy: 0.9985 - val_loss: 0.0279 - val_accuracy: 0.9954\n",
      "Epoch 46/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0078 - accuracy: 0.9987 - val_loss: 0.0279 - val_accuracy: 0.9954\n",
      "Epoch 47/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0078 - accuracy: 0.9987 - val_loss: 0.0281 - val_accuracy: 0.9954\n",
      "Epoch 48/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0077 - accuracy: 0.9987 - val_loss: 0.0281 - val_accuracy: 0.9954\n",
      "Epoch 49/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0077 - accuracy: 0.9987 - val_loss: 0.0280 - val_accuracy: 0.9954\n",
      "Epoch 50/1000\n",
      "8/8 [==============================] - 0s 29ms/step - loss: 0.0077 - accuracy: 0.9987 - val_loss: 0.0278 - val_accuracy: 0.9954\n",
      "Epoch 51/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0076 - accuracy: 0.9987 - val_loss: 0.0281 - val_accuracy: 0.9954\n",
      "Epoch 52/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0076 - accuracy: 0.9987 - val_loss: 0.0280 - val_accuracy: 0.9954\n",
      "Epoch 53/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0075 - accuracy: 0.9987 - val_loss: 0.0279 - val_accuracy: 0.9954\n",
      "Epoch 54/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0075 - accuracy: 0.9987 - val_loss: 0.0280 - val_accuracy: 0.9954\n",
      "Epoch 55/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0074 - accuracy: 0.9987 - val_loss: 0.0281 - val_accuracy: 0.9954\n",
      "Epoch 56/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0074 - accuracy: 0.9987 - val_loss: 0.0279 - val_accuracy: 0.9954\n",
      "Epoch 57/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0074 - accuracy: 0.9987 - val_loss: 0.0280 - val_accuracy: 0.9954\n",
      "Epoch 58/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0073 - accuracy: 0.9987 - val_loss: 0.0281 - val_accuracy: 0.9954\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 59/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0073 - accuracy: 0.9987 - val_loss: 0.0279 - val_accuracy: 0.9954\n",
      "Epoch 60/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0073 - accuracy: 0.9987 - val_loss: 0.0279 - val_accuracy: 0.9954\n",
      "Epoch 61/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0072 - accuracy: 0.9987 - val_loss: 0.0280 - val_accuracy: 0.9954\n",
      "Epoch 62/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0072 - accuracy: 0.9987 - val_loss: 0.0281 - val_accuracy: 0.9954\n",
      "Epoch 63/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0071 - accuracy: 0.9987 - val_loss: 0.0280 - val_accuracy: 0.9954\n",
      "Epoch 64/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0071 - accuracy: 0.9987 - val_loss: 0.0280 - val_accuracy: 0.9954\n",
      "Epoch 65/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0071 - accuracy: 0.9987 - val_loss: 0.0280 - val_accuracy: 0.9954\n",
      "Epoch 66/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.0280 - val_accuracy: 0.9954\n",
      "Epoch 67/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.0280 - val_accuracy: 0.9954\n",
      "Epoch 68/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.0279 - val_accuracy: 0.9954\n",
      "Epoch 69/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0070 - accuracy: 0.9987 - val_loss: 0.0278 - val_accuracy: 0.9954\n",
      "Epoch 70/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0069 - accuracy: 0.9987 - val_loss: 0.0282 - val_accuracy: 0.9954\n",
      "Epoch 71/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0069 - accuracy: 0.9987 - val_loss: 0.0282 - val_accuracy: 0.9954\n",
      "Epoch 72/1000\n",
      "8/8 [==============================] - 0s 21ms/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.0281 - val_accuracy: 0.9954\n",
      "Epoch 73/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.0280 - val_accuracy: 0.9954\n",
      "Epoch 74/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.0280 - val_accuracy: 0.9954\n",
      "Epoch 75/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0068 - accuracy: 0.9987 - val_loss: 0.0280 - val_accuracy: 0.9954\n",
      "Epoch 76/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0067 - accuracy: 0.9987 - val_loss: 0.0278 - val_accuracy: 0.9954\n",
      "Epoch 77/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0067 - accuracy: 0.9987 - val_loss: 0.0280 - val_accuracy: 0.9954\n",
      "Epoch 78/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0067 - accuracy: 0.9987 - val_loss: 0.0279 - val_accuracy: 0.9954\n",
      "Epoch 79/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 0.0283 - val_accuracy: 0.9954\n",
      "Epoch 80/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 0.0282 - val_accuracy: 0.9954\n",
      "Epoch 81/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 0.0281 - val_accuracy: 0.9954\n",
      "Epoch 82/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0066 - accuracy: 0.9987 - val_loss: 0.0281 - val_accuracy: 0.9954\n",
      "Epoch 83/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.0281 - val_accuracy: 0.9954\n",
      "Epoch 84/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.0279 - val_accuracy: 0.9954\n",
      "Epoch 85/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0065 - accuracy: 0.9987 - val_loss: 0.0282 - val_accuracy: 0.9954\n",
      "Epoch 86/1000\n",
      "8/8 [==============================] - 0s 14ms/step - loss: 0.0065 - accuracy: 0.9990 - val_loss: 0.0283 - val_accuracy: 0.9954\n",
      "Epoch 87/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0064 - accuracy: 0.9990 - val_loss: 0.0280 - val_accuracy: 0.9954\n",
      "Epoch 88/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0064 - accuracy: 0.9990 - val_loss: 0.0281 - val_accuracy: 0.9954\n",
      "Epoch 89/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0064 - accuracy: 0.9990 - val_loss: 0.0281 - val_accuracy: 0.9954\n",
      "Epoch 90/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0063 - accuracy: 0.9990 - val_loss: 0.0283 - val_accuracy: 0.9954\n",
      "Epoch 91/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0063 - accuracy: 0.9990 - val_loss: 0.0282 - val_accuracy: 0.9954\n",
      "Epoch 92/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0063 - accuracy: 0.9990 - val_loss: 0.0281 - val_accuracy: 0.9954\n",
      "Epoch 93/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 0.0281 - val_accuracy: 0.9954\n",
      "Epoch 94/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 0.0284 - val_accuracy: 0.9954\n",
      "Epoch 95/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 0.0283 - val_accuracy: 0.9954\n",
      "Epoch 96/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 0.0282 - val_accuracy: 0.9954\n",
      "Epoch 97/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0062 - accuracy: 0.9990 - val_loss: 0.0280 - val_accuracy: 0.9954\n",
      "Epoch 98/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0061 - accuracy: 0.9990 - val_loss: 0.0282 - val_accuracy: 0.9954\n",
      "Epoch 99/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0061 - accuracy: 0.9990 - val_loss: 0.0280 - val_accuracy: 0.9954\n",
      "Epoch 100/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0061 - accuracy: 0.9990 - val_loss: 0.0282 - val_accuracy: 0.9954\n",
      "Epoch 101/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.0283 - val_accuracy: 0.9954\n",
      "Epoch 102/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.0283 - val_accuracy: 0.9954\n",
      "Epoch 103/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.0282 - val_accuracy: 0.9954\n",
      "Epoch 104/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0060 - accuracy: 0.9990 - val_loss: 0.0281 - val_accuracy: 0.9954\n",
      "Epoch 105/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.0282 - val_accuracy: 0.9954\n",
      "Epoch 106/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.0282 - val_accuracy: 0.9954\n",
      "Epoch 107/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.0280 - val_accuracy: 0.9954\n",
      "Epoch 108/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0059 - accuracy: 0.9990 - val_loss: 0.0281 - val_accuracy: 0.9954\n",
      "Epoch 109/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.0283 - val_accuracy: 0.9954\n",
      "Epoch 110/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.0282 - val_accuracy: 0.9954\n",
      "Epoch 111/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.0283 - val_accuracy: 0.9954\n",
      "Epoch 112/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0058 - accuracy: 0.9990 - val_loss: 0.0281 - val_accuracy: 0.9954\n",
      "Epoch 113/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 0.0282 - val_accuracy: 0.9954\n",
      "Epoch 114/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 0.0282 - val_accuracy: 0.9954\n",
      "Epoch 115/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 0.0283 - val_accuracy: 0.9954\n",
      "Epoch 116/1000\n",
      "8/8 [==============================] - 0s 17ms/step - loss: 0.0057 - accuracy: 0.9990 - val_loss: 0.0282 - val_accuracy: 0.9954\n",
      "Epoch 117/1000\n",
      "8/8 [==============================] - 0s 20ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.0284 - val_accuracy: 0.9954\n",
      "Epoch 118/1000\n",
      "8/8 [==============================] - 0s 18ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.0284 - val_accuracy: 0.9954\n",
      "Epoch 119/1000\n",
      "8/8 [==============================] - 0s 22ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.0283 - val_accuracy: 0.9954\n",
      "Epoch 120/1000\n",
      "8/8 [==============================] - 0s 19ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.0284 - val_accuracy: 0.9954\n",
      "Epoch 121/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0056 - accuracy: 0.9990 - val_loss: 0.0283 - val_accuracy: 0.9954\n",
      "Epoch 122/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0055 - accuracy: 0.9990 - val_loss: 0.0283 - val_accuracy: 0.9954\n",
      "Epoch 123/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0055 - accuracy: 0.9990 - val_loss: 0.0284 - val_accuracy: 0.9954\n",
      "Epoch 124/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0055 - accuracy: 0.9990 - val_loss: 0.0285 - val_accuracy: 0.9954\n",
      "Epoch 125/1000\n",
      "8/8 [==============================] - 0s 16ms/step - loss: 0.0055 - accuracy: 0.9990 - val_loss: 0.0284 - val_accuracy: 0.9954\n",
      "Epoch 126/1000\n",
      "8/8 [==============================] - 0s 15ms/step - loss: 0.0055 - accuracy: 0.9990 - val_loss: 0.0284 - val_accuracy: 0.9954\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=1000, batch_size=500, validation_data=(X_valid, y_valid), \n",
    "                   callbacks=[early_stopping_callback, checkpointer])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b7790f",
   "metadata": {},
   "source": [
    "# 저장된 베스트 모델을 불러와서 테스트 하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a33e4706",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3120afa6",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = load_model(\"./model/076--0.0278.keras\")  # .h5"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "330f6774",
   "metadata": {},
   "source": [
    "인공지능 서비스 만들어서 베포한다고할때 만들어진 모델 가져다가 사용한다는것.\n",
    "만들어진 모델 파일 저장하고 다른사람들에게 보내주면 다른 곳에서도 불러와서 사용할 수 있음"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fe24fdc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41/41 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.99      1.00      1.00       980\n",
      "           1       1.00      0.98      0.99       320\n",
      "\n",
      "    accuracy                           1.00      1300\n",
      "   macro avg       1.00      0.99      0.99      1300\n",
      "weighted avg       1.00      1.00      1.00      1300\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 09:23:18.287858: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "best_pred = best_model.predict(X_test)\n",
    "best_pred = pd.DataFrame(best_pred)\n",
    "best_pred = best_pred[0].apply(lambda x: 1 if x > 0.5 else 0)\n",
    "print(classification_report(y_test, best_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "889ae643",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62635433",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa1f84a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179e1c5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b9555ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d0949640",
   "metadata": {},
   "source": [
    "============================================================================================================="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8ce6652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0f09593e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      8.8        6  \n",
       "1      9.5        6  \n",
       "2     10.1        6  \n",
       "3      9.9        6  \n",
       "4      9.9        6  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine = pd.read_csv(\"../06_machine_learning/data/winequality-white.csv\", sep=\";\")\n",
    "wine.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "b3361084",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "quality\n",
       "6    2198\n",
       "5    1457\n",
       "7     880\n",
       "8     175\n",
       "4     163\n",
       "3      20\n",
       "9       5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine['quality'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f3d574a",
   "metadata": {},
   "source": [
    "클래스 많아질수록 예측력은 낮아진다\n",
    "(이진분류는 90퍼 이상 나옴) \n",
    "성능 50퍼밖에 안나온다고 좌절할 필요 없다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e4c612e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine['quality'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f316f41a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4898 entries, 0 to 4897\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         4898 non-null   float64\n",
      " 1   volatile acidity      4898 non-null   float64\n",
      " 2   citric acid           4898 non-null   float64\n",
      " 3   residual sugar        4898 non-null   float64\n",
      " 4   chlorides             4898 non-null   float64\n",
      " 5   free sulfur dioxide   4898 non-null   float64\n",
      " 6   total sulfur dioxide  4898 non-null   float64\n",
      " 7   density               4898 non-null   float64\n",
      " 8   pH                    4898 non-null   float64\n",
      " 9   sulphates             4898 non-null   float64\n",
      " 10  alcohol               4898 non-null   float64\n",
      " 11  quality               4898 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 459.3 KB\n"
     ]
    }
   ],
   "source": [
    "wine.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "2110f494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAiwAAAGdCAYAAAAxCSikAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAtA0lEQVR4nO3df3RU9Z3/8ddkIDPgkoFIyQ8JkSg/JG4wgpLgksKiUageOHok9dBYuiBL0KOYtXXTgFSqUrpVIzWg6WKzVAzRjRhaoRI9xqhEjrgJaREVNRoaJkR+zfBDEjKZ7x8e5uuQH2QgZD6ZPB/n3KP3c9/35n2lZV65987nWrxer1cAAAAGCwt2AwAAAOdCYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGK9fsBvoLq2trdq/f78GDRoki8US7HYAAEAXeL1eHTt2TLGxsQoL6/g6SsgElv379ysuLi7YbQAAgPOwb98+DR8+vMPtIRNYBg0aJOm7E46IiAhyNwAAoCvcbrfi4uJ8n+MdCZnAcuY2UEREBIEFAIBe5lyPc/DQLQAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgvJCZOA5AaPJ4PKqpqdHhw4cVGRmppKQkWa3WYLcFoIcRWAAYq6KiQmvWrFFDQ4NvLDo6WosXL1ZaWloQOwPQ07glBMBIFRUVWr58uRISEpSfn68tW7YoPz9fCQkJWr58uSoqKoLdIoAeZPF6vd5gN9Ed3G63HA6HXC4X7xICejmPx6O5c+cqISFBjz32mN8r51tbW7V06VLV1tbqxRdf5PYQ0Mt19fObKywAjFNTU6OGhgbNnTvXL6xIUlhYmObOnSun06mampogdQigpxFYABjn8OHDkqSRI0e2u/3M+Jk6AKGPwALAOJGRkZKk2tradrefGT9TByD0EVgAGCcpKUnR0dHasGGDWltb/ba1trZqw4YNiomJUVJSUpA6BNDTCCwAjGO1WrV48WJVVlZq6dKl2r17t06ePKndu3dr6dKlqqysVFZWFg/cAn0I3xICYKz25mGJiYlRVlYW87AAIaKrn98EFgBGY6ZbILR19fObmW4BGM1qtSo5OTnYbQAIMp5hAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMF7AgaWiokK33XabYmNjZbFY9Nprr3VaX15eLovF0mb55JNP/OpKSko0btw42Ww2jRs3Tps2bQq0NQAAEKICDiwnTpzQ+PHj9eyzzwa036effiqn0+lbRo0a5dtWWVmpjIwMZWZmateuXcrMzNScOXO0Y8eOQNsDAAAhyOL1er3nvbPFok2bNmn27Nkd1pSXl2vatGk6cuSIBg8e3G5NRkaG3G63tm7d6hu75ZZbNGTIEBUVFXWpF7fbLYfDIZfLpYiIiEBOAwAABElXP7977BmW5ORkxcTEaPr06Xr77bf9tlVWVio9Pd1v7Oabb9b27ds7PF5TU5PcbrffAgAAQtNFDywxMTEqKChQSUmJXn31VY0ZM0bTp09XRUWFr6ahoUFRUVF++0VFRamhoaHD465cuVIOh8O3xMXFXbRzAAAAwdXvYv+AMWPGaMyYMb711NRU7du3T7/73e+UlpbmG7dYLH77eb3eNmPfl5OTo+zsbN+62+0mtAAAEKKC8rXmlJQU7d2717ceHR3d5mpKY2Njm6su32ez2RQREeG3AACA0BSUwFJVVaWYmBjfempqqsrKyvxqtm3bpsmTJ/d0awAAwEAB3xI6fvy4Pv/8c996bW2tqqurFRkZqREjRignJ0f19fVav369JCkvL0+XX365EhMT1dzcrBdffFElJSUqKSnxHeOBBx5QWlqaVq1apVmzZqm0tFRvvvmm3nvvvW44RQAA0NsFHFh27typadOm+dbPPEfy05/+VIWFhXI6naqrq/Ntb25u1kMPPaT6+noNGDBAiYmJev311zVz5kxfzeTJk7Vx40YtXbpUy5Yt0xVXXKHi4mJNmjTpQs4NAACEiAuah8UkzMMCAEDvY9w8LAAAAOeLwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgvIADS0VFhW677TbFxsbKYrHotdde67T+1Vdf1U033aQf/OAHioiIUGpqqt544w2/msLCQlksljbLqVOnAm0PAACEoIADy4kTJzR+/Hg9++yzXaqvqKjQTTfdpC1btuijjz7StGnTdNttt6mqqsqvLiIiQk6n02+x2+2BtgcAAEJQv0B3mDFjhmbMmNHl+ry8PL/1J554QqWlpfrzn/+s5ORk37jFYlF0dHSg7QAAgD6gx59haW1t1bFjxxQZGek3fvz4ccXHx2v48OG69dZb21yBOVtTU5PcbrffAgAAQlOPB5Ynn3xSJ06c0Jw5c3xjY8eOVWFhoTZv3qyioiLZ7XbdcMMN2rt3b4fHWblypRwOh2+Ji4vrifYB9DCPx6Oqqiq99dZbqqqqksfjCXZLAILA4vV6vee9s8WiTZs2afbs2V2qLyoq0oIFC1RaWqobb7yxw7rW1lZde+21SktL0+rVq9utaWpqUlNTk2/d7XYrLi5OLpdLERERAZ0HADNVVFRozZo1amho8I1FR0dr8eLFSktLC2JnALqL2+2Ww+E45+d3j11hKS4u1vz58/Xyyy93GlYkKSwsTNddd12nV1hsNpsiIiL8FgCho6KiQsuXL1dCQoLy8/O1ZcsW5efnKyEhQcuXL1dFRUWwWwTQg3oksBQVFWnevHl66aWX9KMf/eic9V6vV9XV1YqJiemB7gCYxuPxaM2aNUpNTdVjjz2mxMREDRw4UImJiXrssceUmpqqtWvXcnsI6EMCDizHjx9XdXW1qqurJUm1tbWqrq5WXV2dJCknJ0d33323r76oqEh33323nnzySaWkpKihoUENDQ1yuVy+mkcffVRvvPGGvvzyS1VXV2v+/Pmqrq7WokWLLvD0APRGNTU1amho0Ny5cxUW5v/XVFhYmObOnSun06mampogdQigpwUcWHbu3Knk5GTfV5Kzs7OVnJysRx55RJLkdDp94UWSnn/+ebW0tOjee+9VTEyMb3nggQd8NUePHtXChQt11VVXKT09XfX19aqoqND1119/oecHoBc6fPiwJGnkyJHtbj8zfqYOQOgLeB6WqVOnqrPndAsLC/3Wy8vLz3nMp59+Wk8//XSgrQAIUWemPaitrVViYmKb7bW1tX51AEIf7xICYJykpCRFR0drw4YNam1t9dvW2tqqDRs2KCYmRklJSUHqEEBPI7AAMI7VatXixYtVWVmppUuXavfu3Tp58qR2796tpUuXqrKyUllZWbJarcFuFUAPuaB5WEzS1e9xA+g92puHJSYmRllZWczDAoSIrn5+E1gAGM3j8aimpkaHDx9WZGSkkpKSuLIChJCufn4H/NAtAPQkq9Xq96JUAH0Tz7AAAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPH6BbsBAOiMy+VSbm6uDhw4oKioKD3++ONyOBzBbgtADwv4CktFRYVuu+02xcbGymKx6LXXXjvnPu+8844mTJggu92uhIQEPffcc21qSkpKNG7cONlsNo0bN06bNm0KtDUAIWbu3LmaNWuW/v73v+ubb77R3//+d82aNUtz584NdmsAeljAgeXEiRMaP368nn322S7V19bWaubMmZoyZYqqqqr0y1/+Uvfff79KSkp8NZWVlcrIyFBmZqZ27dqlzMxMzZkzRzt27Ai0PQAhYu7cuaqvr5ckjR07VvPmzdPYsWMlSfX19YQWoI+xeL1e73nvbLFo06ZNmj17doc1Dz/8sDZv3qw9e/b4xhYtWqRdu3apsrJSkpSRkSG3262tW7f6am655RYNGTJERUVFXerF7XbL4XDI5XIpIiLi/E4IgBFcLpdmzZolSRo6dKgOHjzo2/b99dLSUm4PAb1cVz+/L/pDt5WVlUpPT/cbu/nmm7Vz506dPn2605rt27d3eNympia53W6/BUBoyM3N9f376NGjlZ+fry1btig/P1+jR49utw5AaLvogaWhoUFRUVF+Y1FRUWppafH9ltRRTUNDQ4fHXblypRwOh2+Ji4vr/uYBBMWBAwckSYmJiXrssceUmJiogQMH+q1/vw5A6OuRrzVbLBa/9TN3ob4/3l7N2WPfl5OTI5fL5Vv27dvXjR0DCKZLLrlE0nd/D4SF+f81FRYWptbWVr86AKHvogeW6OjoNldKGhsb1a9fP1166aWd1px91eX7bDabIiIi/BYAoeGOO+6QJH388cc6efKk37aTJ0/6nok7Uwcg9F30wJKamqqysjK/sW3btmnixInq379/pzWTJ0++2O0BMNDw4cN9/z5z5kz9/Oc/V01NjX7+859r5syZ7dYBCG0BTxx3/Phxff7557712tpaVVdXKzIyUiNGjFBOTo7q6+u1fv16Sd99I+jZZ59Vdna27rnnHlVWVmrdunV+3/554IEHlJaWplWrVmnWrFkqLS3Vm2++qffee68bThFAb5OUlKTo6GgdOXJETU1N+vDDD/Xhhx/6tttsNkVGRiopKSmIXQLoSQFfYdm5c6eSk5OVnJwsScrOzlZycrIeeeQRSZLT6VRdXZ2vfuTIkdqyZYvKy8t1zTXX6Ne//rVWr17tdyl38uTJ2rhxo/74xz8qKSlJhYWFKi4u1qRJky70/AD0QlarVYsXL1Zzc7Ouu+46JSQkaOjQoUpISNB1112n5uZmZWVlyWq1BrtVAD3kguZhMQnzsAChp6KiQmvWrPF7xi0mJkZZWVlKS0sLYmcAuktXP78JLACM5vF4VFNTo8OHD/tuA3FlBQgdXf385uWHAIxmtVp9t6AB9F09Mg8LAADAhSCwAAAA4xFYAACA8QgsAADAeDx0C8Bozc3NKi0t1f79+xUbG6tZs2YpPDw82G0B6GEEFgDGeu655/TKK6/I4/H4jd15551atGhREDsD0NMILACM9Nxzz2njxo0aMmSI5s+fr9TUVN+rPTZu3ChJhBagD2HiOADGaW5u1owZMxQREaFXXnlF/fr9/9+tWlpadOedd8rtdmvr1q3cHgJ6ua5+fvPQLQDjlJaWyuPxaP78+X5hRZL69eunf/u3f5PH41FpaWmQOgTQ0wgsAIyzf/9+SVJqamq728+Mn6kDEPoILACMExsbK0mqrKyUx+NRVVWV3nrrLVVVVcnj8aiystKvDkDo4xkWAMY58wyL3W7XJZdcosbGRt+2YcOG6cSJEzp16hTPsAAhgGdYAPRa4eHhSklJ0YkTJ3TkyBHddddd+tOf/qS77rpLR44c0YkTJ5SSkkJYAfoQvtYMwDgej0dffPGFYmNjdeDAARUVFamoqEjSd29vjo2N1ZdffimPxyOr1RrkbgH0BAILAOPU1NSooaFB+fn5SkhI0PPPP69//OMfGj58uP793/9dX375pe69917V1NQoOTk52O0C6AEEFgDGOXz4sKTvvgX061//Wg0NDZKknTt36oMPPtD8+fP96gCEPgILAONERkZKkp544gmlpqZq2bJlGjlypGpra7VhwwY98cQTfnUAQh8P3QIwTmJioqxWqwYPHqwVK1YoMTFRAwcOVGJiolasWKHBgwfLarUqMTEx2K0C6CEEFgDG2b17tzwej44cOaJHHnlEu3fv1smTJ7V792498sgjOnLkiDwej3bv3h3sVgH0EG4JATDOmWdTcnNztW7dOt17772+bTExMcrNzdXjjz/OMyxAH0JgAWCcM8+mxMbGasOGDaqpqdHhw4cVGRmppKQkffLJJ351AEIft4QAGCcpKUnR0dHasGGDLBaLkpOTNX36dCUnJ8tisWjDhg2KiYlRUlJSsFsF0EMILACMY7VatXjxYlVWVmrp0qV+z7AsXbpUlZWVysrKYtI4oA/hXUIAjFVRUaH8/HwdOHDANxYdHa3FixcrLS0tiJ0B6C68SwhAr/fxxx/rm2++8RtrbGzUxx9/HKSOAAQLD90CMNJzzz2njRs3asiQIRo/frwGDBigb7/9Vrt27dLGjRslSYsWLQpylwB6CreEABinublZM2bMUL9+/dTc3Kzv/zVlsVgUHh6ulpYWbd26lTc2A71cVz+/ucICwDilpaXyeDzyeDxyOBxKTk6W3W7XqVOnVFVVJZfL5au78847g9wtgJ5AYAFgnH379kmS+vfvr+PHj6u8vNy3zWq1qn///jp9+rSvDkDoI7AAMM6hQ4ckSadPn9bgwYN1zTXX+J5hqa6u1tGjR/3qAIQ+AgsA43x/BluXy+V3hcVisbRbByC0EVgAGOf77wjyer0aPXq0LrvsMtXX1+uzzz5rtw5AaCOwADDOkCFD/NY/++wzv6DSUR2A0EVgAWCcI0eO+K13dIXl7DoAoYvAAsA4XGEBcDYCCwDjfP/KyZmZbs/Mw7Jr1y7fdq6wAH0HgQWAcS699FJJUnh4eJtvCYWFhSk8PFzNzc2+OgCh77xefrhmzRqNHDlSdrtdEyZM0Lvvvtth7bx582SxWNosiYmJvprCwsJ2a06dOnU+7QHo5eLi4iR9N0W/w+HQ1KlTdcstt2jq1KlyOBxqbm72qwMQ+gIOLMXFxVqyZIlyc3NVVVWlKVOmaMaMGaqrq2u3/plnnpHT6fQt+/btU2RkZJvptCMiIvzqnE6n7Hb7+Z0VgF5t1qxZslqtstlsvissf/3rX1VeXi6XyyWbzSar1apZs2YFu1UAPSTgwPLUU09p/vz5WrBgga666irl5eUpLi5Oa9eubbfe4XAoOjrat+zcuVNHjhzRz372M786i8XiVxcdHX1+ZwSg1wsPD9edd96ppqYm9e/f329b//791dTUpDvvvJMXHwJ9SECBpbm5WR999JHS09P9xtPT07V9+/YuHWPdunW68cYbFR8f7zd+/PhxxcfHa/jw4br11ltVVVUVSGsAQsyiRYskSU1NTX7jZ9bPbAfQNwQUWA4ePCiPx6OoqCi/8aioKDU0NJxzf6fTqa1bt2rBggV+42PHjlVhYaE2b96soqIi2e123XDDDdq7d2+Hx2pqapLb7fZbAISOqVOnXtB2AKHlvB66/f67PKTvps4+e6w9hYWFGjx4sGbPnu03npKSop/85CcaP368pkyZopdfflmjR4/W73//+w6PtXLlSjkcDt/Cw3dA6HjppZe6tQ5A7xdQYBk6dKisVmubqymNjY1trrqczev16oUXXlBmZuY57zuHhYXpuuuu6/QKS05Ojlwul2/hNfNA6CgoKPBbHzhwoBwOhwYOHNhpHYDQFVBgCQ8P14QJE1RWVuY3XlZWpsmTJ3e67zvvvKPPP/9c8+fPP+fP8Xq9qq6uVkxMTIc1NptNERERfguA0HTy5Em5XC6dPHky2K0ACJKAJ47Lzs5WZmamJk6cqNTUVBUUFKiurs73AFxOTo7q6+u1fv16v/3WrVunSZMm6eqrr25zzEcffVQpKSkaNWqU3G63Vq9ererqauXn55/naQEIJWFhYWptbfX9E0DfE3BgycjI0KFDh7RixQo5nU5dffXV2rJli+9bP06ns82cLC6XSyUlJXrmmWfaPebRo0e1cOFCNTQ0yOFwKDk5WRUVFbr++uvP45QA9HZnpuE/40xIOTusMFcT0HdYvF6vN9hNdAe32y2HwyGXy8XtIaCXu+WWW7o007Xdbtdf//rXHugIwMXS1c/v8/qWEABcTDabrVvrAPR+BBYAxunqvErMvwT0HQQWAABgPAILAOOEhXXtr6au1gHo/fh/OwDjXHnlld1aB6D3I7AAME5jY2O31gHo/QgsAIzTlXeTBVIHoPcjsAAwjsvl6tY6AL0fgQWAcbo6/T7T9AN9B4EFAAAYj8ACwDj9+nXtNWddrQPQ+xFYABinpaWlW+sA9H4EFgDGsVqt3VoHoPcjsAAwDldYAJyNwAIAAIxHYAFgHCaOA3A2AgsA4wwYMKBb6wD0fgQWAMZh4jgAZyOwADDOP/3TP3VrHYDej8ACwDgHDx7s1joAvR+BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYABiHeVgAnI3AAsA4zc3N3VoHoPcjsAAwDm9rBnA2AgsA45x95eTMO4POfncQV1iAvoPAAsB4Xq/X758A+p5+wW4AMNWpU6dUV1cX7DYgqV+/frJarfJ4PGppafHb9tlnnwWpq75txIgRstvtwW4DfQiBBehAXV2dFi5cGOw2IKmlpaVNUDmDP6PgKCgo0OjRo4PdBvoQAgvQgREjRqigoCDYbfRZXQki/PkEz4gRI4LdAvoYAgvQAbvdzm+QQVReXq6pU6d2uh1A38FDtwCMVV5erqeeespv7KmnniKsAH0QgQWA0a699lrfrZ+CggJde+21Qe4IQDAQWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGO+8AsuaNWs0cuRI2e12TZgwQe+++26HteXl5bJYLG2WTz75xK+upKRE48aNk81m07hx47Rp06bzaQ0AAISggANLcXGxlixZotzcXFVVVWnKlCmaMWPGOd+58umnn8rpdPqWUaNG+bZVVlYqIyNDmZmZ2rVrlzIzMzVnzhzt2LEj8DMCAAAhJ+DA8tRTT2n+/PlasGCBrrrqKuXl5SkuLk5r167tdL9hw4YpOjrat1itVt+2vLw83XTTTcrJydHYsWOVk5Oj6dOnKy8vL+ATAgAAoSegwNLc3KyPPvpI6enpfuPp6enavn17p/smJycrJiZG06dP19tvv+23rbKyss0xb7755k6P2dTUJLfb7bcAAIDQFFBgOXjwoDwej6KiovzGo6Ki1NDQ0O4+MTExKigoUElJiV599VWNGTNG06dPV0VFha+moaEhoGNK0sqVK+VwOHxLXFxcIKcCAAB6kfN6+aHFYvFb93q9bcbOGDNmjMaMGeNbT01N1b59+/S73/1OaWlp53VMScrJyVF2drZv3e12E1oAAAhRAV1hGTp0qKxWa5srH42NjW2ukHQmJSVFe/fu9a1HR0cHfEybzaaIiAi/BQAAhKaAAkt4eLgmTJigsrIyv/GysjJNnjy5y8epqqpSTEyMbz01NbXNMbdt2xbQMQEAQOgK+JZQdna2MjMzNXHiRKWmpqqgoEB1dXVatGiRpO9u1dTX12v9+vWSvvsG0OWXX67ExEQ1NzfrxRdfVElJiUpKSnzHfOCBB5SWlqZVq1Zp1qxZKi0t1Ztvvqn33nuvm04TAAD0ZgEHloyMDB06dEgrVqyQ0+nU1VdfrS1btig+Pl6S5HQ6/eZkaW5u1kMPPaT6+noNGDBAiYmJev311zVz5kxfzeTJk7Vx40YtXbpUy5Yt0xVXXKHi4mJNmjSpG04RAAD0dhav1+sNdhPdwe12y+FwyOVy8TwLEGI+++wzLVy4UAUFBRo9enSw2wHQjbr6+c27hAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADG6xfsBuDvwIEDcrlcwW4DMMrXX3/t908A33E4HIqKigp2Gz3C4vV6vcFuoju43W45HA65XC5FREQEu53zcuDAAf0k826dbm4KdisAgF6gf7hNL/5pfa8OLV39/OYKi0FcLpdONzfp24QfqtXuCHY7AACDhZ1ySV++I5fL1asDS1cRWAzUaneo9ZKhwW4DAABj8NAtAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADjEVgAAIDxCCwAAMB4BBYAAGA8AgsAADAegQUAABiPqfkNFPbt0WC3AAAwXF/7rCCwGGhAbUWwWwAAwCgEFgN9OzJNrQMGB7sNAIDBwr492qd+wSWwGKh1wGDe1gwAwPfw0C0AADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPH4WrOBwk65gt0CAMBwfe2z4rwCy5o1a/Rf//VfcjqdSkxMVF5enqZMmdJu7auvvqq1a9equrpaTU1NSkxM1K9+9SvdfPPNvprCwkL97Gc/a7Pvt99+K7vdfj4t9koOh0P9w23Sl+8EuxUAQC/QP9wmh8MR7DZ6RMCBpbi4WEuWLNGaNWt0ww036Pnnn9eMGTP08ccfa8SIEW3qKyoqdNNNN+mJJ57Q4MGD9cc//lG33XabduzYoeTkZF9dRESEPv30U799+1JYkaSoqCi9+Kf1crn6VmoGzuXrr7/W448/rtzcXMXHxwe7HcAYDodDUVFRwW6jRwQcWJ566inNnz9fCxYskCTl5eXpjTfe0Nq1a7Vy5co29Xl5eX7rTzzxhEpLS/XnP//ZL7BYLBZFR0cH2k7IiYqK6jP/4wMCFR8fr9GjRwe7DQBBENBDt83Nzfroo4+Unp7uN56enq7t27d36Ritra06duyYIiMj/caPHz+u+Ph4DR8+XLfeequqqqo6PU5TU5PcbrffAgAAQlNAgeXgwYPyeDxtrgBERUWpoaGhS8d48skndeLECc2ZM8c3NnbsWBUWFmrz5s0qKiqS3W7XDTfcoL1793Z4nJUrV8rhcPiWuLi4QE4FAAD0Iuf1tWaLxeK37vV624y1p6ioSL/61a9UXFysYcOG+cZTUlL0k5/8ROPHj9eUKVP08ssva/To0fr973/f4bFycnLkcrl8y759+87nVAAAQC8Q0DMsQ4cOldVqbXM1pbGx8ZzPXRQXF2v+/Pl65ZVXdOONN3ZaGxYWpuuuu67TKyw2m002m63rzQMAgF4roCss4eHhmjBhgsrKyvzGy8rKNHny5A73Kyoq0rx58/TSSy/pRz/60Tl/jtfrVXV1tWJiYgJpDwAAhKiAvyWUnZ2tzMxMTZw4UampqSooKFBdXZ0WLVok6btbNfX19Vq/fr2k78LK3XffrWeeeUYpKSm+qzMDBgzwfXf80UcfVUpKikaNGiW3263Vq1erurpa+fn53XWeAACgFws4sGRkZOjQoUNasWKFnE6nrr76am3ZssU3N4LT6VRdXZ2v/vnnn1dLS4vuvfde3Xvvvb7xn/70pyosLJQkHT16VAsXLlRDQ4McDoeSk5NVUVGh66+//gJPDwAAhAKL1+v1BruJ7uB2u+VwOORyuRQRERHsdgB0o88++0wLFy5UQUEB87AAIaarn9+8/BAAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgPAILAAAwHoEFAAAYj8ACAACMR2ABAADGI7AAAADjEVgAGO2rr75SVlaWJCkrK0tfffVVcBsCEBT9gt0AAHRk2rRp8nq9vnWPx6N58+bJYrHo7bffDmJnAHoagQXowKlTp1RXVxfsNvqshQsXdrjN6/Vq6tSpKigo6MGO8H0jRoyQ3W4PdhvoQwgsQAfq6uo6/dBE8PHnEzwFBQUaPXp0sNtAH0JgATowYsQIfoMPkqysLHk8nnPWWa1WrV27tgc6wtlGjBgR7BbQxxBYgA7Y7XZ+gwySroSVM3X8GQF9A98SAtAr2Gy2YLcAIIgILACMM3jw4DZjTU1NXaoDEJoILACMc/To0TZjVqu1S3UAQhOBBUCv0NXnWgCEJgILAAAwHoEFgHG6OiEZE5cBfQeBBYBxAvlaM4C+gcACwDjh4eHdWgeg9yOwADDOiRMnurUOQO9HYAEAAMYjsAAwjsVi6dY6AL0fgQWAcW644YZurQPQ+xFYABhn9+7d3VoHoPc7r8CyZs0ajRw5Una7XRMmTNC7777baf0777yjCRMmyG63KyEhQc8991ybmpKSEo0bN042m03jxo3Tpk2bzqc1ACGgvfcGXUgdgN4v4MBSXFysJUuWKDc3V1VVVZoyZYpmzJihurq6dutra2s1c+ZMTZkyRVVVVfrlL3+p+++/XyUlJb6ayspKZWRkKDMzU7t27VJmZqbmzJmjHTt2nP+ZAei1Tp061a11AHo/i9fr9Qayw6RJk3Tttddq7dq1vrGrrrpKs2fP1sqVK9vUP/zww9q8ebP27NnjG1u0aJF27dqlyspKSVJGRobcbre2bt3qq7nllls0ZMgQFRUVdakvt9sth8Mhl8uliIiIQE4JgGGmTp3a5dry8vKL1geAi6+rn98BXWFpbm7WRx99pPT0dL/x9PR0bd++vd19Kisr29TffPPN2rlzp06fPt1pTUfHlL67FOx2u/0WAKFp2LBhSklJ0bBhw4LdCoAgCSiwHDx4UB6PR1FRUX7jUVFRamhoaHefhoaGdutbWlp08ODBTms6OqYkrVy5Ug6Hw7fExcUFcioAepHGxkZ98MEHamxsDHYrAILkvB66PXvuA6/X2+l8CO3Vnz0e6DFzcnLkcrl8y759+7rcP4DepV+/frLb7erXr1+wWwEQJAEFlqFDh8pqtba58tHY2NjmCskZ0dHR7db369dPl156aac1HR1Tkmw2myIiIvwWAKFh9erVfustLS06deqUWlpaOq0DELoCCizh4eGaMGGCysrK/MbLyso0efLkdvdJTU1tU79t2zZNnDhR/fv377Smo2MCCG1JSUndWgeg9wv4llB2drb++7//Wy+88IL27NmjBx98UHV1dVq0aJGk727V3H333b76RYsW6euvv1Z2drb27NmjF154QevWrdNDDz3kq3nggQe0bds2rVq1Sp988olWrVqlN998U0uWLLnwMwTQK53r2z98OwjoWwK+IZyRkaFDhw5pxYoVcjqduvrqq7VlyxbFx8dLkpxOp9+cLCNHjtSWLVv04IMPKj8/X7GxsVq9erXuuOMOX83kyZO1ceNGLV26VMuWLdMVV1yh4uJiTZo0qRtOEUBvVV5erpqaGt1///2+sdWrV3NlBeiDAp6HxVTMwwIAQO9zUeZhAQAACAYCCwAAMB6BBQAAGI/AAgAAjEdgAQAAxiOwAAAA4xFYAACA8QgsAADAeAQWAABgvJB5V/uZCXvdbneQOwEAAF115nP7XBPvh0xgOXbsmCQpLi4uyJ0AAIBAHTt2TA6Ho8PtIfMuodbWVu3fv1+DBg2SxWIJdjsAupHb7VZcXJz27dvHu8KAEOP1enXs2DHFxsYqLKzjJ1VCJrAACF283BQAD90CAADjEVgAAIDxCCwAjGez2bR8+XLZbLZgtwIgSHiGBQAAGI8rLAAAwHgEFgAAYDwCCwAAMB6BBcAF+eqrr2SxWFRdXX1e+1ssFr322mvd2lMgLr/8cuXl5XVaE+weAYTQ1PwAgiMuLk5Op1NDhw6VJJWXl2vatGk6cuSIBg8efM79nU6nhgwZcpG77NiHH36oSy65JGg/H0DXEFgAXBCr1aro6OiA92tublZ4ePh57dudfvCDHwT15wPoGm4JATin1tZWrVq1SldeeaVsNptGjBihxx9/XJL/LaGvvvpK06ZNkyQNGTJEFotF8+bNkyRNnTpV9913n7KzszV06FDddNNNktrebvnHP/6hH//4x4qMjNQll1yiiRMnaseOHR329vDDD2v06NEaOHCgEhIStGzZMp0+fdqvZvPmzZo4caLsdruGDh2q22+/3bft7FtCe/fuVVpamux2u8aNG6eysrIL+U8HoJtwhQXAOeXk5OgPf/iDnn76af3Lv/yLnE6nPvnkkzZ1cXFxKikp0R133KFPP/1UERERGjBggG/7//zP/ygrK0vvv/9+u6+SP378uH74wx/qsssu0+bNmxUdHa3/+7//U2tra4e9DRo0SIWFhYqNjdXf/vY33XPPPRo0aJB+8YtfSJJef/113X777crNzdWf/vQnNTc36/XXX2/3WK2trbr99ts1dOhQffDBB3K73VqyZEmA/7UAXBReAOiE2+322mw27x/+8Id2t9fW1noleauqqrxer9f79ttveyV5jxw54lf3wx/+0HvNNde02V+Sd9OmTV6v1+t9/vnnvYMGDfIeOnTovPv97W9/650wYYJvPTU11Tt37twO6+Pj471PP/201+v1et944w2v1Wr17tu3z7d969atfj0CCA6usADo1J49e9TU1KTp06df8LEmTpzY6fbq6molJycrMjKyy8f83//9X+Xl5enzzz/X8ePH1dLS4vdG5+rqat1zzz1dOtaePXs0YsQIDR8+3DeWmpra5V4AXDw8wwKgU9+/pXOhzvVtnEB/1gcffKAf//jHmjFjhv7yl7+oqqpKubm5am5uPq9jetu5TWWxWALqCcDFQWAB0KlRo0ZpwIABeuutt7pUHx4eLknyeDwB/6ykpCRVV1fr8OHDXap///33FR8fr9zcXE2cOFGjRo3S119/3eaYXe193Lhxqqur0/79+31jlZWVXT8BABcNgQVAp+x2ux5++GH94he/0Pr16/XFF1/ogw8+0Lp169qtj4+Pl8Vi0V/+8hd98803On78eJd/1l133aXo6GjNnj1b77//vr788kuVlJR0GBquvPJK1dXVaePGjfriiy+0evVqbdq0ya9m+fLlKioq0vLly7Vnzx797W9/029/+9t2j3fjjTdqzJgxuvvuu7Vr1y69++67ys3N7XL/AC4eAguAc1q2bJn+4z/+Q4888oiuuuoqZWRkqLGxsd3ayy67TI8++qj+8z//U1FRUbrvvvu6/HPCw8O1bds2DRs2TDNnztQ///M/6ze/+Y2sVmu79bNmzdKDDz6o++67T9dcc422b9+uZcuW+dVMnTpVr7zyijZv3qxrrrlG//qv/9rh16TDwsK0adMmNTU16frrr9eCBQt8X98GEFwWb3s3bQEAAAzCFRYAAGA8AgsAADAegQUAABiPwAIAAIxHYAEAAMYjsAAAAOMRWAAAgPEILAAAwHgEFgAAYDwCCwAAMB6BBQAAGI/AAgAAjPf/ADlo215lsV2ZAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.boxplot(wine.iloc[:,2:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "d7a1902f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "2dea8133",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = wine.drop('quality', axis=1).copy()\n",
    "y = wine['quality'].copy()\n",
    "y2 = wine['quality'].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "42d0e8e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.0</td>\n",
       "      <td>0.27</td>\n",
       "      <td>0.36</td>\n",
       "      <td>20.7</td>\n",
       "      <td>0.045</td>\n",
       "      <td>45.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>1.0010</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.45</td>\n",
       "      <td>8.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.34</td>\n",
       "      <td>1.6</td>\n",
       "      <td>0.049</td>\n",
       "      <td>14.0</td>\n",
       "      <td>132.0</td>\n",
       "      <td>0.9940</td>\n",
       "      <td>3.30</td>\n",
       "      <td>0.49</td>\n",
       "      <td>9.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>8.1</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.40</td>\n",
       "      <td>6.9</td>\n",
       "      <td>0.050</td>\n",
       "      <td>30.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>0.9951</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.44</td>\n",
       "      <td>10.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.23</td>\n",
       "      <td>0.32</td>\n",
       "      <td>8.5</td>\n",
       "      <td>0.058</td>\n",
       "      <td>47.0</td>\n",
       "      <td>186.0</td>\n",
       "      <td>0.9956</td>\n",
       "      <td>3.19</td>\n",
       "      <td>0.40</td>\n",
       "      <td>9.9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.0              0.27         0.36            20.7      0.045   \n",
       "1            6.3              0.30         0.34             1.6      0.049   \n",
       "2            8.1              0.28         0.40             6.9      0.050   \n",
       "3            7.2              0.23         0.32             8.5      0.058   \n",
       "4            7.2              0.23         0.32             8.5      0.058   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 45.0                 170.0   1.0010  3.00       0.45   \n",
       "1                 14.0                 132.0   0.9940  3.30       0.49   \n",
       "2                 30.0                  97.0   0.9951  3.26       0.44   \n",
       "3                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "4                 47.0                 186.0   0.9956  3.19       0.40   \n",
       "\n",
       "   alcohol  \n",
       "0      8.8  \n",
       "1      9.5  \n",
       "2     10.1  \n",
       "3      9.9  \n",
       "4      9.9  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9d4bc6e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    6\n",
       "1    6\n",
       "2    6\n",
       "3    6\n",
       "4    6\n",
       "Name: quality, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "441fdadf",
   "metadata": {},
   "outputs": [],
   "source": [
    "rbs = RobustScaler()\n",
    "X_scaled = rbs.fit_transform(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "2fdee19c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4893</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4894</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4895</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4896</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4897</th>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4898 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          3      4      5      6      7      8      9\n",
       "0     False  False  False   True  False  False  False\n",
       "1     False  False  False   True  False  False  False\n",
       "2     False  False  False   True  False  False  False\n",
       "3     False  False  False   True  False  False  False\n",
       "4     False  False  False   True  False  False  False\n",
       "...     ...    ...    ...    ...    ...    ...    ...\n",
       "4893  False  False  False   True  False  False  False\n",
       "4894  False  False   True  False  False  False  False\n",
       "4895  False  False  False   True  False  False  False\n",
       "4896  False  False  False  False   True  False  False\n",
       "4897  False  False  False   True  False  False  False\n",
       "\n",
       "[4898 rows x 7 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = pd.get_dummies(y)\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "dac84769",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dbdd39ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_valid, y_train, y_valid = train_test_split(X_scaled, y, test_size=0.4, stratify=y, random_state=10)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_valid, y_valid, test_size=0.5, stratify=y_valid, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "2ece8259",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2938, 11) (980, 11) (980, 11)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_valid.shape, X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d30503e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential, Model, load_model\n",
    "from tensorflow.keras.layers import Dense, Input\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "9e7b77fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_4 (Dense)             (None, 32)                384       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 7)                 119       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 5,223\n",
      "Trainable params: 5,223\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))\n",
    "model.add(Dense(64, activation='relu'))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(16, activation='relu'))\n",
    "model.add(Dense(7, activation='softmax'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f5033d38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 09:26:58.844828: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-11 09:26:58.895592: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-11 09:26:58.895651: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 1s 57ms/step - loss: 1.8798 - accuracy: 0.3264 - val_loss: 1.8169 - val_accuracy: 0.4020\n",
      "Epoch 2/10000\n",
      "6/6 [==============================] - ETA: 0s - loss: 1.7746 - accuracy: 0.4112"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 09:26:59.302707: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-11 09:26:59.328595: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-11 09:26:59.328680: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 33ms/step - loss: 1.7746 - accuracy: 0.4112 - val_loss: 1.7087 - val_accuracy: 0.4316\n",
      "Epoch 3/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 1.6644 - accuracy: 0.4370 - val_loss: 1.5924 - val_accuracy: 0.4500\n",
      "Epoch 4/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.5530 - accuracy: 0.4455 - val_loss: 1.4828 - val_accuracy: 0.4480\n",
      "Epoch 5/10000\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 1.4554 - accuracy: 0.4503 - val_loss: 1.3974 - val_accuracy: 0.4490\n",
      "Epoch 6/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.3746 - accuracy: 0.4541 - val_loss: 1.3359 - val_accuracy: 0.4673\n",
      "Epoch 7/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.3184 - accuracy: 0.4803 - val_loss: 1.2988 - val_accuracy: 0.4929\n",
      "Epoch 8/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.2814 - accuracy: 0.4983 - val_loss: 1.2745 - val_accuracy: 0.5041\n",
      "Epoch 9/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.2528 - accuracy: 0.5068 - val_loss: 1.2572 - val_accuracy: 0.5122\n",
      "Epoch 10/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.2278 - accuracy: 0.5071 - val_loss: 1.2417 - val_accuracy: 0.5071\n",
      "Epoch 11/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.2081 - accuracy: 0.5078 - val_loss: 1.2291 - val_accuracy: 0.5071\n",
      "Epoch 12/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.1916 - accuracy: 0.5235 - val_loss: 1.2166 - val_accuracy: 0.5204\n",
      "Epoch 13/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.1764 - accuracy: 0.5265 - val_loss: 1.2036 - val_accuracy: 0.5347\n",
      "Epoch 14/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.1618 - accuracy: 0.5405 - val_loss: 1.1910 - val_accuracy: 0.5459\n",
      "Epoch 15/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.1480 - accuracy: 0.5456 - val_loss: 1.1790 - val_accuracy: 0.5490\n",
      "Epoch 16/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.1354 - accuracy: 0.5517 - val_loss: 1.1678 - val_accuracy: 0.5602\n",
      "Epoch 17/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.1238 - accuracy: 0.5534 - val_loss: 1.1576 - val_accuracy: 0.5541\n",
      "Epoch 18/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.1119 - accuracy: 0.5558 - val_loss: 1.1483 - val_accuracy: 0.5520\n",
      "Epoch 19/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.1015 - accuracy: 0.5555 - val_loss: 1.1387 - val_accuracy: 0.5510\n",
      "Epoch 20/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.0921 - accuracy: 0.5606 - val_loss: 1.1310 - val_accuracy: 0.5480\n",
      "Epoch 21/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.0841 - accuracy: 0.5609 - val_loss: 1.1235 - val_accuracy: 0.5429\n",
      "Epoch 22/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.0785 - accuracy: 0.5654 - val_loss: 1.1174 - val_accuracy: 0.5439\n",
      "Epoch 23/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.0689 - accuracy: 0.5671 - val_loss: 1.1128 - val_accuracy: 0.5520\n",
      "Epoch 24/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.0616 - accuracy: 0.5684 - val_loss: 1.1077 - val_accuracy: 0.5459\n",
      "Epoch 25/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.0575 - accuracy: 0.5715 - val_loss: 1.1025 - val_accuracy: 0.5490\n",
      "Epoch 26/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.0505 - accuracy: 0.5728 - val_loss: 1.1002 - val_accuracy: 0.5510\n",
      "Epoch 27/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.0451 - accuracy: 0.5732 - val_loss: 1.0971 - val_accuracy: 0.5388\n",
      "Epoch 28/10000\n",
      "6/6 [==============================] - 0s 28ms/step - loss: 1.0401 - accuracy: 0.5742 - val_loss: 1.0922 - val_accuracy: 0.5490\n",
      "Epoch 29/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.0355 - accuracy: 0.5708 - val_loss: 1.0893 - val_accuracy: 0.5490\n",
      "Epoch 30/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.0318 - accuracy: 0.5769 - val_loss: 1.0874 - val_accuracy: 0.5439\n",
      "Epoch 31/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.0269 - accuracy: 0.5759 - val_loss: 1.0837 - val_accuracy: 0.5469\n",
      "Epoch 32/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.0226 - accuracy: 0.5803 - val_loss: 1.0823 - val_accuracy: 0.5480\n",
      "Epoch 33/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 1.0171 - accuracy: 0.5820 - val_loss: 1.0796 - val_accuracy: 0.5551\n",
      "Epoch 34/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.0145 - accuracy: 0.5851 - val_loss: 1.0782 - val_accuracy: 0.5500\n",
      "Epoch 35/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 1.0110 - accuracy: 0.5837 - val_loss: 1.0768 - val_accuracy: 0.5459\n",
      "Epoch 36/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.0063 - accuracy: 0.5885 - val_loss: 1.0743 - val_accuracy: 0.5612\n",
      "Epoch 37/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.0027 - accuracy: 0.5933 - val_loss: 1.0713 - val_accuracy: 0.5561\n",
      "Epoch 38/10000\n",
      "6/6 [==============================] - 0s 27ms/step - loss: 0.9984 - accuracy: 0.5933 - val_loss: 1.0686 - val_accuracy: 0.5612\n",
      "Epoch 39/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.9951 - accuracy: 0.5950 - val_loss: 1.0676 - val_accuracy: 0.5643\n",
      "Epoch 40/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.9920 - accuracy: 0.5956 - val_loss: 1.0669 - val_accuracy: 0.5622\n",
      "Epoch 41/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.9913 - accuracy: 0.5984 - val_loss: 1.0651 - val_accuracy: 0.5602\n",
      "Epoch 42/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.9873 - accuracy: 0.5946 - val_loss: 1.0639 - val_accuracy: 0.5571\n",
      "Epoch 43/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.9838 - accuracy: 0.5994 - val_loss: 1.0628 - val_accuracy: 0.5551\n",
      "Epoch 44/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.9787 - accuracy: 0.6007 - val_loss: 1.0606 - val_accuracy: 0.5633\n",
      "Epoch 45/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.9759 - accuracy: 0.6007 - val_loss: 1.0589 - val_accuracy: 0.5592\n",
      "Epoch 46/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.9731 - accuracy: 0.6072 - val_loss: 1.0582 - val_accuracy: 0.5571\n",
      "Epoch 47/10000\n",
      "6/6 [==============================] - 0s 32ms/step - loss: 0.9696 - accuracy: 0.6004 - val_loss: 1.0576 - val_accuracy: 0.5510\n",
      "Epoch 48/10000\n",
      "6/6 [==============================] - 0s 31ms/step - loss: 0.9677 - accuracy: 0.6031 - val_loss: 1.0571 - val_accuracy: 0.5602\n",
      "Epoch 49/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.9650 - accuracy: 0.6052 - val_loss: 1.0550 - val_accuracy: 0.5582\n",
      "Epoch 50/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.9604 - accuracy: 0.6069 - val_loss: 1.0538 - val_accuracy: 0.5551\n",
      "Epoch 51/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.9585 - accuracy: 0.6072 - val_loss: 1.0519 - val_accuracy: 0.5633\n",
      "Epoch 52/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.9540 - accuracy: 0.6093 - val_loss: 1.0513 - val_accuracy: 0.5592\n",
      "Epoch 53/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.9523 - accuracy: 0.6093 - val_loss: 1.0516 - val_accuracy: 0.5561\n",
      "Epoch 54/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.9491 - accuracy: 0.6099 - val_loss: 1.0507 - val_accuracy: 0.5541\n",
      "Epoch 55/10000\n",
      "6/6 [==============================] - 0s 41ms/step - loss: 0.9458 - accuracy: 0.6123 - val_loss: 1.0504 - val_accuracy: 0.5571\n",
      "Epoch 56/10000\n",
      "6/6 [==============================] - 0s 38ms/step - loss: 0.9434 - accuracy: 0.6113 - val_loss: 1.0500 - val_accuracy: 0.5592\n",
      "Epoch 57/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.9417 - accuracy: 0.6103 - val_loss: 1.0497 - val_accuracy: 0.5531\n",
      "Epoch 58/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.9387 - accuracy: 0.6137 - val_loss: 1.0488 - val_accuracy: 0.5510\n",
      "Epoch 59/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.9355 - accuracy: 0.6157 - val_loss: 1.0473 - val_accuracy: 0.5500\n",
      "Epoch 60/10000\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.9324 - accuracy: 0.6174 - val_loss: 1.0464 - val_accuracy: 0.5510\n",
      "Epoch 61/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.9288 - accuracy: 0.6198 - val_loss: 1.0493 - val_accuracy: 0.5459\n",
      "Epoch 62/10000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.9289 - accuracy: 0.6161 - val_loss: 1.0467 - val_accuracy: 0.5531\n",
      "Epoch 63/10000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.9234 - accuracy: 0.6164 - val_loss: 1.0474 - val_accuracy: 0.5551\n",
      "Epoch 64/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.9204 - accuracy: 0.6219 - val_loss: 1.0467 - val_accuracy: 0.5500\n",
      "Epoch 65/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.9183 - accuracy: 0.6184 - val_loss: 1.0448 - val_accuracy: 0.5571\n",
      "Epoch 66/10000\n",
      "6/6 [==============================] - 0s 29ms/step - loss: 0.9169 - accuracy: 0.6212 - val_loss: 1.0443 - val_accuracy: 0.5510\n",
      "Epoch 67/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.9151 - accuracy: 0.6263 - val_loss: 1.0489 - val_accuracy: 0.5490\n",
      "Epoch 68/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.9119 - accuracy: 0.6287 - val_loss: 1.0491 - val_accuracy: 0.5531\n",
      "Epoch 69/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.9096 - accuracy: 0.6178 - val_loss: 1.0490 - val_accuracy: 0.5510\n",
      "Epoch 70/10000\n",
      "6/6 [==============================] - 0s 15ms/step - loss: 0.9065 - accuracy: 0.6300 - val_loss: 1.0462 - val_accuracy: 0.5520\n",
      "Epoch 71/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.9046 - accuracy: 0.6283 - val_loss: 1.0461 - val_accuracy: 0.5582\n",
      "Epoch 72/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.9008 - accuracy: 0.6293 - val_loss: 1.0478 - val_accuracy: 0.5520\n",
      "Epoch 73/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8984 - accuracy: 0.6372 - val_loss: 1.0451 - val_accuracy: 0.5490\n",
      "Epoch 74/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8971 - accuracy: 0.6300 - val_loss: 1.0528 - val_accuracy: 0.5490\n",
      "Epoch 75/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8985 - accuracy: 0.6324 - val_loss: 1.0529 - val_accuracy: 0.5551\n",
      "Epoch 76/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8969 - accuracy: 0.6242 - val_loss: 1.0471 - val_accuracy: 0.5510\n",
      "Epoch 77/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8925 - accuracy: 0.6327 - val_loss: 1.0476 - val_accuracy: 0.5551\n",
      "Epoch 78/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8893 - accuracy: 0.6399 - val_loss: 1.0485 - val_accuracy: 0.5571\n",
      "Epoch 79/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8831 - accuracy: 0.6341 - val_loss: 1.0493 - val_accuracy: 0.5500\n",
      "Epoch 80/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8813 - accuracy: 0.6430 - val_loss: 1.0492 - val_accuracy: 0.5510\n",
      "Epoch 81/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8809 - accuracy: 0.6341 - val_loss: 1.0474 - val_accuracy: 0.5541\n",
      "Epoch 82/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8771 - accuracy: 0.6392 - val_loss: 1.0443 - val_accuracy: 0.5531\n",
      "Epoch 83/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8729 - accuracy: 0.6396 - val_loss: 1.0459 - val_accuracy: 0.5571\n",
      "Epoch 84/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8712 - accuracy: 0.6389 - val_loss: 1.0457 - val_accuracy: 0.5571\n",
      "Epoch 85/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8700 - accuracy: 0.6491 - val_loss: 1.0464 - val_accuracy: 0.5633\n",
      "Epoch 86/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8676 - accuracy: 0.6433 - val_loss: 1.0471 - val_accuracy: 0.5561\n",
      "Epoch 87/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8657 - accuracy: 0.6511 - val_loss: 1.0476 - val_accuracy: 0.5459\n",
      "Epoch 88/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8629 - accuracy: 0.6484 - val_loss: 1.0489 - val_accuracy: 0.5520\n",
      "Epoch 89/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.8586 - accuracy: 0.6498 - val_loss: 1.0484 - val_accuracy: 0.5571\n",
      "Epoch 90/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8580 - accuracy: 0.6491 - val_loss: 1.0479 - val_accuracy: 0.5561\n",
      "Epoch 91/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8541 - accuracy: 0.6484 - val_loss: 1.0510 - val_accuracy: 0.5633\n",
      "Epoch 92/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8529 - accuracy: 0.6576 - val_loss: 1.0513 - val_accuracy: 0.5561\n",
      "Epoch 93/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8506 - accuracy: 0.6545 - val_loss: 1.0480 - val_accuracy: 0.5541\n",
      "Epoch 94/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.8479 - accuracy: 0.6521 - val_loss: 1.0510 - val_accuracy: 0.5561\n",
      "Epoch 95/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8454 - accuracy: 0.6545 - val_loss: 1.0511 - val_accuracy: 0.5633\n",
      "Epoch 96/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8452 - accuracy: 0.6627 - val_loss: 1.0542 - val_accuracy: 0.5592\n",
      "Epoch 97/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8436 - accuracy: 0.6535 - val_loss: 1.0515 - val_accuracy: 0.5531\n",
      "Epoch 98/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8381 - accuracy: 0.6600 - val_loss: 1.0516 - val_accuracy: 0.5653\n",
      "Epoch 99/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8376 - accuracy: 0.6617 - val_loss: 1.0559 - val_accuracy: 0.5520\n",
      "Epoch 100/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8381 - accuracy: 0.6579 - val_loss: 1.0547 - val_accuracy: 0.5653\n",
      "Epoch 101/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8336 - accuracy: 0.6586 - val_loss: 1.0564 - val_accuracy: 0.5551\n",
      "Epoch 102/10000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8364 - accuracy: 0.6583 - val_loss: 1.0571 - val_accuracy: 0.5561\n",
      "Epoch 103/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.8298 - accuracy: 0.6620 - val_loss: 1.0549 - val_accuracy: 0.5653\n",
      "Epoch 104/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8251 - accuracy: 0.6671 - val_loss: 1.0568 - val_accuracy: 0.5582\n",
      "Epoch 105/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8231 - accuracy: 0.6664 - val_loss: 1.0595 - val_accuracy: 0.5480\n",
      "Epoch 106/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8225 - accuracy: 0.6664 - val_loss: 1.0584 - val_accuracy: 0.5520\n",
      "Epoch 107/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8207 - accuracy: 0.6678 - val_loss: 1.0596 - val_accuracy: 0.5551\n",
      "Epoch 108/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8161 - accuracy: 0.6668 - val_loss: 1.0609 - val_accuracy: 0.5531\n",
      "Epoch 109/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8179 - accuracy: 0.6705 - val_loss: 1.0598 - val_accuracy: 0.5551\n",
      "Epoch 110/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8152 - accuracy: 0.6719 - val_loss: 1.0625 - val_accuracy: 0.5571\n",
      "Epoch 111/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.8110 - accuracy: 0.6702 - val_loss: 1.0611 - val_accuracy: 0.5531\n",
      "Epoch 112/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.8093 - accuracy: 0.6736 - val_loss: 1.0583 - val_accuracy: 0.5592\n",
      "Epoch 113/10000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8056 - accuracy: 0.6722 - val_loss: 1.0635 - val_accuracy: 0.5531\n",
      "Epoch 114/10000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.8047 - accuracy: 0.6753 - val_loss: 1.0641 - val_accuracy: 0.5480\n",
      "Epoch 115/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.8037 - accuracy: 0.6811 - val_loss: 1.0721 - val_accuracy: 0.5510\n",
      "Epoch 116/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 21ms/step - loss: 0.8036 - accuracy: 0.6767 - val_loss: 1.0657 - val_accuracy: 0.5531\n",
      "Epoch 117/10000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.7970 - accuracy: 0.6746 - val_loss: 1.0669 - val_accuracy: 0.5510\n",
      "Epoch 118/10000\n",
      "6/6 [==============================] - 0s 24ms/step - loss: 0.7955 - accuracy: 0.6821 - val_loss: 1.0679 - val_accuracy: 0.5490\n",
      "Epoch 119/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7927 - accuracy: 0.6756 - val_loss: 1.0665 - val_accuracy: 0.5561\n",
      "Epoch 120/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7922 - accuracy: 0.6811 - val_loss: 1.0678 - val_accuracy: 0.5551\n",
      "Epoch 121/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7912 - accuracy: 0.6804 - val_loss: 1.0720 - val_accuracy: 0.5551\n",
      "Epoch 122/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7872 - accuracy: 0.6818 - val_loss: 1.0718 - val_accuracy: 0.5582\n",
      "Epoch 123/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7854 - accuracy: 0.6862 - val_loss: 1.0724 - val_accuracy: 0.5541\n",
      "Epoch 124/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7840 - accuracy: 0.6804 - val_loss: 1.0759 - val_accuracy: 0.5541\n",
      "Epoch 125/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7825 - accuracy: 0.6818 - val_loss: 1.0729 - val_accuracy: 0.5551\n",
      "Epoch 126/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7781 - accuracy: 0.6814 - val_loss: 1.0732 - val_accuracy: 0.5510\n",
      "Epoch 127/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7759 - accuracy: 0.6858 - val_loss: 1.0792 - val_accuracy: 0.5612\n",
      "Epoch 128/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7779 - accuracy: 0.6862 - val_loss: 1.0852 - val_accuracy: 0.5602\n",
      "Epoch 129/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7795 - accuracy: 0.6835 - val_loss: 1.0875 - val_accuracy: 0.5469\n",
      "Epoch 130/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.7728 - accuracy: 0.6930 - val_loss: 1.0806 - val_accuracy: 0.5612\n",
      "Epoch 131/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7700 - accuracy: 0.6896 - val_loss: 1.0820 - val_accuracy: 0.5561\n",
      "Epoch 132/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7662 - accuracy: 0.6903 - val_loss: 1.0852 - val_accuracy: 0.5480\n",
      "Epoch 133/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7691 - accuracy: 0.6913 - val_loss: 1.0814 - val_accuracy: 0.5551\n",
      "Epoch 134/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7613 - accuracy: 0.6940 - val_loss: 1.0840 - val_accuracy: 0.5612\n",
      "Epoch 135/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7612 - accuracy: 0.6926 - val_loss: 1.0835 - val_accuracy: 0.5592\n",
      "Epoch 136/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7593 - accuracy: 0.6978 - val_loss: 1.0903 - val_accuracy: 0.5684\n",
      "Epoch 137/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7588 - accuracy: 0.6937 - val_loss: 1.0852 - val_accuracy: 0.5612\n",
      "Epoch 138/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7556 - accuracy: 0.6981 - val_loss: 1.0857 - val_accuracy: 0.5582\n",
      "Epoch 139/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7518 - accuracy: 0.7039 - val_loss: 1.0890 - val_accuracy: 0.5510\n",
      "Epoch 140/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7516 - accuracy: 0.6988 - val_loss: 1.0885 - val_accuracy: 0.5633\n",
      "Epoch 141/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7471 - accuracy: 0.7029 - val_loss: 1.0914 - val_accuracy: 0.5633\n",
      "Epoch 142/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7466 - accuracy: 0.7032 - val_loss: 1.0927 - val_accuracy: 0.5582\n",
      "Epoch 143/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7458 - accuracy: 0.7049 - val_loss: 1.0912 - val_accuracy: 0.5612\n",
      "Epoch 144/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7408 - accuracy: 0.7049 - val_loss: 1.0968 - val_accuracy: 0.5612\n",
      "Epoch 145/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7404 - accuracy: 0.7083 - val_loss: 1.0922 - val_accuracy: 0.5571\n",
      "Epoch 146/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7395 - accuracy: 0.6998 - val_loss: 1.0998 - val_accuracy: 0.5684\n",
      "Epoch 147/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7362 - accuracy: 0.7103 - val_loss: 1.1016 - val_accuracy: 0.5694\n",
      "Epoch 148/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7324 - accuracy: 0.7103 - val_loss: 1.0957 - val_accuracy: 0.5612\n",
      "Epoch 149/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.7300 - accuracy: 0.7103 - val_loss: 1.0950 - val_accuracy: 0.5663\n",
      "Epoch 150/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7277 - accuracy: 0.7110 - val_loss: 1.1043 - val_accuracy: 0.5663\n",
      "Epoch 151/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7273 - accuracy: 0.7120 - val_loss: 1.1001 - val_accuracy: 0.5643\n",
      "Epoch 152/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7264 - accuracy: 0.7120 - val_loss: 1.1022 - val_accuracy: 0.5602\n",
      "Epoch 153/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7252 - accuracy: 0.7097 - val_loss: 1.1045 - val_accuracy: 0.5714\n",
      "Epoch 154/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.7194 - accuracy: 0.7134 - val_loss: 1.1050 - val_accuracy: 0.5582\n",
      "Epoch 155/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7196 - accuracy: 0.7141 - val_loss: 1.1072 - val_accuracy: 0.5663\n",
      "Epoch 156/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7173 - accuracy: 0.7182 - val_loss: 1.1189 - val_accuracy: 0.5673\n",
      "Epoch 157/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.7233 - accuracy: 0.7076 - val_loss: 1.1100 - val_accuracy: 0.5643\n",
      "Epoch 158/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7185 - accuracy: 0.7138 - val_loss: 1.1151 - val_accuracy: 0.5643\n",
      "Epoch 159/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7124 - accuracy: 0.7124 - val_loss: 1.1147 - val_accuracy: 0.5469\n",
      "Epoch 160/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7125 - accuracy: 0.7158 - val_loss: 1.1291 - val_accuracy: 0.5724\n",
      "Epoch 161/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7092 - accuracy: 0.7151 - val_loss: 1.1108 - val_accuracy: 0.5684\n",
      "Epoch 162/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7085 - accuracy: 0.7144 - val_loss: 1.1142 - val_accuracy: 0.5633\n",
      "Epoch 163/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7044 - accuracy: 0.7172 - val_loss: 1.1235 - val_accuracy: 0.5684\n",
      "Epoch 164/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.7067 - accuracy: 0.7151 - val_loss: 1.1206 - val_accuracy: 0.5663\n",
      "Epoch 165/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.7004 - accuracy: 0.7212 - val_loss: 1.1217 - val_accuracy: 0.5735\n",
      "Epoch 166/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6987 - accuracy: 0.7260 - val_loss: 1.1226 - val_accuracy: 0.5735\n",
      "Epoch 167/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6931 - accuracy: 0.7280 - val_loss: 1.1236 - val_accuracy: 0.5643\n",
      "Epoch 168/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6964 - accuracy: 0.7250 - val_loss: 1.1296 - val_accuracy: 0.5796\n",
      "Epoch 169/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6911 - accuracy: 0.7260 - val_loss: 1.1273 - val_accuracy: 0.5673\n",
      "Epoch 170/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.6903 - accuracy: 0.7280 - val_loss: 1.1304 - val_accuracy: 0.5673\n",
      "Epoch 171/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6847 - accuracy: 0.7284 - val_loss: 1.1233 - val_accuracy: 0.5745\n",
      "Epoch 172/10000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.6837 - accuracy: 0.7314 - val_loss: 1.1306 - val_accuracy: 0.5735\n",
      "Epoch 173/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 20ms/step - loss: 0.6822 - accuracy: 0.7274 - val_loss: 1.1318 - val_accuracy: 0.5776\n",
      "Epoch 174/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6770 - accuracy: 0.7314 - val_loss: 1.1334 - val_accuracy: 0.5837\n",
      "Epoch 175/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6767 - accuracy: 0.7314 - val_loss: 1.1328 - val_accuracy: 0.5816\n",
      "Epoch 176/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6768 - accuracy: 0.7318 - val_loss: 1.1355 - val_accuracy: 0.5653\n",
      "Epoch 177/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6772 - accuracy: 0.7301 - val_loss: 1.1436 - val_accuracy: 0.5745\n",
      "Epoch 178/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6740 - accuracy: 0.7352 - val_loss: 1.1448 - val_accuracy: 0.5653\n",
      "Epoch 179/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6716 - accuracy: 0.7304 - val_loss: 1.1435 - val_accuracy: 0.5847\n",
      "Epoch 180/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6688 - accuracy: 0.7376 - val_loss: 1.1430 - val_accuracy: 0.5796\n",
      "Epoch 181/10000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.6666 - accuracy: 0.7393 - val_loss: 1.1447 - val_accuracy: 0.5684\n",
      "Epoch 182/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.6643 - accuracy: 0.7447 - val_loss: 1.1527 - val_accuracy: 0.5694\n",
      "Epoch 183/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6646 - accuracy: 0.7342 - val_loss: 1.1486 - val_accuracy: 0.5735\n",
      "Epoch 184/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6645 - accuracy: 0.7369 - val_loss: 1.1508 - val_accuracy: 0.5765\n",
      "Epoch 185/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6623 - accuracy: 0.7410 - val_loss: 1.1684 - val_accuracy: 0.5755\n",
      "Epoch 186/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6584 - accuracy: 0.7434 - val_loss: 1.1508 - val_accuracy: 0.5786\n",
      "Epoch 187/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6530 - accuracy: 0.7430 - val_loss: 1.1582 - val_accuracy: 0.5724\n",
      "Epoch 188/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6538 - accuracy: 0.7393 - val_loss: 1.1633 - val_accuracy: 0.5776\n",
      "Epoch 189/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6534 - accuracy: 0.7423 - val_loss: 1.1661 - val_accuracy: 0.5857\n",
      "Epoch 190/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6573 - accuracy: 0.7440 - val_loss: 1.1680 - val_accuracy: 0.5653\n",
      "Epoch 191/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6565 - accuracy: 0.7461 - val_loss: 1.1791 - val_accuracy: 0.5592\n",
      "Epoch 192/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6546 - accuracy: 0.7372 - val_loss: 1.1634 - val_accuracy: 0.5643\n",
      "Epoch 193/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6519 - accuracy: 0.7444 - val_loss: 1.1804 - val_accuracy: 0.5704\n",
      "Epoch 194/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6485 - accuracy: 0.7461 - val_loss: 1.1869 - val_accuracy: 0.5745\n",
      "Epoch 195/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6459 - accuracy: 0.7440 - val_loss: 1.1721 - val_accuracy: 0.5663\n",
      "Epoch 196/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6385 - accuracy: 0.7526 - val_loss: 1.1763 - val_accuracy: 0.5755\n",
      "Epoch 197/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6374 - accuracy: 0.7474 - val_loss: 1.1776 - val_accuracy: 0.5694\n",
      "Epoch 198/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6376 - accuracy: 0.7498 - val_loss: 1.1971 - val_accuracy: 0.5714\n",
      "Epoch 199/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6394 - accuracy: 0.7491 - val_loss: 1.1860 - val_accuracy: 0.5714\n",
      "Epoch 200/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6372 - accuracy: 0.7577 - val_loss: 1.2014 - val_accuracy: 0.5714\n",
      "Epoch 201/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6412 - accuracy: 0.7549 - val_loss: 1.1875 - val_accuracy: 0.5582\n",
      "Epoch 202/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6322 - accuracy: 0.7491 - val_loss: 1.1843 - val_accuracy: 0.5755\n",
      "Epoch 203/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6312 - accuracy: 0.7570 - val_loss: 1.1910 - val_accuracy: 0.5724\n",
      "Epoch 204/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6276 - accuracy: 0.7536 - val_loss: 1.2004 - val_accuracy: 0.5684\n",
      "Epoch 205/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6282 - accuracy: 0.7583 - val_loss: 1.2072 - val_accuracy: 0.5663\n",
      "Epoch 206/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6260 - accuracy: 0.7573 - val_loss: 1.1915 - val_accuracy: 0.5684\n",
      "Epoch 207/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6254 - accuracy: 0.7543 - val_loss: 1.2096 - val_accuracy: 0.5571\n",
      "Epoch 208/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6309 - accuracy: 0.7563 - val_loss: 1.2044 - val_accuracy: 0.5755\n",
      "Epoch 209/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6245 - accuracy: 0.7536 - val_loss: 1.2303 - val_accuracy: 0.5745\n",
      "Epoch 210/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6311 - accuracy: 0.7556 - val_loss: 1.2088 - val_accuracy: 0.5714\n",
      "Epoch 211/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6232 - accuracy: 0.7600 - val_loss: 1.2077 - val_accuracy: 0.5561\n",
      "Epoch 212/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6205 - accuracy: 0.7600 - val_loss: 1.2027 - val_accuracy: 0.5684\n",
      "Epoch 213/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6151 - accuracy: 0.7607 - val_loss: 1.2203 - val_accuracy: 0.5724\n",
      "Epoch 214/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.6129 - accuracy: 0.7699 - val_loss: 1.2231 - val_accuracy: 0.5684\n",
      "Epoch 215/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.6133 - accuracy: 0.7624 - val_loss: 1.2144 - val_accuracy: 0.5694\n",
      "Epoch 216/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6094 - accuracy: 0.7600 - val_loss: 1.2286 - val_accuracy: 0.5520\n",
      "Epoch 217/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6193 - accuracy: 0.7600 - val_loss: 1.2171 - val_accuracy: 0.5735\n",
      "Epoch 218/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6079 - accuracy: 0.7668 - val_loss: 1.2337 - val_accuracy: 0.5755\n",
      "Epoch 219/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.6047 - accuracy: 0.7621 - val_loss: 1.2274 - val_accuracy: 0.5714\n",
      "Epoch 220/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.6071 - accuracy: 0.7617 - val_loss: 1.2220 - val_accuracy: 0.5663\n",
      "Epoch 221/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.6019 - accuracy: 0.7668 - val_loss: 1.2206 - val_accuracy: 0.5602\n",
      "Epoch 222/10000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.6004 - accuracy: 0.7723 - val_loss: 1.2186 - val_accuracy: 0.5704\n",
      "Epoch 223/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5930 - accuracy: 0.7743 - val_loss: 1.2336 - val_accuracy: 0.5684\n",
      "Epoch 224/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.5927 - accuracy: 0.7716 - val_loss: 1.2317 - val_accuracy: 0.5776\n",
      "Epoch 225/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5890 - accuracy: 0.7726 - val_loss: 1.2291 - val_accuracy: 0.5776\n",
      "Epoch 226/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.5896 - accuracy: 0.7747 - val_loss: 1.2277 - val_accuracy: 0.5643\n",
      "Epoch 227/10000\n",
      "6/6 [==============================] - 0s 16ms/step - loss: 0.5877 - accuracy: 0.7696 - val_loss: 1.2388 - val_accuracy: 0.5724\n",
      "Epoch 228/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5861 - accuracy: 0.7754 - val_loss: 1.2482 - val_accuracy: 0.5694\n",
      "Epoch 229/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5863 - accuracy: 0.7747 - val_loss: 1.2542 - val_accuracy: 0.5694\n",
      "Epoch 230/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5890 - accuracy: 0.7781 - val_loss: 1.2431 - val_accuracy: 0.5796\n",
      "Epoch 231/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5817 - accuracy: 0.7777 - val_loss: 1.2415 - val_accuracy: 0.5694\n",
      "Epoch 232/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5797 - accuracy: 0.7791 - val_loss: 1.2492 - val_accuracy: 0.5765\n",
      "Epoch 233/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.5800 - accuracy: 0.7757 - val_loss: 1.2468 - val_accuracy: 0.5816\n",
      "Epoch 234/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5785 - accuracy: 0.7781 - val_loss: 1.2483 - val_accuracy: 0.5724\n",
      "Epoch 235/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5758 - accuracy: 0.7886 - val_loss: 1.2493 - val_accuracy: 0.5724\n",
      "Epoch 236/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5777 - accuracy: 0.7788 - val_loss: 1.2514 - val_accuracy: 0.5643\n",
      "Epoch 237/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5700 - accuracy: 0.7818 - val_loss: 1.2628 - val_accuracy: 0.5694\n",
      "Epoch 238/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5742 - accuracy: 0.7815 - val_loss: 1.2693 - val_accuracy: 0.5776\n",
      "Epoch 239/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5772 - accuracy: 0.7818 - val_loss: 1.2621 - val_accuracy: 0.5776\n",
      "Epoch 240/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5726 - accuracy: 0.7842 - val_loss: 1.2689 - val_accuracy: 0.5724\n",
      "Epoch 241/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5705 - accuracy: 0.7856 - val_loss: 1.2658 - val_accuracy: 0.5673\n",
      "Epoch 242/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5681 - accuracy: 0.7914 - val_loss: 1.2702 - val_accuracy: 0.5735\n",
      "Epoch 243/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5610 - accuracy: 0.7876 - val_loss: 1.2747 - val_accuracy: 0.5714\n",
      "Epoch 244/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5586 - accuracy: 0.7886 - val_loss: 1.2701 - val_accuracy: 0.5714\n",
      "Epoch 245/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5581 - accuracy: 0.7920 - val_loss: 1.2770 - val_accuracy: 0.5796\n",
      "Epoch 246/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5594 - accuracy: 0.7903 - val_loss: 1.2791 - val_accuracy: 0.5745\n",
      "Epoch 247/10000\n",
      "6/6 [==============================] - 0s 20ms/step - loss: 0.5556 - accuracy: 0.7852 - val_loss: 1.2796 - val_accuracy: 0.5745\n",
      "Epoch 248/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5544 - accuracy: 0.7968 - val_loss: 1.2798 - val_accuracy: 0.5735\n",
      "Epoch 249/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5527 - accuracy: 0.7951 - val_loss: 1.2829 - val_accuracy: 0.5643\n",
      "Epoch 250/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5515 - accuracy: 0.7907 - val_loss: 1.2834 - val_accuracy: 0.5612\n",
      "Epoch 251/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5538 - accuracy: 0.7941 - val_loss: 1.2952 - val_accuracy: 0.5735\n",
      "Epoch 252/10000\n",
      "6/6 [==============================] - 0s 17ms/step - loss: 0.5502 - accuracy: 0.7931 - val_loss: 1.2980 - val_accuracy: 0.5724\n",
      "Epoch 253/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5446 - accuracy: 0.7971 - val_loss: 1.2977 - val_accuracy: 0.5765\n",
      "Epoch 254/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5441 - accuracy: 0.7931 - val_loss: 1.2982 - val_accuracy: 0.5735\n",
      "Epoch 255/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5431 - accuracy: 0.7988 - val_loss: 1.2959 - val_accuracy: 0.5776\n",
      "Epoch 256/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5415 - accuracy: 0.7975 - val_loss: 1.3079 - val_accuracy: 0.5704\n",
      "Epoch 257/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5395 - accuracy: 0.7985 - val_loss: 1.3098 - val_accuracy: 0.5755\n",
      "Epoch 258/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5361 - accuracy: 0.8002 - val_loss: 1.3072 - val_accuracy: 0.5684\n",
      "Epoch 259/10000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5337 - accuracy: 0.8016 - val_loss: 1.3106 - val_accuracy: 0.5786\n",
      "Epoch 260/10000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.5344 - accuracy: 0.8033 - val_loss: 1.3228 - val_accuracy: 0.5806\n",
      "Epoch 261/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5357 - accuracy: 0.8039 - val_loss: 1.3226 - val_accuracy: 0.5755\n",
      "Epoch 262/10000\n",
      "6/6 [==============================] - 0s 22ms/step - loss: 0.5311 - accuracy: 0.8060 - val_loss: 1.3331 - val_accuracy: 0.5806\n",
      "Epoch 263/10000\n",
      "6/6 [==============================] - 0s 21ms/step - loss: 0.5343 - accuracy: 0.8033 - val_loss: 1.3338 - val_accuracy: 0.5714\n",
      "Epoch 264/10000\n",
      "6/6 [==============================] - 0s 18ms/step - loss: 0.5338 - accuracy: 0.8091 - val_loss: 1.3189 - val_accuracy: 0.5765\n",
      "Epoch 265/10000\n",
      "6/6 [==============================] - 0s 19ms/step - loss: 0.5292 - accuracy: 0.8009 - val_loss: 1.3281 - val_accuracy: 0.5735\n",
      "Epoch 266/10000\n",
      "6/6 [==============================] - 0s 23ms/step - loss: 0.5287 - accuracy: 0.8077 - val_loss: 1.3428 - val_accuracy: 0.5765\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\", optimizer='adam', metrics=['accuracy'])\n",
    "early_stop = EarlyStopping(patience=200) \n",
    "filepath = \"./model/white_wine{epoch:04d}__{val_loss:.4f}.keras\"\n",
    "model_save = ModelCheckpoint(filepath=filepath, save_best_only=True)\n",
    "history = model.fit(X_train, y_train, epochs=10000, batch_size=500, validation_data=(X_valid, y_valid),\n",
    "                   callbacks=[early_stop, model_save])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "c8985709",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "31/31 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-11 09:28:22.596919: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-11 09:28:22.725507: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-11 09:28:22.725568: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    }
   ],
   "source": [
    "wine_best_model = load_model(\"./model/white_wine0066__1.0443.keras\")\n",
    "wine_pred = wine_best_model.predict(X_test)\n",
    "wine_pred = pd.DataFrame(wine_pred, columns=y.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "eedd45a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.002578</td>\n",
       "      <td>0.010138</td>\n",
       "      <td>0.114248</td>\n",
       "      <td>0.812805</td>\n",
       "      <td>0.044664</td>\n",
       "      <td>0.014980</td>\n",
       "      <td>0.000587</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.007781</td>\n",
       "      <td>0.010671</td>\n",
       "      <td>0.137378</td>\n",
       "      <td>0.665632</td>\n",
       "      <td>0.133843</td>\n",
       "      <td>0.042264</td>\n",
       "      <td>0.002431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.006493</td>\n",
       "      <td>0.111238</td>\n",
       "      <td>0.517396</td>\n",
       "      <td>0.347815</td>\n",
       "      <td>0.014024</td>\n",
       "      <td>0.002729</td>\n",
       "      <td>0.000305</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.001687</td>\n",
       "      <td>0.007797</td>\n",
       "      <td>0.094902</td>\n",
       "      <td>0.576898</td>\n",
       "      <td>0.298047</td>\n",
       "      <td>0.020264</td>\n",
       "      <td>0.000405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.001807</td>\n",
       "      <td>0.003743</td>\n",
       "      <td>0.156203</td>\n",
       "      <td>0.718857</td>\n",
       "      <td>0.101045</td>\n",
       "      <td>0.017972</td>\n",
       "      <td>0.000373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>975</th>\n",
       "      <td>0.012053</td>\n",
       "      <td>0.018558</td>\n",
       "      <td>0.307155</td>\n",
       "      <td>0.568341</td>\n",
       "      <td>0.063113</td>\n",
       "      <td>0.027680</td>\n",
       "      <td>0.003101</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>976</th>\n",
       "      <td>0.005065</td>\n",
       "      <td>0.593256</td>\n",
       "      <td>0.375506</td>\n",
       "      <td>0.024974</td>\n",
       "      <td>0.000986</td>\n",
       "      <td>0.000188</td>\n",
       "      <td>0.000025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>977</th>\n",
       "      <td>0.014067</td>\n",
       "      <td>0.033956</td>\n",
       "      <td>0.422885</td>\n",
       "      <td>0.366663</td>\n",
       "      <td>0.140587</td>\n",
       "      <td>0.020015</td>\n",
       "      <td>0.001826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>978</th>\n",
       "      <td>0.004152</td>\n",
       "      <td>0.081787</td>\n",
       "      <td>0.314111</td>\n",
       "      <td>0.570179</td>\n",
       "      <td>0.027136</td>\n",
       "      <td>0.002320</td>\n",
       "      <td>0.000315</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>979</th>\n",
       "      <td>0.006363</td>\n",
       "      <td>0.012768</td>\n",
       "      <td>0.395053</td>\n",
       "      <td>0.534480</td>\n",
       "      <td>0.041396</td>\n",
       "      <td>0.009389</td>\n",
       "      <td>0.000549</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>980 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            3         4         5         6         7         8         9\n",
       "0    0.002578  0.010138  0.114248  0.812805  0.044664  0.014980  0.000587\n",
       "1    0.007781  0.010671  0.137378  0.665632  0.133843  0.042264  0.002431\n",
       "2    0.006493  0.111238  0.517396  0.347815  0.014024  0.002729  0.000305\n",
       "3    0.001687  0.007797  0.094902  0.576898  0.298047  0.020264  0.000405\n",
       "4    0.001807  0.003743  0.156203  0.718857  0.101045  0.017972  0.000373\n",
       "..        ...       ...       ...       ...       ...       ...       ...\n",
       "975  0.012053  0.018558  0.307155  0.568341  0.063113  0.027680  0.003101\n",
       "976  0.005065  0.593256  0.375506  0.024974  0.000986  0.000188  0.000025\n",
       "977  0.014067  0.033956  0.422885  0.366663  0.140587  0.020015  0.001826\n",
       "978  0.004152  0.081787  0.314111  0.570179  0.027136  0.002320  0.000315\n",
       "979  0.006363  0.012768  0.395053  0.534480  0.041396  0.009389  0.000549\n",
       "\n",
       "[980 rows x 7 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "5d94df4e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      6\n",
       "1      6\n",
       "2      7\n",
       "3      7\n",
       "4      5\n",
       "      ..\n",
       "975    6\n",
       "976    4\n",
       "977    5\n",
       "978    6\n",
       "979    6\n",
       "Length: 980, dtype: int64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test_class = y_test.idxmax(axis=1)\n",
    "y_test_class = y_test_class.reset_index(drop=True)\n",
    "y_test_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "5a2c8723",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      6\n",
       "1      6\n",
       "2      5\n",
       "3      6\n",
       "4      6\n",
       "      ..\n",
       "975    6\n",
       "976    4\n",
       "977    5\n",
       "978    6\n",
       "979    6\n",
       "Length: 980, dtype: int64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_pred_class = wine_pred.idxmax(axis=1)\n",
    "wine_pred_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "b9f7e3bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3      4      5      6      7      8      9    \n",
       "False  False  False  True   False  False  False    2198\n",
       "              True   False  False  False  False    1457\n",
       "              False  False  True   False  False     880\n",
       "                            False  True   False     175\n",
       "       True   False  False  False  False  False     163\n",
       "True   False  False  False  False  False  False      20\n",
       "False  False  False  False  False  False  True        5\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "6aa3cd66",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.60      0.09      0.16        33\n",
      "           5       0.59      0.57      0.58       291\n",
      "           6       0.55      0.72      0.63       440\n",
      "           7       0.53      0.37      0.44       176\n",
      "           8       0.00      0.00      0.00        35\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.56       980\n",
      "   macro avg       0.33      0.25      0.26       980\n",
      "weighted avg       0.54      0.56      0.54       980\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_class, wine_pred_class))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ae909a27",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "339801f1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([3, 3, 3, ..., 3, 4, 3])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "le = LabelEncoder()\n",
    "y2_labeled = le.fit_transform(y2)\n",
    "y2_labeled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74aa7541",
   "metadata": {},
   "source": [
    "XGB로 비교분석"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "4599382c",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train2, X_valid2, y_train2, y_valid2 = train_test_split(X_scaled, y2_labeled, test_size=0.4, stratify=y2_labeled, random_state=10)\n",
    "X_valid2, X_test2, y_valid2, y_test2 = train_test_split(X_valid2, y_valid2, test_size=0.5, stratify=y_valid2, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d91ac53",
   "metadata": {},
   "outputs": [],
   "source": [
    "adasyn = ADASYN(random_state=10, n_neighbors=2, n_jobs=-1)\n",
    "X_train2_adasyn, y_train2_adasyn = adasyn.fit_resample(X_train2, y_train2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5034acaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train2_adasyn = pd.DataFrame(X_train2_adasyn, columns=X.columns)\n",
    "X_train2_adasyn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0830effb",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "y_train2_adasyn = pd.Series(y_train2_adasyn)\n",
    "y_train2_adasyn.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2946791c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9e6c835",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dc6a578",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "506df56c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting xgboost\n",
      "  Downloading xgboost-2.1.1-py3-none-manylinux_2_28_x86_64.whl.metadata (2.1 kB)\n",
      "Requirement already satisfied: numpy in /home/user/miniforge3/envs/dml/lib/python3.9/site-packages (from xgboost) (1.26.4)\n",
      "Collecting nvidia-nccl-cu12 (from xgboost)\n",
      "  Downloading nvidia_nccl_cu12-2.22.3-py3-none-manylinux2014_x86_64.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: scipy in /home/user/miniforge3/envs/dml/lib/python3.9/site-packages (from xgboost) (1.13.1)\n",
      "Downloading xgboost-2.1.1-py3-none-manylinux_2_28_x86_64.whl (153.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m153.9/153.9 MB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu12-2.22.3-py3-none-manylinux2014_x86_64.whl (190.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m190.9/190.9 MB\u001b[0m \u001b[31m57.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: nvidia-nccl-cu12, xgboost\n",
      "Successfully installed nvidia-nccl-cu12-2.22.3 xgboost-2.1.1\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "58ab6927",
   "metadata": {},
   "outputs": [],
   "source": [
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "26cd5b67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.48      0.33      0.39        33\n",
      "           5       0.64      0.61      0.62       291\n",
      "           6       0.64      0.70      0.67       440\n",
      "           7       0.59      0.60      0.59       176\n",
      "           8       0.60      0.34      0.44        35\n",
      "           9       0.00      0.00      0.00         1\n",
      "\n",
      "    accuracy                           0.62       980\n",
      "   macro avg       0.42      0.37      0.39       980\n",
      "weighted avg       0.62      0.62      0.62       980\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "/home/user/miniforge3/envs/dml/lib/python3.9/site-packages/sklearn/metrics/_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "xgb = XGBClassifier(max_depth= 5, n_estimators=1000, random_state=10, n_jobs=-1)\n",
    "xgb.fit(X_train2, y_train2)\n",
    "xgb_pred = xgb.predict(X_valid2)\n",
    "print(classification_report(le.inverse_transform(y_valid2), le.inverse_transform(xgb_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cdfbcd4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a5a7fd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "807a2ef2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db23017e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f455c81a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abef7c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff951b00",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d1c0a4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c59bb56",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "187fce45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c8275d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a1bd2e3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

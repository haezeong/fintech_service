{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3a5dc59f",
   "metadata": {},
   "source": [
    "# 텐서플로우(google)-산업용\n",
    "* 이미지 관련 라이브러리\n",
    "* keras를 이용해 코딩이 쉬움\n",
    "* 순차적 sequentional, functional, class\n",
    "\n",
    "# 파이토치(meta)-연구용\n",
    "* 자연어 관련 라이브러리\n",
    "* 허깅페이스, 랭체인\n",
    "* class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "127c900f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3a0096e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "85800d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(action='ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "97f7cb71",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"https://raw.githubusercontent.com/haram4th/ablearn/main/Taitanic_train.csv\")\n",
    "data.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5ea6ebeb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PassengerId', 'Survived', 'Pclass', 'Name', 'Sex', 'Age', 'SibSp',\n",
       "       'Parch', 'Ticket', 'Fare', 'Cabin', 'Embarked'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "58053304",
   "metadata": {},
   "outputs": [],
   "source": [
    "data= data[['Survived', 'Pclass','Sex', 'Age', 'SibSp', 'Parch', 'Embarked']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1096596f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>male</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Q</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass     Sex   Age  SibSp  Parch Embarked\n",
       "0           0       3    male  22.0      1      0        S\n",
       "1           1       1  female  38.0      1      0        C\n",
       "2           1       3  female  26.0      0      0        S\n",
       "3           1       1  female  35.0      1      0        S\n",
       "4           0       3    male  35.0      0      0        S\n",
       "..        ...     ...     ...   ...    ...    ...      ...\n",
       "886         0       2    male  27.0      0      0        S\n",
       "887         1       1  female  19.0      0      0        S\n",
       "888         0       3  female   NaN      1      2        S\n",
       "889         1       1    male  26.0      0      0        C\n",
       "890         0       3    male  32.0      0      0        Q\n",
       "\n",
       "[891 rows x 7 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4a42b014",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age  SibSp  Parch Embarked  family\n",
       "0         0       3    male  22.0      1      0        S       1\n",
       "1         1       1  female  38.0      1      0        C       1\n",
       "2         1       3  female  26.0      0      0        S       0\n",
       "3         1       1  female  35.0      1      0        S       1\n",
       "4         0       3    male  35.0      0      0        S       0"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['family'] = data['SibSp'] + data['Parch']\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "90c0d025",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age Embarked  family\n",
       "0         0       3    male  22.0        S       1\n",
       "1         1       1  female  38.0        C       1\n",
       "2         1       3  female  26.0        S       0\n",
       "3         1       1  female  35.0        S       1\n",
       "4         0       3    male  35.0        S       0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data.drop(['SibSp', 'Parch'], axis=1)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c43440d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Age'] = data['Age'].fillna(data['Age'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e0bdff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'S'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Embarked'].mode()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18d28a96",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Embarked'] = data['Embarked'].fillna(data['Embarked'].mode()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fa858299",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>C</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>S</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass     Sex   Age Embarked  family\n",
       "0         0       3    male  22.0        S       1\n",
       "1         1       1  female  38.0        C       1\n",
       "2         1       3  female  26.0        S       0\n",
       "3         1       1  female  35.0        S       1\n",
       "4         0       3    male  35.0        S       0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b0c60c89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>family</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass   Age  family  Sex_male  Embarked_Q  Embarked_S\n",
       "0         0       3  22.0       1      True       False        True\n",
       "1         1       1  38.0       1     False       False       False\n",
       "2         1       3  26.0       0     False       False        True\n",
       "3         1       1  35.0       1     False       False        True\n",
       "4         0       3  35.0       0      True       False        True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data= pd.get_dummies(data, drop_first=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cbf97098",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= data.drop('Survived', axis=1)\n",
    "y= data['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4d4abf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4a819df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Age</th>\n",
       "      <th>family</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.827377</td>\n",
       "      <td>-0.592481</td>\n",
       "      <td>0.059160</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.615838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-1.566107</td>\n",
       "      <td>0.638789</td>\n",
       "      <td>0.059160</td>\n",
       "      <td>-1.355574</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>-1.623803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.827377</td>\n",
       "      <td>-0.284663</td>\n",
       "      <td>-0.560975</td>\n",
       "      <td>-1.355574</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.615838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-1.566107</td>\n",
       "      <td>0.407926</td>\n",
       "      <td>0.059160</td>\n",
       "      <td>-1.355574</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.615838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.827377</td>\n",
       "      <td>0.407926</td>\n",
       "      <td>-0.560975</td>\n",
       "      <td>0.737695</td>\n",
       "      <td>-0.307562</td>\n",
       "      <td>0.615838</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Pclass       Age    family  Sex_male  Embarked_Q  Embarked_S\n",
       "0  0.827377 -0.592481  0.059160  0.737695   -0.307562    0.615838\n",
       "1 -1.566107  0.638789  0.059160 -1.355574   -0.307562   -1.623803\n",
       "2  0.827377 -0.284663 -0.560975 -1.355574   -0.307562    0.615838\n",
       "3 -1.566107  0.407926  0.059160 -1.355574   -0.307562    0.615838\n",
       "4  0.827377  0.407926 -0.560975  0.737695   -0.307562    0.615838"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ss= StandardScaler()\n",
    "X_scaled = ss.fit_transform(X)\n",
    "X_scaled= pd.DataFrame(X_scaled, columns=X.columns)\n",
    "X_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c676a036",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "77ba543d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.7, random_state=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "f63f4882",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "e244ffce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.85       386\n",
      "           1       0.80      0.67      0.73       238\n",
      "\n",
      "    accuracy                           0.81       624\n",
      "   macro avg       0.81      0.78      0.79       624\n",
      "weighted avg       0.81      0.81      0.81       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dtc = DecisionTreeClassifier(max_depth=3, random_state=10)\n",
    "dtc.fit(X_train, y_train)\n",
    "pred = dtc.predict(X_test)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f30e70e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       386\n",
      "           1       0.74      0.67      0.70       238\n",
      "\n",
      "    accuracy                           0.78       624\n",
      "   macro avg       0.77      0.76      0.77       624\n",
      "weighted avg       0.78      0.78      0.78       624\n",
      "\n",
      "2\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.87      0.84       386\n",
      "           1       0.77      0.68      0.72       238\n",
      "\n",
      "    accuracy                           0.80       624\n",
      "   macro avg       0.79      0.77      0.78       624\n",
      "weighted avg       0.80      0.80      0.80       624\n",
      "\n",
      "3\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.90      0.85       386\n",
      "           1       0.80      0.67      0.73       238\n",
      "\n",
      "    accuracy                           0.81       624\n",
      "   macro avg       0.81      0.78      0.79       624\n",
      "weighted avg       0.81      0.81      0.81       624\n",
      "\n",
      "4\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.82      0.88      0.85       386\n",
      "           1       0.78      0.69      0.73       238\n",
      "\n",
      "    accuracy                           0.81       624\n",
      "   macro avg       0.80      0.78      0.79       624\n",
      "weighted avg       0.81      0.81      0.81       624\n",
      "\n",
      "5\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.88      0.85       386\n",
      "           1       0.78      0.67      0.72       238\n",
      "\n",
      "    accuracy                           0.80       624\n",
      "   macro avg       0.80      0.78      0.78       624\n",
      "weighted avg       0.80      0.80      0.80       624\n",
      "\n",
      "6\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.90      0.84       386\n",
      "           1       0.79      0.63      0.70       238\n",
      "\n",
      "    accuracy                           0.79       624\n",
      "   macro avg       0.79      0.76      0.77       624\n",
      "weighted avg       0.79      0.79      0.79       624\n",
      "\n",
      "7\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83       386\n",
      "           1       0.75      0.62      0.68       238\n",
      "\n",
      "    accuracy                           0.78       624\n",
      "   macro avg       0.77      0.75      0.75       624\n",
      "weighted avg       0.77      0.78      0.77       624\n",
      "\n",
      "8\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.89      0.84       386\n",
      "           1       0.78      0.62      0.69       238\n",
      "\n",
      "    accuracy                           0.79       624\n",
      "   macro avg       0.79      0.76      0.76       624\n",
      "weighted avg       0.79      0.79      0.78       624\n",
      "\n",
      "9\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.87      0.83       386\n",
      "           1       0.75      0.63      0.69       238\n",
      "\n",
      "    accuracy                           0.78       624\n",
      "   macro avg       0.77      0.75      0.76       624\n",
      "weighted avg       0.78      0.78      0.78       624\n",
      "\n",
      "10\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.88      0.83       386\n",
      "           1       0.76      0.62      0.68       238\n",
      "\n",
      "    accuracy                           0.78       624\n",
      "   macro avg       0.77      0.75      0.76       624\n",
      "weighted avg       0.78      0.78      0.77       624\n",
      "\n",
      "11\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.86      0.82       386\n",
      "           1       0.74      0.62      0.67       238\n",
      "\n",
      "    accuracy                           0.77       624\n",
      "   macro avg       0.76      0.74      0.75       624\n",
      "weighted avg       0.77      0.77      0.77       624\n",
      "\n",
      "12\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82       386\n",
      "           1       0.73      0.62      0.67       238\n",
      "\n",
      "    accuracy                           0.77       624\n",
      "   macro avg       0.76      0.74      0.74       624\n",
      "weighted avg       0.76      0.77      0.76       624\n",
      "\n",
      "13\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82       386\n",
      "           1       0.73      0.62      0.67       238\n",
      "\n",
      "    accuracy                           0.77       624\n",
      "   macro avg       0.76      0.74      0.75       624\n",
      "weighted avg       0.76      0.77      0.76       624\n",
      "\n",
      "14\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82       386\n",
      "           1       0.73      0.62      0.67       238\n",
      "\n",
      "    accuracy                           0.77       624\n",
      "   macro avg       0.76      0.74      0.75       624\n",
      "weighted avg       0.76      0.77      0.76       624\n",
      "\n",
      "15\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82       386\n",
      "           1       0.73      0.62      0.67       238\n",
      "\n",
      "    accuracy                           0.77       624\n",
      "   macro avg       0.76      0.74      0.75       624\n",
      "weighted avg       0.76      0.77      0.76       624\n",
      "\n",
      "16\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82       386\n",
      "           1       0.73      0.62      0.67       238\n",
      "\n",
      "    accuracy                           0.77       624\n",
      "   macro avg       0.76      0.74      0.75       624\n",
      "weighted avg       0.76      0.77      0.76       624\n",
      "\n",
      "17\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82       386\n",
      "           1       0.73      0.62      0.67       238\n",
      "\n",
      "    accuracy                           0.77       624\n",
      "   macro avg       0.76      0.74      0.75       624\n",
      "weighted avg       0.76      0.77      0.76       624\n",
      "\n",
      "18\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82       386\n",
      "           1       0.73      0.62      0.67       238\n",
      "\n",
      "    accuracy                           0.77       624\n",
      "   macro avg       0.76      0.74      0.75       624\n",
      "weighted avg       0.76      0.77      0.76       624\n",
      "\n",
      "19\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.86      0.82       386\n",
      "           1       0.73      0.62      0.67       238\n",
      "\n",
      "    accuracy                           0.77       624\n",
      "   macro avg       0.76      0.74      0.75       624\n",
      "weighted avg       0.76      0.77      0.76       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,20):\n",
    "    dtc = DecisionTreeClassifier(max_depth=i, random_state=10)\n",
    "    dtc.fit(X_train, y_train)\n",
    "    pred = dtc.predict(X_test)\n",
    "    print(i)\n",
    "    print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "960fd31e",
   "metadata": {},
   "source": [
    "# Tensorflow Sequential API를 사용한 순차적 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fabd85c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6a344b",
   "metadata": {},
   "source": [
    "# 딥러닝 신경망 모델 정의"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cabaa3ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(267, 6)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "b153ec6c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape[1]  #컬럼개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "46f0f1f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model =Sequential()\n",
    "model.add(Dense(32, input_dim=X_train.shape[1], activation='relu'))  #입력층, input_dim: 독립변수의 컬럼수\n",
    "model.add(Dense(64, activation='relu')) #은닉층 1번\n",
    "model.add(Dense(32, activation='relu')) #은닉층 2\n",
    "model.add(Dense(16, activation='relu')) #은닉층 3\n",
    "model.add(Dense(1, activation='sigmoid')) #출력층, 이진분류: sigmoid. 다중분류: softmax"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6731e36d",
   "metadata": {},
   "source": [
    "# 모델 파라미터 세팅 model.compile()\n",
    "* loss: 오차 계산 지표\n",
    "  * 이진분류: binary_crossentropy\n",
    "  * 다중분류: categorical_crossentropy\n",
    "  * 데이터에 0이 많은 희소행렬인 경우: sparse_categorical_crossentropy\n",
    "  * 연속형데이터: (회귀분석): mse\n",
    "* optimizer: 머신러닝할때 learning_rate -딥러닝 네트워크가 가장 빠르게\n",
    "  * adam을 가장 많이 사용"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bd016eb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_1 (Dense)             (None, 32)                224       \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 16)                528       \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,961\n",
      "Trainable params: 4,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "#순차적으로가다가 맞지않으면 역전파 오차가 이진분류일경우 binaryclassentropy\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14f18695",
   "metadata": {},
   "source": [
    "# 모델 훈련\n",
    "* epochs: 전체 데이터를 한 번 훈련 하는 주기\n",
    "* batch_size: 전체 데이터를 쪼개서 훈련, 메모리에 맞춰서 크기 조절\n",
    "* validation_data: 검증 데이터로 모델 검증실시"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "22e85e41",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 14:15:37.875731: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-09 14:15:37.953726: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-09 14:15:37.953787: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 1s 45ms/step - loss: 0.6835 - accuracy: 0.6330 - val_loss: 0.6703 - val_accuracy: 0.6939\n",
      "Epoch 2/200\n",
      "6/7 [========================>.....] - ETA: 0s - loss: 0.6589 - accuracy: 0.7333"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 14:15:38.454057: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-09 14:15:38.480707: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-09 14:15:38.480808: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 24ms/step - loss: 0.6564 - accuracy: 0.7453 - val_loss: 0.6493 - val_accuracy: 0.7212\n",
      "Epoch 3/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.6291 - accuracy: 0.7528 - val_loss: 0.6251 - val_accuracy: 0.7500\n",
      "Epoch 4/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.5984 - accuracy: 0.7603 - val_loss: 0.5931 - val_accuracy: 0.7644\n",
      "Epoch 5/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.5629 - accuracy: 0.7753 - val_loss: 0.5571 - val_accuracy: 0.7788\n",
      "Epoch 6/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.5180 - accuracy: 0.7978 - val_loss: 0.5212 - val_accuracy: 0.7821\n",
      "Epoch 7/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.4768 - accuracy: 0.8127 - val_loss: 0.4887 - val_accuracy: 0.7804\n",
      "Epoch 8/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.4388 - accuracy: 0.8240 - val_loss: 0.4663 - val_accuracy: 0.7901\n",
      "Epoch 9/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.4154 - accuracy: 0.8240 - val_loss: 0.4560 - val_accuracy: 0.7885\n",
      "Epoch 10/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.4022 - accuracy: 0.8240 - val_loss: 0.4535 - val_accuracy: 0.7949\n",
      "Epoch 11/200\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.3938 - accuracy: 0.8315 - val_loss: 0.4512 - val_accuracy: 0.8013\n",
      "Epoch 12/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3863 - accuracy: 0.8390 - val_loss: 0.4479 - val_accuracy: 0.7965\n",
      "Epoch 13/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3800 - accuracy: 0.8352 - val_loss: 0.4463 - val_accuracy: 0.7981\n",
      "Epoch 14/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3774 - accuracy: 0.8464 - val_loss: 0.4431 - val_accuracy: 0.8029\n",
      "Epoch 15/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3714 - accuracy: 0.8390 - val_loss: 0.4446 - val_accuracy: 0.7981\n",
      "Epoch 16/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3678 - accuracy: 0.8464 - val_loss: 0.4429 - val_accuracy: 0.8045\n",
      "Epoch 17/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3632 - accuracy: 0.8464 - val_loss: 0.4408 - val_accuracy: 0.8205\n",
      "Epoch 18/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3613 - accuracy: 0.8464 - val_loss: 0.4419 - val_accuracy: 0.8093\n",
      "Epoch 19/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3575 - accuracy: 0.8502 - val_loss: 0.4452 - val_accuracy: 0.8045\n",
      "Epoch 20/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3555 - accuracy: 0.8502 - val_loss: 0.4456 - val_accuracy: 0.8077\n",
      "Epoch 21/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3536 - accuracy: 0.8539 - val_loss: 0.4460 - val_accuracy: 0.8093\n",
      "Epoch 22/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3502 - accuracy: 0.8539 - val_loss: 0.4442 - val_accuracy: 0.8109\n",
      "Epoch 23/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3468 - accuracy: 0.8539 - val_loss: 0.4464 - val_accuracy: 0.8125\n",
      "Epoch 24/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3459 - accuracy: 0.8577 - val_loss: 0.4464 - val_accuracy: 0.8093\n",
      "Epoch 25/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3438 - accuracy: 0.8539 - val_loss: 0.4467 - val_accuracy: 0.8093\n",
      "Epoch 26/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3399 - accuracy: 0.8614 - val_loss: 0.4448 - val_accuracy: 0.8173\n",
      "Epoch 27/200\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.3386 - accuracy: 0.8614 - val_loss: 0.4448 - val_accuracy: 0.8061\n",
      "Epoch 28/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3373 - accuracy: 0.8652 - val_loss: 0.4475 - val_accuracy: 0.8061\n",
      "Epoch 29/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3360 - accuracy: 0.8652 - val_loss: 0.4498 - val_accuracy: 0.8125\n",
      "Epoch 30/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3325 - accuracy: 0.8652 - val_loss: 0.4530 - val_accuracy: 0.8077\n",
      "Epoch 31/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3314 - accuracy: 0.8689 - val_loss: 0.4517 - val_accuracy: 0.8093\n",
      "Epoch 32/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3307 - accuracy: 0.8689 - val_loss: 0.4520 - val_accuracy: 0.8077\n",
      "Epoch 33/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3281 - accuracy: 0.8727 - val_loss: 0.4551 - val_accuracy: 0.8077\n",
      "Epoch 34/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3246 - accuracy: 0.8689 - val_loss: 0.4566 - val_accuracy: 0.8141\n",
      "Epoch 35/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3215 - accuracy: 0.8764 - val_loss: 0.4584 - val_accuracy: 0.8109\n",
      "Epoch 36/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3199 - accuracy: 0.8727 - val_loss: 0.4610 - val_accuracy: 0.8125\n",
      "Epoch 37/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3192 - accuracy: 0.8764 - val_loss: 0.4630 - val_accuracy: 0.8093\n",
      "Epoch 38/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3184 - accuracy: 0.8689 - val_loss: 0.4632 - val_accuracy: 0.8093\n",
      "Epoch 39/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3177 - accuracy: 0.8764 - val_loss: 0.4666 - val_accuracy: 0.8093\n",
      "Epoch 40/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3140 - accuracy: 0.8764 - val_loss: 0.4690 - val_accuracy: 0.8077\n",
      "Epoch 41/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3120 - accuracy: 0.8801 - val_loss: 0.4669 - val_accuracy: 0.8061\n",
      "Epoch 42/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3127 - accuracy: 0.8764 - val_loss: 0.4652 - val_accuracy: 0.8093\n",
      "Epoch 43/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3108 - accuracy: 0.8764 - val_loss: 0.4670 - val_accuracy: 0.8077\n",
      "Epoch 44/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.3071 - accuracy: 0.8801 - val_loss: 0.4734 - val_accuracy: 0.8077\n",
      "Epoch 45/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3089 - accuracy: 0.8801 - val_loss: 0.4812 - val_accuracy: 0.8029\n",
      "Epoch 46/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3071 - accuracy: 0.8727 - val_loss: 0.4814 - val_accuracy: 0.8029\n",
      "Epoch 47/200\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.3022 - accuracy: 0.8839 - val_loss: 0.4773 - val_accuracy: 0.8093\n",
      "Epoch 48/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3034 - accuracy: 0.8876 - val_loss: 0.4784 - val_accuracy: 0.8125\n",
      "Epoch 49/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3026 - accuracy: 0.8839 - val_loss: 0.4799 - val_accuracy: 0.8077\n",
      "Epoch 50/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2989 - accuracy: 0.8839 - val_loss: 0.4848 - val_accuracy: 0.8029\n",
      "Epoch 51/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3035 - accuracy: 0.8727 - val_loss: 0.4920 - val_accuracy: 0.8077\n",
      "Epoch 52/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.3001 - accuracy: 0.8839 - val_loss: 0.4908 - val_accuracy: 0.8061\n",
      "Epoch 53/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2993 - accuracy: 0.8801 - val_loss: 0.4920 - val_accuracy: 0.8029\n",
      "Epoch 54/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2948 - accuracy: 0.8801 - val_loss: 0.4899 - val_accuracy: 0.8013\n",
      "Epoch 55/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2982 - accuracy: 0.8764 - val_loss: 0.4936 - val_accuracy: 0.8013\n",
      "Epoch 56/200\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.2909 - accuracy: 0.8801 - val_loss: 0.4969 - val_accuracy: 0.8029\n",
      "Epoch 57/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2945 - accuracy: 0.8839 - val_loss: 0.4988 - val_accuracy: 0.8029\n",
      "Epoch 58/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2882 - accuracy: 0.8839 - val_loss: 0.5020 - val_accuracy: 0.7997\n",
      "Epoch 59/200\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.2868 - accuracy: 0.8801 - val_loss: 0.4990 - val_accuracy: 0.8029\n",
      "Epoch 60/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2866 - accuracy: 0.8801 - val_loss: 0.5040 - val_accuracy: 0.8029\n",
      "Epoch 61/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2936 - accuracy: 0.8764 - val_loss: 0.5133 - val_accuracy: 0.8029\n",
      "Epoch 62/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2862 - accuracy: 0.8839 - val_loss: 0.5084 - val_accuracy: 0.7965\n",
      "Epoch 63/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2851 - accuracy: 0.8801 - val_loss: 0.5082 - val_accuracy: 0.7981\n",
      "Epoch 64/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2874 - accuracy: 0.8764 - val_loss: 0.5122 - val_accuracy: 0.8029\n",
      "Epoch 65/200\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.2814 - accuracy: 0.8801 - val_loss: 0.5134 - val_accuracy: 0.8013\n",
      "Epoch 66/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2796 - accuracy: 0.8839 - val_loss: 0.5171 - val_accuracy: 0.7949\n",
      "Epoch 67/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2770 - accuracy: 0.8876 - val_loss: 0.5184 - val_accuracy: 0.7981\n",
      "Epoch 68/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2777 - accuracy: 0.8839 - val_loss: 0.5222 - val_accuracy: 0.8013\n",
      "Epoch 69/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2775 - accuracy: 0.8727 - val_loss: 0.5242 - val_accuracy: 0.8013\n",
      "Epoch 70/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2794 - accuracy: 0.8801 - val_loss: 0.5266 - val_accuracy: 0.7997\n",
      "Epoch 71/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2769 - accuracy: 0.8839 - val_loss: 0.5254 - val_accuracy: 0.7965\n",
      "Epoch 72/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2739 - accuracy: 0.8801 - val_loss: 0.5328 - val_accuracy: 0.8045\n",
      "Epoch 73/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2733 - accuracy: 0.8801 - val_loss: 0.5359 - val_accuracy: 0.7965\n",
      "Epoch 74/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2714 - accuracy: 0.8914 - val_loss: 0.5348 - val_accuracy: 0.7933\n",
      "Epoch 75/200\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.2688 - accuracy: 0.8989 - val_loss: 0.5363 - val_accuracy: 0.7965\n",
      "Epoch 76/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2726 - accuracy: 0.8876 - val_loss: 0.5371 - val_accuracy: 0.7949\n",
      "Epoch 77/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2702 - accuracy: 0.8876 - val_loss: 0.5454 - val_accuracy: 0.7981\n",
      "Epoch 78/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2696 - accuracy: 0.8876 - val_loss: 0.5390 - val_accuracy: 0.7933\n",
      "Epoch 79/200\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.2685 - accuracy: 0.8951 - val_loss: 0.5479 - val_accuracy: 0.7965\n",
      "Epoch 80/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2648 - accuracy: 0.8951 - val_loss: 0.5492 - val_accuracy: 0.7965\n",
      "Epoch 81/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2687 - accuracy: 0.8801 - val_loss: 0.5546 - val_accuracy: 0.7933\n",
      "Epoch 82/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2683 - accuracy: 0.8876 - val_loss: 0.5576 - val_accuracy: 0.7933\n",
      "Epoch 83/200\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.2603 - accuracy: 0.8914 - val_loss: 0.5555 - val_accuracy: 0.7933\n",
      "Epoch 84/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2684 - accuracy: 0.8801 - val_loss: 0.5603 - val_accuracy: 0.7981\n",
      "Epoch 85/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2727 - accuracy: 0.8764 - val_loss: 0.5722 - val_accuracy: 0.7981\n",
      "Epoch 86/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2596 - accuracy: 0.8951 - val_loss: 0.5654 - val_accuracy: 0.7949\n",
      "Epoch 87/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2668 - accuracy: 0.8839 - val_loss: 0.5677 - val_accuracy: 0.7885\n",
      "Epoch 88/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2589 - accuracy: 0.8914 - val_loss: 0.5750 - val_accuracy: 0.7917\n",
      "Epoch 89/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2619 - accuracy: 0.8951 - val_loss: 0.5734 - val_accuracy: 0.7917\n",
      "Epoch 90/200\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.2614 - accuracy: 0.8876 - val_loss: 0.5727 - val_accuracy: 0.7933\n",
      "Epoch 91/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2551 - accuracy: 0.8876 - val_loss: 0.5785 - val_accuracy: 0.7933\n",
      "Epoch 92/200\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.2555 - accuracy: 0.8951 - val_loss: 0.5803 - val_accuracy: 0.7869\n",
      "Epoch 93/200\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.2579 - accuracy: 0.8876 - val_loss: 0.5798 - val_accuracy: 0.7917\n",
      "Epoch 94/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.2527 - accuracy: 0.8914 - val_loss: 0.5881 - val_accuracy: 0.7933\n",
      "Epoch 95/200\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.2588 - accuracy: 0.8839 - val_loss: 0.5909 - val_accuracy: 0.7933\n",
      "Epoch 96/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.2541 - accuracy: 0.8914 - val_loss: 0.5851 - val_accuracy: 0.7933\n",
      "Epoch 97/200\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.2552 - accuracy: 0.8914 - val_loss: 0.5931 - val_accuracy: 0.7933\n",
      "Epoch 98/200\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.2499 - accuracy: 0.8914 - val_loss: 0.5914 - val_accuracy: 0.7917\n",
      "Epoch 99/200\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.2501 - accuracy: 0.8914 - val_loss: 0.5940 - val_accuracy: 0.7885\n",
      "Epoch 100/200\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.2489 - accuracy: 0.8876 - val_loss: 0.6076 - val_accuracy: 0.7965\n",
      "Epoch 101/200\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.2493 - accuracy: 0.8951 - val_loss: 0.6038 - val_accuracy: 0.7917\n",
      "Epoch 102/200\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.2525 - accuracy: 0.8914 - val_loss: 0.6081 - val_accuracy: 0.7933\n",
      "Epoch 103/200\n",
      "7/7 [==============================] - 0s 31ms/step - loss: 0.2450 - accuracy: 0.8951 - val_loss: 0.6057 - val_accuracy: 0.7917\n",
      "Epoch 104/200\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.2470 - accuracy: 0.8989 - val_loss: 0.6164 - val_accuracy: 0.7917\n",
      "Epoch 105/200\n",
      "7/7 [==============================] - 0s 27ms/step - loss: 0.2450 - accuracy: 0.8876 - val_loss: 0.6148 - val_accuracy: 0.7933\n",
      "Epoch 106/200\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.2546 - accuracy: 0.8876 - val_loss: 0.6195 - val_accuracy: 0.7869\n",
      "Epoch 107/200\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.2464 - accuracy: 0.8951 - val_loss: 0.6118 - val_accuracy: 0.7949\n",
      "Epoch 108/200\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.2451 - accuracy: 0.8951 - val_loss: 0.6161 - val_accuracy: 0.7965\n",
      "Epoch 109/200\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.2473 - accuracy: 0.8914 - val_loss: 0.6244 - val_accuracy: 0.7965\n",
      "Epoch 110/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2401 - accuracy: 0.9026 - val_loss: 0.6318 - val_accuracy: 0.7933\n",
      "Epoch 111/200\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.2403 - accuracy: 0.8951 - val_loss: 0.6313 - val_accuracy: 0.7885\n",
      "Epoch 112/200\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.2463 - accuracy: 0.9026 - val_loss: 0.6378 - val_accuracy: 0.7949\n",
      "Epoch 113/200\n",
      "7/7 [==============================] - 0s 26ms/step - loss: 0.2414 - accuracy: 0.8876 - val_loss: 0.6367 - val_accuracy: 0.7933\n",
      "Epoch 114/200\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.2391 - accuracy: 0.8989 - val_loss: 0.6415 - val_accuracy: 0.7853\n",
      "Epoch 115/200\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.2398 - accuracy: 0.8876 - val_loss: 0.6393 - val_accuracy: 0.7933\n",
      "Epoch 116/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2383 - accuracy: 0.8951 - val_loss: 0.6498 - val_accuracy: 0.7901\n",
      "Epoch 117/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2467 - accuracy: 0.8876 - val_loss: 0.6526 - val_accuracy: 0.7917\n",
      "Epoch 118/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2422 - accuracy: 0.8989 - val_loss: 0.6416 - val_accuracy: 0.7885\n",
      "Epoch 119/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2397 - accuracy: 0.8989 - val_loss: 0.6555 - val_accuracy: 0.7917\n",
      "Epoch 120/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2398 - accuracy: 0.9026 - val_loss: 0.6616 - val_accuracy: 0.7981\n",
      "Epoch 121/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.2320 - accuracy: 0.8914 - val_loss: 0.6648 - val_accuracy: 0.7869\n",
      "Epoch 122/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2343 - accuracy: 0.8989 - val_loss: 0.6582 - val_accuracy: 0.7901\n",
      "Epoch 123/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2324 - accuracy: 0.8989 - val_loss: 0.6719 - val_accuracy: 0.7885\n",
      "Epoch 124/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2336 - accuracy: 0.8989 - val_loss: 0.6839 - val_accuracy: 0.7853\n",
      "Epoch 125/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2325 - accuracy: 0.8989 - val_loss: 0.6771 - val_accuracy: 0.7901\n",
      "Epoch 126/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2338 - accuracy: 0.8989 - val_loss: 0.6741 - val_accuracy: 0.7869\n",
      "Epoch 127/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2314 - accuracy: 0.8951 - val_loss: 0.6854 - val_accuracy: 0.7869\n",
      "Epoch 128/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2384 - accuracy: 0.8951 - val_loss: 0.7051 - val_accuracy: 0.7965\n",
      "Epoch 129/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2324 - accuracy: 0.8951 - val_loss: 0.6831 - val_accuracy: 0.7901\n",
      "Epoch 130/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2324 - accuracy: 0.8914 - val_loss: 0.6805 - val_accuracy: 0.7853\n",
      "Epoch 131/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2358 - accuracy: 0.8914 - val_loss: 0.6871 - val_accuracy: 0.7869\n",
      "Epoch 132/200\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.2346 - accuracy: 0.8989 - val_loss: 0.6808 - val_accuracy: 0.7869\n",
      "Epoch 133/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2360 - accuracy: 0.8876 - val_loss: 0.7132 - val_accuracy: 0.7965\n",
      "Epoch 134/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2281 - accuracy: 0.8989 - val_loss: 0.6975 - val_accuracy: 0.7885\n",
      "Epoch 135/200\n",
      "7/7 [==============================] - 0s 21ms/step - loss: 0.2301 - accuracy: 0.8914 - val_loss: 0.7042 - val_accuracy: 0.7917\n",
      "Epoch 136/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2256 - accuracy: 0.9026 - val_loss: 0.7062 - val_accuracy: 0.7837\n",
      "Epoch 137/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2229 - accuracy: 0.8951 - val_loss: 0.7109 - val_accuracy: 0.7885\n",
      "Epoch 138/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2266 - accuracy: 0.8951 - val_loss: 0.7157 - val_accuracy: 0.7853\n",
      "Epoch 139/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2235 - accuracy: 0.9026 - val_loss: 0.7137 - val_accuracy: 0.7853\n",
      "Epoch 140/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2251 - accuracy: 0.8839 - val_loss: 0.7045 - val_accuracy: 0.7885\n",
      "Epoch 141/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2234 - accuracy: 0.8989 - val_loss: 0.7162 - val_accuracy: 0.7869\n",
      "Epoch 142/200\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.2265 - accuracy: 0.8914 - val_loss: 0.7348 - val_accuracy: 0.7869\n",
      "Epoch 143/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2204 - accuracy: 0.9064 - val_loss: 0.7226 - val_accuracy: 0.7885\n",
      "Epoch 144/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2207 - accuracy: 0.8989 - val_loss: 0.7289 - val_accuracy: 0.7885\n",
      "Epoch 145/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2166 - accuracy: 0.9026 - val_loss: 0.7344 - val_accuracy: 0.7869\n",
      "Epoch 146/200\n",
      "7/7 [==============================] - 0s 29ms/step - loss: 0.2240 - accuracy: 0.8989 - val_loss: 0.7322 - val_accuracy: 0.7837\n",
      "Epoch 147/200\n",
      "7/7 [==============================] - 0s 30ms/step - loss: 0.2175 - accuracy: 0.8989 - val_loss: 0.7388 - val_accuracy: 0.7837\n",
      "Epoch 148/200\n",
      "7/7 [==============================] - 0s 28ms/step - loss: 0.2187 - accuracy: 0.9026 - val_loss: 0.7361 - val_accuracy: 0.7853\n",
      "Epoch 149/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.2247 - accuracy: 0.9026 - val_loss: 0.7478 - val_accuracy: 0.7853\n",
      "Epoch 150/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2255 - accuracy: 0.9064 - val_loss: 0.7440 - val_accuracy: 0.7901\n",
      "Epoch 151/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2264 - accuracy: 0.9026 - val_loss: 0.7577 - val_accuracy: 0.7901\n",
      "Epoch 152/200\n",
      "7/7 [==============================] - 0s 25ms/step - loss: 0.2191 - accuracy: 0.8989 - val_loss: 0.7542 - val_accuracy: 0.7853\n",
      "Epoch 153/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2258 - accuracy: 0.8914 - val_loss: 0.7581 - val_accuracy: 0.7837\n",
      "Epoch 154/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2189 - accuracy: 0.9026 - val_loss: 0.7456 - val_accuracy: 0.7837\n",
      "Epoch 155/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2211 - accuracy: 0.8951 - val_loss: 0.7564 - val_accuracy: 0.7804\n",
      "Epoch 156/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2159 - accuracy: 0.8989 - val_loss: 0.7579 - val_accuracy: 0.7837\n",
      "Epoch 157/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2151 - accuracy: 0.9026 - val_loss: 0.7702 - val_accuracy: 0.7917\n",
      "Epoch 158/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2190 - accuracy: 0.9026 - val_loss: 0.7750 - val_accuracy: 0.7917\n",
      "Epoch 159/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2183 - accuracy: 0.9101 - val_loss: 0.7711 - val_accuracy: 0.7885\n",
      "Epoch 160/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2253 - accuracy: 0.9139 - val_loss: 0.7754 - val_accuracy: 0.7885\n",
      "Epoch 161/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2159 - accuracy: 0.9139 - val_loss: 0.7872 - val_accuracy: 0.7885\n",
      "Epoch 162/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2273 - accuracy: 0.9064 - val_loss: 0.7759 - val_accuracy: 0.7804\n",
      "Epoch 163/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2140 - accuracy: 0.9064 - val_loss: 0.7702 - val_accuracy: 0.7837\n",
      "Epoch 164/200\n",
      "7/7 [==============================] - 0s 24ms/step - loss: 0.2099 - accuracy: 0.8951 - val_loss: 0.7924 - val_accuracy: 0.7837\n",
      "Epoch 165/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2111 - accuracy: 0.9101 - val_loss: 0.7915 - val_accuracy: 0.7821\n",
      "Epoch 166/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2162 - accuracy: 0.9101 - val_loss: 0.7872 - val_accuracy: 0.7837\n",
      "Epoch 167/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2104 - accuracy: 0.9064 - val_loss: 0.8031 - val_accuracy: 0.7821\n",
      "Epoch 168/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2133 - accuracy: 0.9064 - val_loss: 0.7855 - val_accuracy: 0.7869\n",
      "Epoch 169/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2071 - accuracy: 0.9176 - val_loss: 0.8046 - val_accuracy: 0.7901\n",
      "Epoch 170/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2120 - accuracy: 0.9026 - val_loss: 0.8061 - val_accuracy: 0.7837\n",
      "Epoch 171/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2070 - accuracy: 0.9139 - val_loss: 0.8082 - val_accuracy: 0.7885\n",
      "Epoch 172/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2159 - accuracy: 0.9026 - val_loss: 0.8169 - val_accuracy: 0.7804\n",
      "Epoch 173/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2127 - accuracy: 0.8951 - val_loss: 0.8226 - val_accuracy: 0.7853\n",
      "Epoch 174/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2030 - accuracy: 0.9064 - val_loss: 0.8141 - val_accuracy: 0.7853\n",
      "Epoch 175/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2114 - accuracy: 0.9064 - val_loss: 0.8256 - val_accuracy: 0.7949\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 176/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2142 - accuracy: 0.8951 - val_loss: 0.8257 - val_accuracy: 0.7869\n",
      "Epoch 177/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2030 - accuracy: 0.9101 - val_loss: 0.8214 - val_accuracy: 0.7869\n",
      "Epoch 178/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2053 - accuracy: 0.9064 - val_loss: 0.8277 - val_accuracy: 0.7917\n",
      "Epoch 179/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2001 - accuracy: 0.9026 - val_loss: 0.8271 - val_accuracy: 0.7949\n",
      "Epoch 180/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2041 - accuracy: 0.9101 - val_loss: 0.8416 - val_accuracy: 0.7869\n",
      "Epoch 181/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2088 - accuracy: 0.9064 - val_loss: 0.8392 - val_accuracy: 0.7885\n",
      "Epoch 182/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2009 - accuracy: 0.9176 - val_loss: 0.8491 - val_accuracy: 0.7917\n",
      "Epoch 183/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2029 - accuracy: 0.9064 - val_loss: 0.8485 - val_accuracy: 0.7853\n",
      "Epoch 184/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2112 - accuracy: 0.9064 - val_loss: 0.8622 - val_accuracy: 0.7901\n",
      "Epoch 185/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2178 - accuracy: 0.9064 - val_loss: 0.8666 - val_accuracy: 0.7885\n",
      "Epoch 186/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2081 - accuracy: 0.9026 - val_loss: 0.8632 - val_accuracy: 0.7853\n",
      "Epoch 187/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2046 - accuracy: 0.9026 - val_loss: 0.8435 - val_accuracy: 0.7837\n",
      "Epoch 188/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2037 - accuracy: 0.9064 - val_loss: 0.8597 - val_accuracy: 0.7965\n",
      "Epoch 189/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2100 - accuracy: 0.9101 - val_loss: 0.8618 - val_accuracy: 0.7917\n",
      "Epoch 190/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2013 - accuracy: 0.9139 - val_loss: 0.8613 - val_accuracy: 0.7804\n",
      "Epoch 191/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.2015 - accuracy: 0.8989 - val_loss: 0.8822 - val_accuracy: 0.7917\n",
      "Epoch 192/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.1957 - accuracy: 0.9176 - val_loss: 0.8700 - val_accuracy: 0.7821\n",
      "Epoch 193/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2019 - accuracy: 0.9288 - val_loss: 0.8888 - val_accuracy: 0.7837\n",
      "Epoch 194/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.1968 - accuracy: 0.9064 - val_loss: 0.8851 - val_accuracy: 0.7821\n",
      "Epoch 195/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.1980 - accuracy: 0.9139 - val_loss: 0.9042 - val_accuracy: 0.7901\n",
      "Epoch 196/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2031 - accuracy: 0.8989 - val_loss: 0.8894 - val_accuracy: 0.7821\n",
      "Epoch 197/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.1937 - accuracy: 0.9213 - val_loss: 0.8890 - val_accuracy: 0.7853\n",
      "Epoch 198/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2024 - accuracy: 0.9176 - val_loss: 0.8904 - val_accuracy: 0.7885\n",
      "Epoch 199/200\n",
      "7/7 [==============================] - 0s 22ms/step - loss: 0.2087 - accuracy: 0.9139 - val_loss: 0.9161 - val_accuracy: 0.7917\n",
      "Epoch 200/200\n",
      "7/7 [==============================] - 0s 23ms/step - loss: 0.1919 - accuracy: 0.9213 - val_loss: 0.8897 - val_accuracy: 0.7804\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, epochs=200, batch_size=40, validation_data=(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ed92878",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 136번째 정확도 90넘어"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5a7a5bd",
   "metadata": {},
   "source": [
    "# 딥러닝 모델 성능 평가\n",
    "* 딥러닝에서 모델의 성능을 평가하는 지표는 주로 loss를 본다\n",
    "*로스는? 회귀에서 회귀선과 데이터의 오차 (mse,sse)\n",
    "* 보통 loss가 낮으면 accuracy가 올라가지만 비례하지 않을 때도 있음.\n",
    "* 두 지표간에 차이가 있을 경우 loss가 낮은 모델이 우수한 모델"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f3de9578",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 5ms/step - loss: 0.8897 - accuracy: 0.7804\n",
      "test loss 0.8897191882133484\n",
      "test accuracy 0.7804487347602844\n"
     ]
    }
   ],
   "source": [
    "score = model.evaluate(X_test, y_test)\n",
    "print('test loss', score[0])\n",
    "print('test accuracy', score[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1710285",
   "metadata": {},
   "outputs": [],
   "source": [
    "#로스가 일정기간 변화없으면 로스 낮은거 중간중간 저장하게 만들어야한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49cb827d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c88b206",
   "metadata": {},
   "source": [
    "# 딥러닝 학습결과 시각화"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d9e01d3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['loss', 'accuracy', 'val_loss', 'val_accuracy'])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ad032735",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2000x1000 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,10))\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('loss')\n",
    "plt.legend(['train', 'val'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2d9a611b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20/20 [==============================] - 0s 3ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[3.45231891e-02],\n",
       "       [6.15967475e-02],\n",
       "       [8.17954689e-02],\n",
       "       [9.99998093e-01],\n",
       "       [9.99994397e-01],\n",
       "       [1.21228337e-01],\n",
       "       [8.56533423e-02],\n",
       "       [1.60657614e-02],\n",
       "       [9.25404802e-02],\n",
       "       [4.63281758e-02],\n",
       "       [4.42719873e-04],\n",
       "       [9.99910831e-01],\n",
       "       [4.03923020e-02],\n",
       "       [9.48717445e-02],\n",
       "       [1.22370094e-03],\n",
       "       [1.48011732e-03],\n",
       "       [1.76621995e-06],\n",
       "       [3.04611051e-04],\n",
       "       [4.27913755e-01],\n",
       "       [1.53766721e-01],\n",
       "       [5.21501992e-03],\n",
       "       [9.42184776e-03],\n",
       "       [9.94426966e-01],\n",
       "       [6.06274046e-03],\n",
       "       [9.99032497e-01],\n",
       "       [6.15967475e-02],\n",
       "       [6.15967475e-02],\n",
       "       [9.99999642e-01],\n",
       "       [1.01971189e-02],\n",
       "       [1.00000000e+00],\n",
       "       [9.99994397e-01],\n",
       "       [1.48011732e-03],\n",
       "       [1.48941562e-01],\n",
       "       [9.04009736e-04],\n",
       "       [9.99963045e-01],\n",
       "       [5.48034087e-02],\n",
       "       [4.46018457e-01],\n",
       "       [9.16238832e-07],\n",
       "       [7.60529563e-02],\n",
       "       [9.25404802e-02],\n",
       "       [9.47619963e-04],\n",
       "       [3.54192592e-03],\n",
       "       [5.48034087e-02],\n",
       "       [8.95671732e-08],\n",
       "       [2.23502200e-02],\n",
       "       [2.40035027e-01],\n",
       "       [3.52986604e-02],\n",
       "       [3.52986604e-02],\n",
       "       [9.99958873e-01],\n",
       "       [2.89232470e-02],\n",
       "       [1.64652035e-01],\n",
       "       [1.38222296e-02],\n",
       "       [3.20494883e-02],\n",
       "       [9.90019321e-01],\n",
       "       [9.99792278e-01],\n",
       "       [9.99960780e-01],\n",
       "       [8.13955849e-04],\n",
       "       [5.52710533e-01],\n",
       "       [1.00000000e+00],\n",
       "       [8.54661455e-04],\n",
       "       [6.69778064e-02],\n",
       "       [1.00000000e+00],\n",
       "       [7.85596728e-01],\n",
       "       [4.67461616e-01],\n",
       "       [5.96941682e-04],\n",
       "       [1.42608747e-01],\n",
       "       [1.52660841e-02],\n",
       "       [6.62449896e-02],\n",
       "       [4.63802479e-02],\n",
       "       [9.10364985e-01],\n",
       "       [2.60723149e-03],\n",
       "       [1.14462890e-01],\n",
       "       [8.56533423e-02],\n",
       "       [5.23376046e-03],\n",
       "       [9.45724428e-01],\n",
       "       [1.59745917e-01],\n",
       "       [6.07488491e-02],\n",
       "       [6.47933263e-09],\n",
       "       [1.57238305e-01],\n",
       "       [3.48979607e-02],\n",
       "       [4.80562821e-03],\n",
       "       [7.60529563e-02],\n",
       "       [1.33148220e-03],\n",
       "       [9.98492241e-01],\n",
       "       [9.80862975e-01],\n",
       "       [2.64904834e-03],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999762e-01],\n",
       "       [1.54564739e-03],\n",
       "       [4.06271100e-01],\n",
       "       [9.25404802e-02],\n",
       "       [7.60529563e-02],\n",
       "       [9.48717445e-02],\n",
       "       [5.48034087e-02],\n",
       "       [9.99999523e-01],\n",
       "       [5.06173313e-01],\n",
       "       [2.90741622e-01],\n",
       "       [4.96998988e-03],\n",
       "       [9.99985099e-01],\n",
       "       [5.84903918e-02],\n",
       "       [4.54697153e-03],\n",
       "       [3.54627103e-01],\n",
       "       [7.89987738e-04],\n",
       "       [2.59485319e-02],\n",
       "       [5.46392143e-01],\n",
       "       [9.98457193e-01],\n",
       "       [1.48011732e-03],\n",
       "       [2.33031645e-01],\n",
       "       [7.03779638e-01],\n",
       "       [6.01602755e-02],\n",
       "       [6.43481612e-01],\n",
       "       [2.35973188e-04],\n",
       "       [1.00000000e+00],\n",
       "       [5.48034087e-02],\n",
       "       [1.21228337e-01],\n",
       "       [2.22829152e-02],\n",
       "       [3.01080376e-01],\n",
       "       [9.99999881e-01],\n",
       "       [4.96356875e-01],\n",
       "       [9.22049165e-01],\n",
       "       [9.99999762e-01],\n",
       "       [5.68462566e-09],\n",
       "       [9.99998927e-01],\n",
       "       [7.80850828e-01],\n",
       "       [7.69428670e-01],\n",
       "       [7.85596728e-01],\n",
       "       [1.00000000e+00],\n",
       "       [5.21501992e-03],\n",
       "       [5.48034087e-02],\n",
       "       [9.99792278e-01],\n",
       "       [9.99999881e-01],\n",
       "       [4.63281758e-02],\n",
       "       [7.98631981e-02],\n",
       "       [1.00000000e+00],\n",
       "       [9.80716109e-01],\n",
       "       [5.06173313e-01],\n",
       "       [8.75840022e-04],\n",
       "       [1.57238305e-01],\n",
       "       [9.99979854e-01],\n",
       "       [7.26998895e-02],\n",
       "       [7.13056684e-01],\n",
       "       [8.17954689e-02],\n",
       "       [9.48717445e-02],\n",
       "       [9.96865053e-03],\n",
       "       [5.48034087e-02],\n",
       "       [5.48034087e-02],\n",
       "       [1.14115579e-02],\n",
       "       [8.99478851e-04],\n",
       "       [2.87794452e-02],\n",
       "       [2.00879555e-02],\n",
       "       [6.70711696e-02],\n",
       "       [1.91112503e-01],\n",
       "       [9.99999285e-01],\n",
       "       [2.10940957e-01],\n",
       "       [4.34614494e-02],\n",
       "       [3.07057500e-01],\n",
       "       [5.48034087e-02],\n",
       "       [8.36704820e-02],\n",
       "       [7.60529563e-02],\n",
       "       [1.53766721e-01],\n",
       "       [8.24230374e-05],\n",
       "       [7.85596728e-01],\n",
       "       [3.85024101e-02],\n",
       "       [5.48034087e-02],\n",
       "       [1.42608747e-01],\n",
       "       [3.13761771e-01],\n",
       "       [9.25404802e-02],\n",
       "       [9.98210981e-02],\n",
       "       [9.68115330e-01],\n",
       "       [3.52986604e-02],\n",
       "       [9.99340832e-01],\n",
       "       [9.99988675e-01],\n",
       "       [1.78101734e-04],\n",
       "       [7.05950737e-01],\n",
       "       [8.46162811e-02],\n",
       "       [8.73763580e-04],\n",
       "       [2.69925743e-01],\n",
       "       [8.30456614e-03],\n",
       "       [1.57238305e-01],\n",
       "       [4.00767237e-01],\n",
       "       [9.67648327e-01],\n",
       "       [5.08372307e-01],\n",
       "       [9.48717445e-02],\n",
       "       [1.50977492e-01],\n",
       "       [4.66379046e-04],\n",
       "       [2.52456486e-01],\n",
       "       [8.56533423e-02],\n",
       "       [1.20956890e-01],\n",
       "       [1.07617415e-02],\n",
       "       [8.67377908e-04],\n",
       "       [3.89268845e-01],\n",
       "       [2.35462760e-08],\n",
       "       [9.49487686e-01],\n",
       "       [9.48717445e-02],\n",
       "       [6.07789734e-05],\n",
       "       [2.59485319e-02],\n",
       "       [6.00629733e-08],\n",
       "       [2.17183530e-02],\n",
       "       [9.98235822e-01],\n",
       "       [3.45231891e-02],\n",
       "       [7.19135106e-02],\n",
       "       [4.61869866e-01],\n",
       "       [7.26998895e-02],\n",
       "       [9.94948387e-01],\n",
       "       [7.60529563e-02],\n",
       "       [5.48034087e-02],\n",
       "       [9.48717445e-02],\n",
       "       [7.60529563e-02],\n",
       "       [6.21004581e-01],\n",
       "       [9.15944695e-01],\n",
       "       [4.44535119e-03],\n",
       "       [6.06274046e-03],\n",
       "       [9.54270456e-03],\n",
       "       [7.59556442e-02],\n",
       "       [5.11308259e-04],\n",
       "       [5.45492172e-01],\n",
       "       [7.85596728e-01],\n",
       "       [4.63281758e-02],\n",
       "       [6.15967475e-02],\n",
       "       [7.29690166e-03],\n",
       "       [9.99654651e-01],\n",
       "       [6.20738021e-04],\n",
       "       [9.99232173e-01],\n",
       "       [7.05950737e-01],\n",
       "       [8.54023278e-01],\n",
       "       [9.99855876e-01],\n",
       "       [5.85883968e-02],\n",
       "       [5.48034087e-02],\n",
       "       [1.12238911e-03],\n",
       "       [9.99968171e-01],\n",
       "       [1.21228337e-01],\n",
       "       [5.75653464e-03],\n",
       "       [5.06173313e-01],\n",
       "       [1.38250936e-03],\n",
       "       [8.04260597e-02],\n",
       "       [6.15967475e-02],\n",
       "       [7.60529563e-02],\n",
       "       [9.50757205e-01],\n",
       "       [3.52986604e-02],\n",
       "       [9.66211796e-01],\n",
       "       [9.99999881e-01],\n",
       "       [9.99999881e-01],\n",
       "       [9.24952984e-01],\n",
       "       [7.45803595e-01],\n",
       "       [8.17954689e-02],\n",
       "       [5.48034087e-02],\n",
       "       [3.02703887e-01],\n",
       "       [9.99970317e-01],\n",
       "       [6.35387450e-02],\n",
       "       [5.48034087e-02],\n",
       "       [5.48034087e-02],\n",
       "       [1.81388413e-14],\n",
       "       [5.76806404e-02],\n",
       "       [5.11308259e-04],\n",
       "       [9.99697924e-01],\n",
       "       [9.97993469e-01],\n",
       "       [7.59556442e-02],\n",
       "       [1.53766721e-01],\n",
       "       [9.97174323e-01],\n",
       "       [1.38250936e-03],\n",
       "       [9.48717445e-02],\n",
       "       [5.48034087e-02],\n",
       "       [6.47731423e-01],\n",
       "       [9.99686599e-01],\n",
       "       [1.35714920e-12],\n",
       "       [6.85672939e-01],\n",
       "       [3.04133892e-01],\n",
       "       [7.85596728e-01],\n",
       "       [1.29103082e-05],\n",
       "       [1.00000000e+00],\n",
       "       [1.91112503e-01],\n",
       "       [1.04233208e-04],\n",
       "       [3.49526435e-01],\n",
       "       [9.23085883e-02],\n",
       "       [9.98760343e-01],\n",
       "       [1.83704344e-06],\n",
       "       [9.95868206e-01],\n",
       "       [9.99970317e-01],\n",
       "       [4.28325310e-03],\n",
       "       [7.60529563e-02],\n",
       "       [9.99974608e-01],\n",
       "       [9.89805877e-01],\n",
       "       [9.98126090e-01],\n",
       "       [3.05026602e-02],\n",
       "       [6.90051496e-01],\n",
       "       [4.63281758e-02],\n",
       "       [9.99438465e-01],\n",
       "       [8.24794888e-01],\n",
       "       [8.96650076e-01],\n",
       "       [1.57238305e-01],\n",
       "       [7.98631981e-02],\n",
       "       [1.34547201e-06],\n",
       "       [2.86491774e-03],\n",
       "       [1.59745917e-01],\n",
       "       [9.99990582e-01],\n",
       "       [1.48118464e-02],\n",
       "       [1.81388413e-14],\n",
       "       [7.85596728e-01],\n",
       "       [3.06410581e-01],\n",
       "       [9.14050698e-01],\n",
       "       [1.11300040e-04],\n",
       "       [7.62594864e-02],\n",
       "       [3.75670642e-02],\n",
       "       [9.25404802e-02],\n",
       "       [6.45010686e-03],\n",
       "       [6.17507771e-02],\n",
       "       [3.05026602e-02],\n",
       "       [5.48034087e-02],\n",
       "       [9.46003012e-04],\n",
       "       [1.36517228e-05],\n",
       "       [9.99945283e-01],\n",
       "       [1.14462890e-01],\n",
       "       [3.52986604e-02],\n",
       "       [4.03923020e-02],\n",
       "       [4.15188042e-05],\n",
       "       [1.19323684e-02],\n",
       "       [9.75118041e-01],\n",
       "       [4.20887262e-01],\n",
       "       [2.29594377e-07],\n",
       "       [5.48034087e-02],\n",
       "       [4.22896534e-01],\n",
       "       [5.09260874e-03],\n",
       "       [9.99693274e-01],\n",
       "       [2.53736731e-02],\n",
       "       [9.99954939e-01],\n",
       "       [9.99973536e-01],\n",
       "       [4.63802479e-02],\n",
       "       [3.52986604e-02],\n",
       "       [7.23002304e-04],\n",
       "       [9.99617577e-01],\n",
       "       [9.26044941e-01],\n",
       "       [2.07892843e-02],\n",
       "       [4.34614494e-02],\n",
       "       [9.27810133e-01],\n",
       "       [3.02664369e-01],\n",
       "       [4.96412278e-04],\n",
       "       [9.88541245e-01],\n",
       "       [1.12035468e-01],\n",
       "       [1.53766721e-01],\n",
       "       [9.99990702e-01],\n",
       "       [2.94000119e-01],\n",
       "       [1.53766721e-01],\n",
       "       [9.99825776e-01],\n",
       "       [1.00000000e+00],\n",
       "       [5.48034087e-02],\n",
       "       [4.22896534e-01],\n",
       "       [2.27590725e-01],\n",
       "       [1.38915613e-01],\n",
       "       [1.53766721e-01],\n",
       "       [2.64904834e-03],\n",
       "       [9.23085883e-02],\n",
       "       [8.17954689e-02],\n",
       "       [5.85362494e-01],\n",
       "       [6.37615216e-04],\n",
       "       [7.60417879e-02],\n",
       "       [7.94307292e-01],\n",
       "       [1.53766721e-01],\n",
       "       [6.17507771e-02],\n",
       "       [1.58535026e-03],\n",
       "       [4.36299331e-02],\n",
       "       [9.66211796e-01],\n",
       "       [1.53766721e-01],\n",
       "       [6.15967475e-02],\n",
       "       [9.66211796e-01],\n",
       "       [1.09699438e-03],\n",
       "       [1.00000000e+00],\n",
       "       [9.99975681e-01],\n",
       "       [9.99998927e-01],\n",
       "       [9.99975085e-01],\n",
       "       [5.48034087e-02],\n",
       "       [7.98631981e-02],\n",
       "       [5.75354079e-06],\n",
       "       [1.21228337e-01],\n",
       "       [9.15944695e-01],\n",
       "       [7.98631981e-02],\n",
       "       [5.48034087e-02],\n",
       "       [3.04133892e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.99974608e-01],\n",
       "       [7.67999530e-01],\n",
       "       [9.80862975e-01],\n",
       "       [1.47490129e-02],\n",
       "       [2.10940957e-01],\n",
       "       [7.84150898e-01],\n",
       "       [9.12754476e-01],\n",
       "       [9.99111950e-01],\n",
       "       [8.04875135e-01],\n",
       "       [1.59745917e-01],\n",
       "       [1.59745917e-01],\n",
       "       [5.40535301e-02],\n",
       "       [8.61367024e-03],\n",
       "       [9.68115330e-01],\n",
       "       [1.21228337e-01],\n",
       "       [6.07488491e-02],\n",
       "       [9.25404802e-02],\n",
       "       [2.86491774e-03],\n",
       "       [8.73763580e-04],\n",
       "       [6.31063525e-03],\n",
       "       [9.77027774e-01],\n",
       "       [2.72460456e-04],\n",
       "       [1.21228337e-01],\n",
       "       [7.62594864e-02],\n",
       "       [8.56533423e-02],\n",
       "       [8.29183161e-01],\n",
       "       [1.58535026e-03],\n",
       "       [5.48034087e-02],\n",
       "       [5.32436417e-03],\n",
       "       [9.92371082e-01],\n",
       "       [2.06157821e-03],\n",
       "       [9.99994397e-01],\n",
       "       [9.48717445e-02],\n",
       "       [9.99697924e-01],\n",
       "       [9.34708595e-01],\n",
       "       [3.52986604e-02],\n",
       "       [8.81585062e-01],\n",
       "       [1.82195893e-03],\n",
       "       [4.00107443e-01],\n",
       "       [1.53766721e-01],\n",
       "       [1.53766721e-01],\n",
       "       [2.53616100e-10],\n",
       "       [9.87732887e-01],\n",
       "       [9.34956595e-02],\n",
       "       [7.85596728e-01],\n",
       "       [6.15967475e-02],\n",
       "       [9.99974966e-01],\n",
       "       [9.21074927e-01],\n",
       "       [4.83107775e-01],\n",
       "       [5.48034087e-02],\n",
       "       [7.49065101e-01],\n",
       "       [3.26968075e-06],\n",
       "       [9.99998689e-01],\n",
       "       [5.48034087e-02],\n",
       "       [9.96530950e-01],\n",
       "       [1.26514138e-07],\n",
       "       [8.58596042e-02],\n",
       "       [9.97785151e-01],\n",
       "       [9.99999166e-01],\n",
       "       [3.98695411e-05],\n",
       "       [1.46982357e-01],\n",
       "       [1.81165244e-02],\n",
       "       [9.68115330e-01],\n",
       "       [5.90844333e-01],\n",
       "       [9.66955304e-01],\n",
       "       [9.87322390e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.65788603e-01],\n",
       "       [9.99697924e-01],\n",
       "       [2.36951970e-02],\n",
       "       [3.06684598e-02],\n",
       "       [6.63403213e-01],\n",
       "       [9.99697924e-01],\n",
       "       [3.02703887e-01],\n",
       "       [5.48034087e-02],\n",
       "       [8.86658788e-01],\n",
       "       [9.99111950e-01],\n",
       "       [9.99659777e-01],\n",
       "       [7.10846856e-02],\n",
       "       [1.53766721e-01],\n",
       "       [3.06684598e-02],\n",
       "       [1.14115579e-02],\n",
       "       [8.68780771e-04],\n",
       "       [2.80531636e-03],\n",
       "       [1.11679728e-10],\n",
       "       [4.98914093e-01],\n",
       "       [9.99994397e-01],\n",
       "       [7.67314816e-07],\n",
       "       [9.81690943e-01],\n",
       "       [7.21363351e-03],\n",
       "       [9.14403275e-02],\n",
       "       [3.31122607e-07],\n",
       "       [2.69925743e-01],\n",
       "       [6.15967475e-02],\n",
       "       [9.28462446e-02],\n",
       "       [2.52331791e-08],\n",
       "       [8.17954689e-02],\n",
       "       [7.98631981e-02],\n",
       "       [6.70711696e-02],\n",
       "       [1.00000000e+00],\n",
       "       [9.99999881e-01],\n",
       "       [5.15896303e-08],\n",
       "       [8.29631805e-01],\n",
       "       [7.85596728e-01],\n",
       "       [3.26803029e-01],\n",
       "       [9.26077783e-01],\n",
       "       [9.65400506e-03],\n",
       "       [6.90051496e-01],\n",
       "       [5.40535301e-02],\n",
       "       [2.69925743e-01],\n",
       "       [1.42608747e-01],\n",
       "       [8.49728510e-02],\n",
       "       [1.50977492e-01],\n",
       "       [1.75197273e-01],\n",
       "       [1.54564739e-03],\n",
       "       [9.99998808e-01],\n",
       "       [2.80834526e-01],\n",
       "       [7.80850828e-01],\n",
       "       [2.82057747e-02],\n",
       "       [1.38915613e-01],\n",
       "       [8.56533423e-02],\n",
       "       [9.99998927e-01],\n",
       "       [6.17507771e-02],\n",
       "       [9.99739945e-01],\n",
       "       [9.48717445e-02],\n",
       "       [9.65400506e-03],\n",
       "       [5.48034087e-02],\n",
       "       [5.76893091e-01],\n",
       "       [9.53434885e-01],\n",
       "       [4.67633916e-04],\n",
       "       [9.84784603e-01],\n",
       "       [4.96998988e-03],\n",
       "       [1.37219608e-01],\n",
       "       [9.99373972e-01],\n",
       "       [5.46392143e-01],\n",
       "       [1.10114329e-02],\n",
       "       [3.02703887e-01],\n",
       "       [5.81408858e-01],\n",
       "       [9.98379946e-01],\n",
       "       [1.53766721e-01],\n",
       "       [1.00000000e+00],\n",
       "       [1.57238305e-01],\n",
       "       [5.54902246e-03],\n",
       "       [1.65969543e-02],\n",
       "       [1.33847459e-06],\n",
       "       [1.24847274e-02],\n",
       "       [1.78497133e-03],\n",
       "       [2.94000119e-01],\n",
       "       [1.78497133e-03],\n",
       "       [1.48472577e-01],\n",
       "       [5.33180058e-01],\n",
       "       [2.87794452e-02],\n",
       "       [9.99990463e-01],\n",
       "       [1.01971189e-02],\n",
       "       [4.42719873e-04],\n",
       "       [1.75197273e-01],\n",
       "       [9.88906026e-01],\n",
       "       [9.66040075e-01],\n",
       "       [9.98126090e-01],\n",
       "       [3.52986604e-02],\n",
       "       [1.42608747e-01],\n",
       "       [8.73763580e-04],\n",
       "       [1.48011732e-03],\n",
       "       [9.99032378e-01],\n",
       "       [1.50977492e-01],\n",
       "       [5.13954973e-03],\n",
       "       [4.63281758e-02],\n",
       "       [6.42496743e-04],\n",
       "       [4.35848013e-02],\n",
       "       [1.42768156e-02],\n",
       "       [4.63281758e-02],\n",
       "       [5.48034087e-02],\n",
       "       [8.56533423e-02],\n",
       "       [1.09699438e-03],\n",
       "       [1.12035468e-01],\n",
       "       [5.85883968e-02],\n",
       "       [9.99895930e-01],\n",
       "       [6.63403213e-01],\n",
       "       [5.72346500e-04],\n",
       "       [2.89783686e-01],\n",
       "       [8.75700891e-01],\n",
       "       [1.45264035e-02],\n",
       "       [9.99998927e-01],\n",
       "       [5.84630780e-02],\n",
       "       [5.48034087e-02],\n",
       "       [9.99995947e-01],\n",
       "       [5.85883968e-02],\n",
       "       [7.60529563e-02],\n",
       "       [9.70797002e-01],\n",
       "       [7.10846856e-02],\n",
       "       [7.60529563e-02],\n",
       "       [9.99322295e-01],\n",
       "       [2.00152115e-07],\n",
       "       [7.60529563e-02],\n",
       "       [1.00000000e+00],\n",
       "       [1.54564739e-03],\n",
       "       [1.62909806e-01],\n",
       "       [1.98786631e-01],\n",
       "       [7.92833924e-01],\n",
       "       [4.96356875e-01],\n",
       "       [9.99942422e-01],\n",
       "       [4.96949442e-03],\n",
       "       [9.99937654e-01],\n",
       "       [3.52986604e-02],\n",
       "       [8.43629241e-01],\n",
       "       [1.00000000e+00],\n",
       "       [9.92480755e-01],\n",
       "       [3.77742708e-01],\n",
       "       [3.39176438e-08],\n",
       "       [9.82696831e-01],\n",
       "       [7.85596728e-01],\n",
       "       [1.48011732e-03],\n",
       "       [7.60529563e-02],\n",
       "       [1.13132149e-01],\n",
       "       [1.21228337e-01],\n",
       "       [6.17507771e-02],\n",
       "       [9.54870284e-01],\n",
       "       [5.48034087e-02],\n",
       "       [1.28896624e-01],\n",
       "       [9.07663226e-01],\n",
       "       [7.85596728e-01],\n",
       "       [1.91112503e-01],\n",
       "       [8.33023190e-01],\n",
       "       [2.27590725e-01],\n",
       "       [5.48034087e-02],\n",
       "       [1.79392010e-01],\n",
       "       [9.99288380e-01],\n",
       "       [9.52156028e-04],\n",
       "       [1.42768156e-02],\n",
       "       [8.04260597e-02],\n",
       "       [1.14462890e-01],\n",
       "       [6.74481869e-01],\n",
       "       [2.36951970e-02],\n",
       "       [1.53766721e-01],\n",
       "       [3.82215768e-01],\n",
       "       [9.99991536e-01],\n",
       "       [5.52710533e-01],\n",
       "       [9.99974608e-01],\n",
       "       [9.89805877e-01],\n",
       "       [6.06274046e-03],\n",
       "       [4.63281758e-02],\n",
       "       [3.31157334e-02],\n",
       "       [9.99978781e-01],\n",
       "       [2.64904834e-03],\n",
       "       [8.44400929e-05],\n",
       "       [2.87794452e-02]], dtype=float32)"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred = model.predict(X_test)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "d5f0d313",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.034523</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.061597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.081795</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.999998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.999994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>619</th>\n",
       "      <td>0.033116</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>620</th>\n",
       "      <td>0.999979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>621</th>\n",
       "      <td>0.002649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>622</th>\n",
       "      <td>0.000084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>623</th>\n",
       "      <td>0.028779</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>624 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            0\n",
       "0    0.034523\n",
       "1    0.061597\n",
       "2    0.081795\n",
       "3    0.999998\n",
       "4    0.999994\n",
       "..        ...\n",
       "619  0.033116\n",
       "620  0.999979\n",
       "621  0.002649\n",
       "622  0.000084\n",
       "623  0.028779\n",
       "\n",
       "[624 rows x 1 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred =pd.DataFrame(pred)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "c720a10b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      0\n",
       "1      0\n",
       "2      0\n",
       "3      1\n",
       "4      1\n",
       "      ..\n",
       "619    0\n",
       "620    1\n",
       "621    0\n",
       "622    0\n",
       "623    0\n",
       "Name: 0, Length: 624, dtype: int64"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred= pred[0].apply(lambda x: 1 if x>=0.7 else 0)\n",
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "ec0ce322",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.78      0.89      0.83       386\n",
      "           1       0.77      0.59      0.67       238\n",
      "\n",
      "    accuracy                           0.78       624\n",
      "   macro avg       0.77      0.74      0.75       624\n",
      "weighted avg       0.77      0.78      0.77       624\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9858fafd",
   "metadata": {},
   "source": [
    "# Tensorflow Functional API를 이용한 함수형 모델\n",
    "* Sequential API는 단순히 층을 여러개 쌓는 형태라 복잡한 모델 생성에 한계가 있어\n",
    "* Functional API는 입력층과 출력층을 사용자가 직접 정의 가능\n",
    "* 다중입력(Multi-input), 다중출력(Multi-output)등 복잡한 모델을 정의 할 수 있음\n",
    "* Input(shape=(독립변수 수))로 입력층 정의\n",
    "* 이전 층을 다음 층의 입력으로 사용\n",
    "* model()에 입력과 출력 정의\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "8c35ec4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "835ce6d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_3 (InputLayer)        [(None, 6)]               0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 32)                224       \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 64)                2112      \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 16)                528       \n",
      "                                                                 \n",
      " dense_20 (Dense)            (None, 1)                 17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,961\n",
      "Trainable params: 4,961\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "inputs = Input(shape=(X_train.shape[1])) #입력층 정의 Input(shape=(독립변수 수,))  #튜플형태로 들어가기에 컴마 적어주기\n",
    "x = Dense(32, activation='relu')(inputs)  #은닉층 1번\n",
    "x = Dense(64, activation='relu')(x)  #은닉층2번\n",
    "x = Dense(32, activation='relu')(x)  #은닉층3번\n",
    "x = Dense(16, activation='relu')(x)  #은닉층4번\n",
    "x = Dense(1, activation='sigmoid')(x)  #출력층\n",
    "model = Model(inputs, x)  #가변인수로 인풋에 여러개 넣을 수 있다는 것이 싴퀀셜과의 차이\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "662459a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 15:21:09.445287: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-09 15:21:09.511310: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-09 15:21:09.511369: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 1s 89ms/step - loss: 0.7409 - accuracy: 0.3858 - val_loss: 0.7236 - val_accuracy: 0.3734\n",
      "Epoch 2/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.7087 - accuracy: 0.3895 - val_loss: 0.7017 - val_accuracy: 0.3830\n",
      "Epoch 3/400\n",
      "1/3 [=========>....................] - ETA: 0s - loss: 0.6896 - accuracy: 0.4100"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 15:21:09.782476: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-09 15:21:09.809166: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-09 15:21:09.809227: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 36ms/step - loss: 0.6871 - accuracy: 0.4494 - val_loss: 0.6848 - val_accuracy: 0.4423\n",
      "Epoch 4/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6676 - accuracy: 0.5730 - val_loss: 0.6693 - val_accuracy: 0.6490\n",
      "Epoch 5/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.6507 - accuracy: 0.7528 - val_loss: 0.6559 - val_accuracy: 0.6843\n",
      "Epoch 6/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.6358 - accuracy: 0.7903 - val_loss: 0.6426 - val_accuracy: 0.7228\n",
      "Epoch 7/400\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.6210 - accuracy: 0.8015 - val_loss: 0.6293 - val_accuracy: 0.7436\n",
      "Epoch 8/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.6060 - accuracy: 0.8015 - val_loss: 0.6164 - val_accuracy: 0.7788\n",
      "Epoch 9/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5912 - accuracy: 0.8127 - val_loss: 0.6030 - val_accuracy: 0.7869\n",
      "Epoch 10/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5748 - accuracy: 0.8127 - val_loss: 0.5889 - val_accuracy: 0.7901\n",
      "Epoch 11/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5584 - accuracy: 0.8202 - val_loss: 0.5746 - val_accuracy: 0.7885\n",
      "Epoch 12/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.5419 - accuracy: 0.8202 - val_loss: 0.5605 - val_accuracy: 0.7917\n",
      "Epoch 13/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.5260 - accuracy: 0.8202 - val_loss: 0.5471 - val_accuracy: 0.7965\n",
      "Epoch 14/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.5111 - accuracy: 0.8165 - val_loss: 0.5351 - val_accuracy: 0.7837\n",
      "Epoch 15/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4969 - accuracy: 0.8240 - val_loss: 0.5232 - val_accuracy: 0.7917\n",
      "Epoch 16/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.4837 - accuracy: 0.8240 - val_loss: 0.5110 - val_accuracy: 0.7949\n",
      "Epoch 17/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4690 - accuracy: 0.8240 - val_loss: 0.4999 - val_accuracy: 0.7949\n",
      "Epoch 18/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4562 - accuracy: 0.8165 - val_loss: 0.4894 - val_accuracy: 0.8029\n",
      "Epoch 19/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.4440 - accuracy: 0.8202 - val_loss: 0.4798 - val_accuracy: 0.8029\n",
      "Epoch 20/400\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.4319 - accuracy: 0.8202 - val_loss: 0.4717 - val_accuracy: 0.8013\n",
      "Epoch 21/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4224 - accuracy: 0.8277 - val_loss: 0.4652 - val_accuracy: 0.7997\n",
      "Epoch 22/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.4152 - accuracy: 0.8202 - val_loss: 0.4595 - val_accuracy: 0.8093\n",
      "Epoch 23/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.4053 - accuracy: 0.8277 - val_loss: 0.4563 - val_accuracy: 0.8061\n",
      "Epoch 24/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3999 - accuracy: 0.8315 - val_loss: 0.4543 - val_accuracy: 0.8029\n",
      "Epoch 25/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3952 - accuracy: 0.8390 - val_loss: 0.4537 - val_accuracy: 0.8029\n",
      "Epoch 26/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3939 - accuracy: 0.8352 - val_loss: 0.4546 - val_accuracy: 0.8045\n",
      "Epoch 27/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3910 - accuracy: 0.8352 - val_loss: 0.4529 - val_accuracy: 0.8061\n",
      "Epoch 28/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3862 - accuracy: 0.8352 - val_loss: 0.4506 - val_accuracy: 0.8029\n",
      "Epoch 29/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3858 - accuracy: 0.8352 - val_loss: 0.4500 - val_accuracy: 0.7997\n",
      "Epoch 30/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3831 - accuracy: 0.8352 - val_loss: 0.4482 - val_accuracy: 0.8013\n",
      "Epoch 31/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3788 - accuracy: 0.8390 - val_loss: 0.4475 - val_accuracy: 0.8077\n",
      "Epoch 32/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3766 - accuracy: 0.8502 - val_loss: 0.4473 - val_accuracy: 0.8077\n",
      "Epoch 33/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3739 - accuracy: 0.8464 - val_loss: 0.4464 - val_accuracy: 0.8077\n",
      "Epoch 34/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3721 - accuracy: 0.8427 - val_loss: 0.4450 - val_accuracy: 0.8109\n",
      "Epoch 35/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3694 - accuracy: 0.8502 - val_loss: 0.4439 - val_accuracy: 0.8093\n",
      "Epoch 36/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3677 - accuracy: 0.8502 - val_loss: 0.4435 - val_accuracy: 0.8109\n",
      "Epoch 37/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3658 - accuracy: 0.8502 - val_loss: 0.4434 - val_accuracy: 0.8125\n",
      "Epoch 38/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3639 - accuracy: 0.8539 - val_loss: 0.4436 - val_accuracy: 0.8125\n",
      "Epoch 39/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3618 - accuracy: 0.8577 - val_loss: 0.4440 - val_accuracy: 0.8141\n",
      "Epoch 40/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3604 - accuracy: 0.8577 - val_loss: 0.4439 - val_accuracy: 0.8157\n",
      "Epoch 41/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3591 - accuracy: 0.8577 - val_loss: 0.4442 - val_accuracy: 0.8157\n",
      "Epoch 42/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3581 - accuracy: 0.8539 - val_loss: 0.4440 - val_accuracy: 0.8141\n",
      "Epoch 43/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3565 - accuracy: 0.8577 - val_loss: 0.4442 - val_accuracy: 0.8173\n",
      "Epoch 44/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3541 - accuracy: 0.8652 - val_loss: 0.4432 - val_accuracy: 0.8189\n",
      "Epoch 45/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3535 - accuracy: 0.8614 - val_loss: 0.4428 - val_accuracy: 0.8173\n",
      "Epoch 46/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3510 - accuracy: 0.8614 - val_loss: 0.4428 - val_accuracy: 0.8189\n",
      "Epoch 47/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3498 - accuracy: 0.8614 - val_loss: 0.4430 - val_accuracy: 0.8157\n",
      "Epoch 48/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3496 - accuracy: 0.8689 - val_loss: 0.4437 - val_accuracy: 0.8205\n",
      "Epoch 49/400\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3469 - accuracy: 0.8652 - val_loss: 0.4443 - val_accuracy: 0.8189\n",
      "Epoch 50/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3457 - accuracy: 0.8689 - val_loss: 0.4458 - val_accuracy: 0.8157\n",
      "Epoch 51/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3453 - accuracy: 0.8652 - val_loss: 0.4461 - val_accuracy: 0.8221\n",
      "Epoch 52/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3441 - accuracy: 0.8652 - val_loss: 0.4454 - val_accuracy: 0.8157\n",
      "Epoch 53/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3427 - accuracy: 0.8689 - val_loss: 0.4470 - val_accuracy: 0.8157\n",
      "Epoch 54/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3408 - accuracy: 0.8689 - val_loss: 0.4477 - val_accuracy: 0.8237\n",
      "Epoch 55/400\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.3386 - accuracy: 0.8689 - val_loss: 0.4495 - val_accuracy: 0.8205\n",
      "Epoch 56/400\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3382 - accuracy: 0.8689 - val_loss: 0.4513 - val_accuracy: 0.8205\n",
      "Epoch 57/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3366 - accuracy: 0.8689 - val_loss: 0.4515 - val_accuracy: 0.8205\n",
      "Epoch 58/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3373 - accuracy: 0.8614 - val_loss: 0.4518 - val_accuracy: 0.8189\n",
      "Epoch 59/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3348 - accuracy: 0.8652 - val_loss: 0.4524 - val_accuracy: 0.8205\n",
      "Epoch 60/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3330 - accuracy: 0.8689 - val_loss: 0.4538 - val_accuracy: 0.8221\n",
      "Epoch 61/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3325 - accuracy: 0.8727 - val_loss: 0.4549 - val_accuracy: 0.8189\n",
      "Epoch 62/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3326 - accuracy: 0.8689 - val_loss: 0.4557 - val_accuracy: 0.8189\n",
      "Epoch 63/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3315 - accuracy: 0.8689 - val_loss: 0.4553 - val_accuracy: 0.8189\n",
      "Epoch 64/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3289 - accuracy: 0.8727 - val_loss: 0.4549 - val_accuracy: 0.8157\n",
      "Epoch 65/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3284 - accuracy: 0.8689 - val_loss: 0.4549 - val_accuracy: 0.8205\n",
      "Epoch 66/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3273 - accuracy: 0.8689 - val_loss: 0.4560 - val_accuracy: 0.8205\n",
      "Epoch 67/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3270 - accuracy: 0.8689 - val_loss: 0.4576 - val_accuracy: 0.8205\n",
      "Epoch 68/400\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3262 - accuracy: 0.8689 - val_loss: 0.4574 - val_accuracy: 0.8205\n",
      "Epoch 69/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3251 - accuracy: 0.8689 - val_loss: 0.4589 - val_accuracy: 0.8221\n",
      "Epoch 70/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3240 - accuracy: 0.8689 - val_loss: 0.4594 - val_accuracy: 0.8173\n",
      "Epoch 71/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3226 - accuracy: 0.8727 - val_loss: 0.4618 - val_accuracy: 0.8141\n",
      "Epoch 72/400\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3224 - accuracy: 0.8689 - val_loss: 0.4635 - val_accuracy: 0.8157\n",
      "Epoch 73/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3206 - accuracy: 0.8764 - val_loss: 0.4638 - val_accuracy: 0.8109\n",
      "Epoch 74/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3196 - accuracy: 0.8764 - val_loss: 0.4646 - val_accuracy: 0.8125\n",
      "Epoch 75/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3198 - accuracy: 0.8727 - val_loss: 0.4647 - val_accuracy: 0.8141\n",
      "Epoch 76/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3185 - accuracy: 0.8614 - val_loss: 0.4656 - val_accuracy: 0.8109\n",
      "Epoch 77/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3185 - accuracy: 0.8689 - val_loss: 0.4665 - val_accuracy: 0.8109\n",
      "Epoch 78/400\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3168 - accuracy: 0.8727 - val_loss: 0.4668 - val_accuracy: 0.8109\n",
      "Epoch 79/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3156 - accuracy: 0.8689 - val_loss: 0.4680 - val_accuracy: 0.8061\n",
      "Epoch 80/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.3153 - accuracy: 0.8689 - val_loss: 0.4690 - val_accuracy: 0.8045\n",
      "Epoch 81/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3145 - accuracy: 0.8764 - val_loss: 0.4697 - val_accuracy: 0.8093\n",
      "Epoch 82/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3126 - accuracy: 0.8764 - val_loss: 0.4695 - val_accuracy: 0.8077\n",
      "Epoch 83/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3122 - accuracy: 0.8689 - val_loss: 0.4712 - val_accuracy: 0.8093\n",
      "Epoch 84/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3116 - accuracy: 0.8727 - val_loss: 0.4736 - val_accuracy: 0.8109\n",
      "Epoch 85/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3107 - accuracy: 0.8727 - val_loss: 0.4751 - val_accuracy: 0.8045\n",
      "Epoch 86/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3091 - accuracy: 0.8727 - val_loss: 0.4772 - val_accuracy: 0.8045\n",
      "Epoch 87/400\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.3096 - accuracy: 0.8689 - val_loss: 0.4781 - val_accuracy: 0.8061\n",
      "Epoch 88/400\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.3084 - accuracy: 0.8727 - val_loss: 0.4783 - val_accuracy: 0.8061\n",
      "Epoch 89/400\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.3091 - accuracy: 0.8727 - val_loss: 0.4785 - val_accuracy: 0.8061\n",
      "Epoch 90/400\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.3084 - accuracy: 0.8727 - val_loss: 0.4783 - val_accuracy: 0.8061\n",
      "Epoch 91/400\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3061 - accuracy: 0.8764 - val_loss: 0.4788 - val_accuracy: 0.8061\n",
      "Epoch 92/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3061 - accuracy: 0.8727 - val_loss: 0.4796 - val_accuracy: 0.8061\n",
      "Epoch 93/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3049 - accuracy: 0.8727 - val_loss: 0.4809 - val_accuracy: 0.8077\n",
      "Epoch 94/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3038 - accuracy: 0.8764 - val_loss: 0.4826 - val_accuracy: 0.8077\n",
      "Epoch 95/400\n",
      "3/3 [==============================] - 0s 41ms/step - loss: 0.3029 - accuracy: 0.8727 - val_loss: 0.4837 - val_accuracy: 0.8029\n",
      "Epoch 96/400\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.3021 - accuracy: 0.8689 - val_loss: 0.4860 - val_accuracy: 0.8029\n",
      "Epoch 97/400\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.3032 - accuracy: 0.8764 - val_loss: 0.4885 - val_accuracy: 0.8013\n",
      "Epoch 98/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.3018 - accuracy: 0.8801 - val_loss: 0.4888 - val_accuracy: 0.8045\n",
      "Epoch 99/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3009 - accuracy: 0.8764 - val_loss: 0.4896 - val_accuracy: 0.8045\n",
      "Epoch 100/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.3006 - accuracy: 0.8764 - val_loss: 0.4918 - val_accuracy: 0.8077\n",
      "Epoch 101/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2984 - accuracy: 0.8727 - val_loss: 0.4936 - val_accuracy: 0.8061\n",
      "Epoch 102/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2983 - accuracy: 0.8727 - val_loss: 0.4952 - val_accuracy: 0.8045\n",
      "Epoch 103/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.3007 - accuracy: 0.8727 - val_loss: 0.4983 - val_accuracy: 0.8029\n",
      "Epoch 104/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2968 - accuracy: 0.8801 - val_loss: 0.4994 - val_accuracy: 0.8061\n",
      "Epoch 105/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2969 - accuracy: 0.8764 - val_loss: 0.5020 - val_accuracy: 0.8077\n",
      "Epoch 106/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2965 - accuracy: 0.8764 - val_loss: 0.5020 - val_accuracy: 0.8029\n",
      "Epoch 107/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2942 - accuracy: 0.8764 - val_loss: 0.5031 - val_accuracy: 0.8013\n",
      "Epoch 108/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2966 - accuracy: 0.8801 - val_loss: 0.5046 - val_accuracy: 0.8029\n",
      "Epoch 109/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2942 - accuracy: 0.8839 - val_loss: 0.5040 - val_accuracy: 0.8077\n",
      "Epoch 110/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2941 - accuracy: 0.8689 - val_loss: 0.5051 - val_accuracy: 0.8061\n",
      "Epoch 111/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2941 - accuracy: 0.8764 - val_loss: 0.5069 - val_accuracy: 0.8045\n",
      "Epoch 112/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2921 - accuracy: 0.8839 - val_loss: 0.5082 - val_accuracy: 0.8045\n",
      "Epoch 113/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2916 - accuracy: 0.8876 - val_loss: 0.5102 - val_accuracy: 0.8045\n",
      "Epoch 114/400\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2900 - accuracy: 0.8876 - val_loss: 0.5130 - val_accuracy: 0.8061\n",
      "Epoch 115/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2906 - accuracy: 0.8876 - val_loss: 0.5162 - val_accuracy: 0.8061\n",
      "Epoch 116/400\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2902 - accuracy: 0.8801 - val_loss: 0.5162 - val_accuracy: 0.8061\n",
      "Epoch 117/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2901 - accuracy: 0.8839 - val_loss: 0.5194 - val_accuracy: 0.8013\n",
      "Epoch 118/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2898 - accuracy: 0.8839 - val_loss: 0.5175 - val_accuracy: 0.8013\n",
      "Epoch 119/400\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2884 - accuracy: 0.8839 - val_loss: 0.5202 - val_accuracy: 0.8013\n",
      "Epoch 120/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2894 - accuracy: 0.8839 - val_loss: 0.5188 - val_accuracy: 0.8045\n",
      "Epoch 121/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2888 - accuracy: 0.8801 - val_loss: 0.5219 - val_accuracy: 0.8013\n",
      "Epoch 122/400\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2865 - accuracy: 0.8801 - val_loss: 0.5231 - val_accuracy: 0.7981\n",
      "Epoch 123/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2853 - accuracy: 0.8876 - val_loss: 0.5267 - val_accuracy: 0.8045\n",
      "Epoch 124/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2896 - accuracy: 0.8801 - val_loss: 0.5292 - val_accuracy: 0.8045\n",
      "Epoch 125/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2880 - accuracy: 0.8839 - val_loss: 0.5289 - val_accuracy: 0.8013\n",
      "Epoch 126/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2829 - accuracy: 0.8914 - val_loss: 0.5298 - val_accuracy: 0.8045\n",
      "Epoch 127/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2852 - accuracy: 0.8876 - val_loss: 0.5296 - val_accuracy: 0.8013\n",
      "Epoch 128/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2900 - accuracy: 0.8727 - val_loss: 0.5346 - val_accuracy: 0.7997\n",
      "Epoch 129/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2853 - accuracy: 0.8764 - val_loss: 0.5360 - val_accuracy: 0.8029\n",
      "Epoch 130/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2807 - accuracy: 0.8839 - val_loss: 0.5407 - val_accuracy: 0.8029\n",
      "Epoch 131/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2864 - accuracy: 0.8839 - val_loss: 0.5424 - val_accuracy: 0.8029\n",
      "Epoch 132/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2806 - accuracy: 0.8876 - val_loss: 0.5402 - val_accuracy: 0.7997\n",
      "Epoch 133/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2813 - accuracy: 0.8839 - val_loss: 0.5415 - val_accuracy: 0.7997\n",
      "Epoch 134/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2830 - accuracy: 0.8839 - val_loss: 0.5389 - val_accuracy: 0.7997\n",
      "Epoch 135/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2783 - accuracy: 0.8839 - val_loss: 0.5400 - val_accuracy: 0.7997\n",
      "Epoch 136/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2785 - accuracy: 0.8801 - val_loss: 0.5413 - val_accuracy: 0.8045\n",
      "Epoch 137/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2787 - accuracy: 0.8839 - val_loss: 0.5417 - val_accuracy: 0.8013\n",
      "Epoch 138/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2779 - accuracy: 0.8914 - val_loss: 0.5422 - val_accuracy: 0.7965\n",
      "Epoch 139/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2771 - accuracy: 0.8876 - val_loss: 0.5447 - val_accuracy: 0.7981\n",
      "Epoch 140/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2760 - accuracy: 0.8914 - val_loss: 0.5481 - val_accuracy: 0.7981\n",
      "Epoch 141/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2751 - accuracy: 0.8839 - val_loss: 0.5509 - val_accuracy: 0.7949\n",
      "Epoch 142/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2743 - accuracy: 0.8914 - val_loss: 0.5547 - val_accuracy: 0.7949\n",
      "Epoch 143/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2750 - accuracy: 0.8839 - val_loss: 0.5555 - val_accuracy: 0.7933\n",
      "Epoch 144/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2734 - accuracy: 0.8876 - val_loss: 0.5567 - val_accuracy: 0.7933\n",
      "Epoch 145/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2738 - accuracy: 0.8914 - val_loss: 0.5575 - val_accuracy: 0.7965\n",
      "Epoch 146/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2737 - accuracy: 0.8876 - val_loss: 0.5598 - val_accuracy: 0.7965\n",
      "Epoch 147/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2723 - accuracy: 0.8876 - val_loss: 0.5622 - val_accuracy: 0.7965\n",
      "Epoch 148/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2707 - accuracy: 0.8914 - val_loss: 0.5627 - val_accuracy: 0.7965\n",
      "Epoch 149/400\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2714 - accuracy: 0.8876 - val_loss: 0.5633 - val_accuracy: 0.7933\n",
      "Epoch 150/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2712 - accuracy: 0.8839 - val_loss: 0.5658 - val_accuracy: 0.7965\n",
      "Epoch 151/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2704 - accuracy: 0.8839 - val_loss: 0.5667 - val_accuracy: 0.7917\n",
      "Epoch 152/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2729 - accuracy: 0.8876 - val_loss: 0.5694 - val_accuracy: 0.7965\n",
      "Epoch 153/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2691 - accuracy: 0.8914 - val_loss: 0.5693 - val_accuracy: 0.7981\n",
      "Epoch 154/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2697 - accuracy: 0.8914 - val_loss: 0.5726 - val_accuracy: 0.7949\n",
      "Epoch 155/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2736 - accuracy: 0.8876 - val_loss: 0.5719 - val_accuracy: 0.7981\n",
      "Epoch 156/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2714 - accuracy: 0.8914 - val_loss: 0.5732 - val_accuracy: 0.7997\n",
      "Epoch 157/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2697 - accuracy: 0.8876 - val_loss: 0.5758 - val_accuracy: 0.8013\n",
      "Epoch 158/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2701 - accuracy: 0.8839 - val_loss: 0.5762 - val_accuracy: 0.7981\n",
      "Epoch 159/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2702 - accuracy: 0.8876 - val_loss: 0.5769 - val_accuracy: 0.7933\n",
      "Epoch 160/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2702 - accuracy: 0.8914 - val_loss: 0.5772 - val_accuracy: 0.7917\n",
      "Epoch 161/400\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.2654 - accuracy: 0.8914 - val_loss: 0.5798 - val_accuracy: 0.7933\n",
      "Epoch 162/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2693 - accuracy: 0.8839 - val_loss: 0.5829 - val_accuracy: 0.7949\n",
      "Epoch 163/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2708 - accuracy: 0.8839 - val_loss: 0.5853 - val_accuracy: 0.7965\n",
      "Epoch 164/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2668 - accuracy: 0.8914 - val_loss: 0.5866 - val_accuracy: 0.7981\n",
      "Epoch 165/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2680 - accuracy: 0.8914 - val_loss: 0.5863 - val_accuracy: 0.7997\n",
      "Epoch 166/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2658 - accuracy: 0.8839 - val_loss: 0.5877 - val_accuracy: 0.7949\n",
      "Epoch 167/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2639 - accuracy: 0.8914 - val_loss: 0.5873 - val_accuracy: 0.7949\n",
      "Epoch 168/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2649 - accuracy: 0.8876 - val_loss: 0.5897 - val_accuracy: 0.7965\n",
      "Epoch 169/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2634 - accuracy: 0.8839 - val_loss: 0.5927 - val_accuracy: 0.7933\n",
      "Epoch 170/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2619 - accuracy: 0.8914 - val_loss: 0.5949 - val_accuracy: 0.7917\n",
      "Epoch 171/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2627 - accuracy: 0.8876 - val_loss: 0.5951 - val_accuracy: 0.7965\n",
      "Epoch 172/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2615 - accuracy: 0.8914 - val_loss: 0.5977 - val_accuracy: 0.7981\n",
      "Epoch 173/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2614 - accuracy: 0.8876 - val_loss: 0.6000 - val_accuracy: 0.7981\n",
      "Epoch 174/400\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2619 - accuracy: 0.8876 - val_loss: 0.6015 - val_accuracy: 0.7965\n",
      "Epoch 175/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2603 - accuracy: 0.8914 - val_loss: 0.6028 - val_accuracy: 0.7981\n",
      "Epoch 176/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2606 - accuracy: 0.8914 - val_loss: 0.6033 - val_accuracy: 0.7965\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 177/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2592 - accuracy: 0.8914 - val_loss: 0.6062 - val_accuracy: 0.7949\n",
      "Epoch 178/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2584 - accuracy: 0.8876 - val_loss: 0.6069 - val_accuracy: 0.7949\n",
      "Epoch 179/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2619 - accuracy: 0.8914 - val_loss: 0.6090 - val_accuracy: 0.7933\n",
      "Epoch 180/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2594 - accuracy: 0.8951 - val_loss: 0.6099 - val_accuracy: 0.7949\n",
      "Epoch 181/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2582 - accuracy: 0.8839 - val_loss: 0.6134 - val_accuracy: 0.7933\n",
      "Epoch 182/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2596 - accuracy: 0.8876 - val_loss: 0.6143 - val_accuracy: 0.7933\n",
      "Epoch 183/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2573 - accuracy: 0.8876 - val_loss: 0.6164 - val_accuracy: 0.7917\n",
      "Epoch 184/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2572 - accuracy: 0.8989 - val_loss: 0.6168 - val_accuracy: 0.7933\n",
      "Epoch 185/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2562 - accuracy: 0.9026 - val_loss: 0.6183 - val_accuracy: 0.7949\n",
      "Epoch 186/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2563 - accuracy: 0.9026 - val_loss: 0.6210 - val_accuracy: 0.7933\n",
      "Epoch 187/400\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2572 - accuracy: 0.8951 - val_loss: 0.6223 - val_accuracy: 0.7933\n",
      "Epoch 188/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2592 - accuracy: 0.8914 - val_loss: 0.6263 - val_accuracy: 0.7917\n",
      "Epoch 189/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2568 - accuracy: 0.8951 - val_loss: 0.6275 - val_accuracy: 0.7933\n",
      "Epoch 190/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2557 - accuracy: 0.8914 - val_loss: 0.6262 - val_accuracy: 0.7933\n",
      "Epoch 191/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2543 - accuracy: 0.8951 - val_loss: 0.6278 - val_accuracy: 0.7933\n",
      "Epoch 192/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2536 - accuracy: 0.8951 - val_loss: 0.6307 - val_accuracy: 0.7933\n",
      "Epoch 193/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2530 - accuracy: 0.8951 - val_loss: 0.6337 - val_accuracy: 0.7901\n",
      "Epoch 194/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2525 - accuracy: 0.9026 - val_loss: 0.6377 - val_accuracy: 0.7901\n",
      "Epoch 195/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2520 - accuracy: 0.8989 - val_loss: 0.6404 - val_accuracy: 0.7901\n",
      "Epoch 196/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2513 - accuracy: 0.8951 - val_loss: 0.6425 - val_accuracy: 0.7949\n",
      "Epoch 197/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2512 - accuracy: 0.8951 - val_loss: 0.6472 - val_accuracy: 0.7965\n",
      "Epoch 198/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2526 - accuracy: 0.8951 - val_loss: 0.6498 - val_accuracy: 0.7949\n",
      "Epoch 199/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2512 - accuracy: 0.8989 - val_loss: 0.6514 - val_accuracy: 0.7949\n",
      "Epoch 200/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2518 - accuracy: 0.8989 - val_loss: 0.6496 - val_accuracy: 0.7933\n",
      "Epoch 201/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2513 - accuracy: 0.9064 - val_loss: 0.6509 - val_accuracy: 0.7933\n",
      "Epoch 202/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2515 - accuracy: 0.8989 - val_loss: 0.6549 - val_accuracy: 0.7917\n",
      "Epoch 203/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2501 - accuracy: 0.8989 - val_loss: 0.6555 - val_accuracy: 0.7917\n",
      "Epoch 204/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2489 - accuracy: 0.8989 - val_loss: 0.6568 - val_accuracy: 0.7917\n",
      "Epoch 205/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2478 - accuracy: 0.8914 - val_loss: 0.6580 - val_accuracy: 0.7917\n",
      "Epoch 206/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2501 - accuracy: 0.8951 - val_loss: 0.6603 - val_accuracy: 0.7917\n",
      "Epoch 207/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2493 - accuracy: 0.8989 - val_loss: 0.6598 - val_accuracy: 0.7933\n",
      "Epoch 208/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2497 - accuracy: 0.8989 - val_loss: 0.6610 - val_accuracy: 0.7917\n",
      "Epoch 209/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2480 - accuracy: 0.8951 - val_loss: 0.6641 - val_accuracy: 0.7933\n",
      "Epoch 210/400\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.2504 - accuracy: 0.8914 - val_loss: 0.6660 - val_accuracy: 0.7933\n",
      "Epoch 211/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2458 - accuracy: 0.8989 - val_loss: 0.6682 - val_accuracy: 0.7917\n",
      "Epoch 212/400\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.2471 - accuracy: 0.8989 - val_loss: 0.6711 - val_accuracy: 0.7917\n",
      "Epoch 213/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2448 - accuracy: 0.9026 - val_loss: 0.6742 - val_accuracy: 0.7917\n",
      "Epoch 214/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2464 - accuracy: 0.9026 - val_loss: 0.6770 - val_accuracy: 0.7917\n",
      "Epoch 215/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2448 - accuracy: 0.8989 - val_loss: 0.6803 - val_accuracy: 0.7901\n",
      "Epoch 216/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2442 - accuracy: 0.9026 - val_loss: 0.6814 - val_accuracy: 0.7901\n",
      "Epoch 217/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2461 - accuracy: 0.9026 - val_loss: 0.6823 - val_accuracy: 0.7917\n",
      "Epoch 218/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2468 - accuracy: 0.8951 - val_loss: 0.6845 - val_accuracy: 0.7965\n",
      "Epoch 219/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2424 - accuracy: 0.9026 - val_loss: 0.6860 - val_accuracy: 0.7885\n",
      "Epoch 220/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2549 - accuracy: 0.8764 - val_loss: 0.6888 - val_accuracy: 0.7869\n",
      "Epoch 221/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2484 - accuracy: 0.8989 - val_loss: 0.6887 - val_accuracy: 0.7933\n",
      "Epoch 222/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2460 - accuracy: 0.8951 - val_loss: 0.6859 - val_accuracy: 0.7949\n",
      "Epoch 223/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2473 - accuracy: 0.8951 - val_loss: 0.6924 - val_accuracy: 0.7901\n",
      "Epoch 224/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2449 - accuracy: 0.9026 - val_loss: 0.6884 - val_accuracy: 0.7885\n",
      "Epoch 225/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2419 - accuracy: 0.9026 - val_loss: 0.6935 - val_accuracy: 0.7949\n",
      "Epoch 226/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2450 - accuracy: 0.8989 - val_loss: 0.6913 - val_accuracy: 0.7901\n",
      "Epoch 227/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2396 - accuracy: 0.9064 - val_loss: 0.6950 - val_accuracy: 0.7869\n",
      "Epoch 228/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2476 - accuracy: 0.9026 - val_loss: 0.6978 - val_accuracy: 0.7901\n",
      "Epoch 229/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2436 - accuracy: 0.9026 - val_loss: 0.6989 - val_accuracy: 0.7917\n",
      "Epoch 230/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2411 - accuracy: 0.9064 - val_loss: 0.6989 - val_accuracy: 0.7901\n",
      "Epoch 231/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2393 - accuracy: 0.9064 - val_loss: 0.7002 - val_accuracy: 0.7917\n",
      "Epoch 232/400\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.2422 - accuracy: 0.9101 - val_loss: 0.7022 - val_accuracy: 0.7885\n",
      "Epoch 233/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2392 - accuracy: 0.9101 - val_loss: 0.7068 - val_accuracy: 0.7885\n",
      "Epoch 234/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2419 - accuracy: 0.9064 - val_loss: 0.7091 - val_accuracy: 0.7853\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 235/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2401 - accuracy: 0.8989 - val_loss: 0.7111 - val_accuracy: 0.7901\n",
      "Epoch 236/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2409 - accuracy: 0.8989 - val_loss: 0.7120 - val_accuracy: 0.7933\n",
      "Epoch 237/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2390 - accuracy: 0.8989 - val_loss: 0.7162 - val_accuracy: 0.7869\n",
      "Epoch 238/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2390 - accuracy: 0.9026 - val_loss: 0.7178 - val_accuracy: 0.7885\n",
      "Epoch 239/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2366 - accuracy: 0.9026 - val_loss: 0.7200 - val_accuracy: 0.7885\n",
      "Epoch 240/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2362 - accuracy: 0.9064 - val_loss: 0.7220 - val_accuracy: 0.7885\n",
      "Epoch 241/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2402 - accuracy: 0.9026 - val_loss: 0.7238 - val_accuracy: 0.7949\n",
      "Epoch 242/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2392 - accuracy: 0.9026 - val_loss: 0.7278 - val_accuracy: 0.7837\n",
      "Epoch 243/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2354 - accuracy: 0.9026 - val_loss: 0.7301 - val_accuracy: 0.7869\n",
      "Epoch 244/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2417 - accuracy: 0.9064 - val_loss: 0.7314 - val_accuracy: 0.7869\n",
      "Epoch 245/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2411 - accuracy: 0.9064 - val_loss: 0.7355 - val_accuracy: 0.7869\n",
      "Epoch 246/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2390 - accuracy: 0.9026 - val_loss: 0.7297 - val_accuracy: 0.7885\n",
      "Epoch 247/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2358 - accuracy: 0.9101 - val_loss: 0.7355 - val_accuracy: 0.7933\n",
      "Epoch 248/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2370 - accuracy: 0.9026 - val_loss: 0.7355 - val_accuracy: 0.7885\n",
      "Epoch 249/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2397 - accuracy: 0.9101 - val_loss: 0.7362 - val_accuracy: 0.7885\n",
      "Epoch 250/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2360 - accuracy: 0.9064 - val_loss: 0.7380 - val_accuracy: 0.7869\n",
      "Epoch 251/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2363 - accuracy: 0.8989 - val_loss: 0.7420 - val_accuracy: 0.7853\n",
      "Epoch 252/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2354 - accuracy: 0.9101 - val_loss: 0.7469 - val_accuracy: 0.7837\n",
      "Epoch 253/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2380 - accuracy: 0.9026 - val_loss: 0.7424 - val_accuracy: 0.7869\n",
      "Epoch 254/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2343 - accuracy: 0.9064 - val_loss: 0.7441 - val_accuracy: 0.7885\n",
      "Epoch 255/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2330 - accuracy: 0.9101 - val_loss: 0.7495 - val_accuracy: 0.7821\n",
      "Epoch 256/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2337 - accuracy: 0.9026 - val_loss: 0.7494 - val_accuracy: 0.7869\n",
      "Epoch 257/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2311 - accuracy: 0.9101 - val_loss: 0.7530 - val_accuracy: 0.7885\n",
      "Epoch 258/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2340 - accuracy: 0.9101 - val_loss: 0.7564 - val_accuracy: 0.7885\n",
      "Epoch 259/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2348 - accuracy: 0.9064 - val_loss: 0.7601 - val_accuracy: 0.7869\n",
      "Epoch 260/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2320 - accuracy: 0.8951 - val_loss: 0.7629 - val_accuracy: 0.7853\n",
      "Epoch 261/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2309 - accuracy: 0.9064 - val_loss: 0.7638 - val_accuracy: 0.7837\n",
      "Epoch 262/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2323 - accuracy: 0.9064 - val_loss: 0.7703 - val_accuracy: 0.7804\n",
      "Epoch 263/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2347 - accuracy: 0.9026 - val_loss: 0.7649 - val_accuracy: 0.7885\n",
      "Epoch 264/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2341 - accuracy: 0.9026 - val_loss: 0.7668 - val_accuracy: 0.7869\n",
      "Epoch 265/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2307 - accuracy: 0.9064 - val_loss: 0.7669 - val_accuracy: 0.7869\n",
      "Epoch 266/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2329 - accuracy: 0.9064 - val_loss: 0.7662 - val_accuracy: 0.7917\n",
      "Epoch 267/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2343 - accuracy: 0.8989 - val_loss: 0.7714 - val_accuracy: 0.7837\n",
      "Epoch 268/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2318 - accuracy: 0.8989 - val_loss: 0.7711 - val_accuracy: 0.7837\n",
      "Epoch 269/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2297 - accuracy: 0.9064 - val_loss: 0.7768 - val_accuracy: 0.7821\n",
      "Epoch 270/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2311 - accuracy: 0.9064 - val_loss: 0.7771 - val_accuracy: 0.7853\n",
      "Epoch 271/400\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.2276 - accuracy: 0.9101 - val_loss: 0.7812 - val_accuracy: 0.7837\n",
      "Epoch 272/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2308 - accuracy: 0.9064 - val_loss: 0.7846 - val_accuracy: 0.7837\n",
      "Epoch 273/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2261 - accuracy: 0.9139 - val_loss: 0.7847 - val_accuracy: 0.7901\n",
      "Epoch 274/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2304 - accuracy: 0.9026 - val_loss: 0.7863 - val_accuracy: 0.7869\n",
      "Epoch 275/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2267 - accuracy: 0.9101 - val_loss: 0.7913 - val_accuracy: 0.7837\n",
      "Epoch 276/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2262 - accuracy: 0.9101 - val_loss: 0.7898 - val_accuracy: 0.7869\n",
      "Epoch 277/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2320 - accuracy: 0.9026 - val_loss: 0.7940 - val_accuracy: 0.7837\n",
      "Epoch 278/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2248 - accuracy: 0.9101 - val_loss: 0.7945 - val_accuracy: 0.7804\n",
      "Epoch 279/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2277 - accuracy: 0.9101 - val_loss: 0.7957 - val_accuracy: 0.7853\n",
      "Epoch 280/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2294 - accuracy: 0.9139 - val_loss: 0.7989 - val_accuracy: 0.7853\n",
      "Epoch 281/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2250 - accuracy: 0.9101 - val_loss: 0.8084 - val_accuracy: 0.7788\n",
      "Epoch 282/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2277 - accuracy: 0.9064 - val_loss: 0.8052 - val_accuracy: 0.7837\n",
      "Epoch 283/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2240 - accuracy: 0.9026 - val_loss: 0.8064 - val_accuracy: 0.7853\n",
      "Epoch 284/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2275 - accuracy: 0.9026 - val_loss: 0.8069 - val_accuracy: 0.7869\n",
      "Epoch 285/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2270 - accuracy: 0.9101 - val_loss: 0.8162 - val_accuracy: 0.7788\n",
      "Epoch 286/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2267 - accuracy: 0.9064 - val_loss: 0.8110 - val_accuracy: 0.7853\n",
      "Epoch 287/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2331 - accuracy: 0.8989 - val_loss: 0.8152 - val_accuracy: 0.7804\n",
      "Epoch 288/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2298 - accuracy: 0.9026 - val_loss: 0.8193 - val_accuracy: 0.7837\n",
      "Epoch 289/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2258 - accuracy: 0.9064 - val_loss: 0.8220 - val_accuracy: 0.7853\n",
      "Epoch 290/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2251 - accuracy: 0.9064 - val_loss: 0.8233 - val_accuracy: 0.7837\n",
      "Epoch 291/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2216 - accuracy: 0.9064 - val_loss: 0.8261 - val_accuracy: 0.7837\n",
      "Epoch 292/400\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.2262 - accuracy: 0.9101 - val_loss: 0.8330 - val_accuracy: 0.7788\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 293/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2223 - accuracy: 0.9101 - val_loss: 0.8290 - val_accuracy: 0.7837\n",
      "Epoch 294/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2244 - accuracy: 0.8951 - val_loss: 0.8302 - val_accuracy: 0.7837\n",
      "Epoch 295/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2238 - accuracy: 0.8951 - val_loss: 0.8287 - val_accuracy: 0.7837\n",
      "Epoch 296/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2229 - accuracy: 0.9064 - val_loss: 0.8300 - val_accuracy: 0.7821\n",
      "Epoch 297/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2211 - accuracy: 0.9026 - val_loss: 0.8324 - val_accuracy: 0.7837\n",
      "Epoch 298/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2228 - accuracy: 0.9176 - val_loss: 0.8382 - val_accuracy: 0.7821\n",
      "Epoch 299/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2250 - accuracy: 0.9026 - val_loss: 0.8524 - val_accuracy: 0.7756\n",
      "Epoch 300/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2216 - accuracy: 0.9064 - val_loss: 0.8469 - val_accuracy: 0.7821\n",
      "Epoch 301/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2191 - accuracy: 0.9101 - val_loss: 0.8406 - val_accuracy: 0.7772\n",
      "Epoch 302/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2220 - accuracy: 0.9026 - val_loss: 0.8410 - val_accuracy: 0.7821\n",
      "Epoch 303/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2184 - accuracy: 0.9026 - val_loss: 0.8451 - val_accuracy: 0.7869\n",
      "Epoch 304/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2212 - accuracy: 0.9101 - val_loss: 0.8453 - val_accuracy: 0.7853\n",
      "Epoch 305/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2203 - accuracy: 0.9101 - val_loss: 0.8469 - val_accuracy: 0.7788\n",
      "Epoch 306/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2173 - accuracy: 0.9101 - val_loss: 0.8498 - val_accuracy: 0.7853\n",
      "Epoch 307/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2183 - accuracy: 0.9101 - val_loss: 0.8555 - val_accuracy: 0.7837\n",
      "Epoch 308/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2198 - accuracy: 0.8989 - val_loss: 0.8562 - val_accuracy: 0.7853\n",
      "Epoch 309/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2168 - accuracy: 0.9026 - val_loss: 0.8611 - val_accuracy: 0.7853\n",
      "Epoch 310/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2211 - accuracy: 0.8989 - val_loss: 0.8635 - val_accuracy: 0.7853\n",
      "Epoch 311/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2196 - accuracy: 0.9064 - val_loss: 0.8730 - val_accuracy: 0.7740\n",
      "Epoch 312/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2203 - accuracy: 0.9139 - val_loss: 0.8695 - val_accuracy: 0.7837\n",
      "Epoch 313/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2207 - accuracy: 0.9101 - val_loss: 0.8711 - val_accuracy: 0.7804\n",
      "Epoch 314/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2176 - accuracy: 0.9101 - val_loss: 0.8839 - val_accuracy: 0.7772\n",
      "Epoch 315/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2188 - accuracy: 0.9101 - val_loss: 0.8792 - val_accuracy: 0.7788\n",
      "Epoch 316/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2142 - accuracy: 0.9139 - val_loss: 0.8831 - val_accuracy: 0.7724\n",
      "Epoch 317/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2195 - accuracy: 0.9101 - val_loss: 0.8822 - val_accuracy: 0.7804\n",
      "Epoch 318/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2185 - accuracy: 0.9101 - val_loss: 0.8929 - val_accuracy: 0.7788\n",
      "Epoch 319/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2195 - accuracy: 0.9101 - val_loss: 0.8882 - val_accuracy: 0.7788\n",
      "Epoch 320/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2158 - accuracy: 0.9101 - val_loss: 0.8864 - val_accuracy: 0.7772\n",
      "Epoch 321/400\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.2178 - accuracy: 0.9026 - val_loss: 0.8889 - val_accuracy: 0.7772\n",
      "Epoch 322/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2134 - accuracy: 0.9139 - val_loss: 0.8918 - val_accuracy: 0.7788\n",
      "Epoch 323/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2124 - accuracy: 0.9139 - val_loss: 0.8932 - val_accuracy: 0.7837\n",
      "Epoch 324/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2103 - accuracy: 0.9101 - val_loss: 0.8971 - val_accuracy: 0.7804\n",
      "Epoch 325/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2133 - accuracy: 0.9139 - val_loss: 0.9016 - val_accuracy: 0.7821\n",
      "Epoch 326/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2132 - accuracy: 0.9101 - val_loss: 0.8982 - val_accuracy: 0.7821\n",
      "Epoch 327/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2103 - accuracy: 0.9101 - val_loss: 0.9009 - val_accuracy: 0.7837\n",
      "Epoch 328/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2107 - accuracy: 0.9101 - val_loss: 0.9095 - val_accuracy: 0.7804\n",
      "Epoch 329/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2146 - accuracy: 0.9064 - val_loss: 0.9101 - val_accuracy: 0.7837\n",
      "Epoch 330/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2091 - accuracy: 0.9101 - val_loss: 0.9118 - val_accuracy: 0.7772\n",
      "Epoch 331/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2105 - accuracy: 0.9064 - val_loss: 0.9152 - val_accuracy: 0.7788\n",
      "Epoch 332/400\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.2095 - accuracy: 0.9026 - val_loss: 0.9206 - val_accuracy: 0.7788\n",
      "Epoch 333/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2089 - accuracy: 0.8989 - val_loss: 0.9252 - val_accuracy: 0.7804\n",
      "Epoch 334/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2099 - accuracy: 0.9064 - val_loss: 0.9297 - val_accuracy: 0.7756\n",
      "Epoch 335/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2124 - accuracy: 0.9101 - val_loss: 0.9283 - val_accuracy: 0.7756\n",
      "Epoch 336/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2117 - accuracy: 0.9026 - val_loss: 0.9257 - val_accuracy: 0.7804\n",
      "Epoch 337/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2105 - accuracy: 0.9064 - val_loss: 0.9265 - val_accuracy: 0.7853\n",
      "Epoch 338/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2072 - accuracy: 0.9064 - val_loss: 0.9311 - val_accuracy: 0.7772\n",
      "Epoch 339/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2085 - accuracy: 0.9064 - val_loss: 0.9321 - val_accuracy: 0.7788\n",
      "Epoch 340/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2058 - accuracy: 0.9064 - val_loss: 0.9347 - val_accuracy: 0.7804\n",
      "Epoch 341/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2076 - accuracy: 0.9101 - val_loss: 0.9411 - val_accuracy: 0.7804\n",
      "Epoch 342/400\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.2060 - accuracy: 0.9139 - val_loss: 0.9485 - val_accuracy: 0.7788\n",
      "Epoch 343/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2077 - accuracy: 0.9139 - val_loss: 0.9568 - val_accuracy: 0.7676\n",
      "Epoch 344/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2046 - accuracy: 0.9139 - val_loss: 0.9574 - val_accuracy: 0.7772\n",
      "Epoch 345/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2085 - accuracy: 0.9101 - val_loss: 0.9517 - val_accuracy: 0.7772\n",
      "Epoch 346/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2086 - accuracy: 0.9064 - val_loss: 0.9477 - val_accuracy: 0.7821\n",
      "Epoch 347/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2067 - accuracy: 0.9139 - val_loss: 0.9505 - val_accuracy: 0.7821\n",
      "Epoch 348/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2057 - accuracy: 0.9139 - val_loss: 0.9517 - val_accuracy: 0.7740\n",
      "Epoch 349/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2061 - accuracy: 0.9139 - val_loss: 0.9526 - val_accuracy: 0.7821\n",
      "Epoch 350/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2053 - accuracy: 0.9139 - val_loss: 0.9582 - val_accuracy: 0.7772\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 351/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2048 - accuracy: 0.9139 - val_loss: 0.9646 - val_accuracy: 0.7772\n",
      "Epoch 352/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2076 - accuracy: 0.9026 - val_loss: 0.9701 - val_accuracy: 0.7740\n",
      "Epoch 353/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2063 - accuracy: 0.9064 - val_loss: 0.9778 - val_accuracy: 0.7724\n",
      "Epoch 354/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2060 - accuracy: 0.9064 - val_loss: 0.9780 - val_accuracy: 0.7756\n",
      "Epoch 355/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2042 - accuracy: 0.9176 - val_loss: 0.9854 - val_accuracy: 0.7708\n",
      "Epoch 356/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2033 - accuracy: 0.9176 - val_loss: 0.9836 - val_accuracy: 0.7821\n",
      "Epoch 357/400\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.2024 - accuracy: 0.9139 - val_loss: 0.9914 - val_accuracy: 0.7756\n",
      "Epoch 358/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2015 - accuracy: 0.9026 - val_loss: 0.9974 - val_accuracy: 0.7692\n",
      "Epoch 359/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2055 - accuracy: 0.9064 - val_loss: 1.0054 - val_accuracy: 0.7644\n",
      "Epoch 360/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2012 - accuracy: 0.9101 - val_loss: 1.0024 - val_accuracy: 0.7724\n",
      "Epoch 361/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2042 - accuracy: 0.9139 - val_loss: 1.0037 - val_accuracy: 0.7676\n",
      "Epoch 362/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2013 - accuracy: 0.9101 - val_loss: 1.0083 - val_accuracy: 0.7692\n",
      "Epoch 363/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2019 - accuracy: 0.9101 - val_loss: 1.0080 - val_accuracy: 0.7724\n",
      "Epoch 364/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2022 - accuracy: 0.9176 - val_loss: 1.0070 - val_accuracy: 0.7756\n",
      "Epoch 365/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2007 - accuracy: 0.9213 - val_loss: 1.0003 - val_accuracy: 0.7788\n",
      "Epoch 366/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2048 - accuracy: 0.9101 - val_loss: 0.9992 - val_accuracy: 0.7772\n",
      "Epoch 367/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2046 - accuracy: 0.9101 - val_loss: 1.0057 - val_accuracy: 0.7740\n",
      "Epoch 368/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.2033 - accuracy: 0.9101 - val_loss: 1.0070 - val_accuracy: 0.7756\n",
      "Epoch 369/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1978 - accuracy: 0.9176 - val_loss: 1.0046 - val_accuracy: 0.7788\n",
      "Epoch 370/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2033 - accuracy: 0.9176 - val_loss: 1.0083 - val_accuracy: 0.7837\n",
      "Epoch 371/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1990 - accuracy: 0.9213 - val_loss: 1.0156 - val_accuracy: 0.7740\n",
      "Epoch 372/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.2005 - accuracy: 0.9176 - val_loss: 1.0231 - val_accuracy: 0.7756\n",
      "Epoch 373/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1997 - accuracy: 0.9139 - val_loss: 1.0260 - val_accuracy: 0.7740\n",
      "Epoch 374/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1997 - accuracy: 0.9064 - val_loss: 1.0289 - val_accuracy: 0.7724\n",
      "Epoch 375/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1998 - accuracy: 0.9064 - val_loss: 1.0336 - val_accuracy: 0.7740\n",
      "Epoch 376/400\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 0.1976 - accuracy: 0.9213 - val_loss: 1.0431 - val_accuracy: 0.7724\n",
      "Epoch 377/400\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.1983 - accuracy: 0.9213 - val_loss: 1.0444 - val_accuracy: 0.7756\n",
      "Epoch 378/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.1977 - accuracy: 0.9176 - val_loss: 1.0422 - val_accuracy: 0.7821\n",
      "Epoch 379/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1972 - accuracy: 0.9101 - val_loss: 1.0466 - val_accuracy: 0.7756\n",
      "Epoch 380/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1978 - accuracy: 0.9251 - val_loss: 1.0510 - val_accuracy: 0.7772\n",
      "Epoch 381/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1958 - accuracy: 0.9213 - val_loss: 1.0551 - val_accuracy: 0.7692\n",
      "Epoch 382/400\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.1978 - accuracy: 0.9101 - val_loss: 1.0594 - val_accuracy: 0.7692\n",
      "Epoch 383/400\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1998 - accuracy: 0.9176 - val_loss: 1.0675 - val_accuracy: 0.7708\n",
      "Epoch 384/400\n",
      "3/3 [==============================] - 0s 44ms/step - loss: 0.1988 - accuracy: 0.9213 - val_loss: 1.0655 - val_accuracy: 0.7724\n",
      "Epoch 385/400\n",
      "3/3 [==============================] - 0s 47ms/step - loss: 0.1960 - accuracy: 0.9213 - val_loss: 1.0644 - val_accuracy: 0.7724\n",
      "Epoch 386/400\n",
      "3/3 [==============================] - 0s 46ms/step - loss: 0.1966 - accuracy: 0.9139 - val_loss: 1.0615 - val_accuracy: 0.7756\n",
      "Epoch 387/400\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1940 - accuracy: 0.9139 - val_loss: 1.0664 - val_accuracy: 0.7740\n",
      "Epoch 388/400\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1943 - accuracy: 0.9213 - val_loss: 1.0712 - val_accuracy: 0.7756\n",
      "Epoch 389/400\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.1948 - accuracy: 0.9251 - val_loss: 1.0722 - val_accuracy: 0.7708\n",
      "Epoch 390/400\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.1939 - accuracy: 0.9176 - val_loss: 1.0794 - val_accuracy: 0.7740\n",
      "Epoch 391/400\n",
      "3/3 [==============================] - 0s 50ms/step - loss: 0.1979 - accuracy: 0.9251 - val_loss: 1.0865 - val_accuracy: 0.7724\n",
      "Epoch 392/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1914 - accuracy: 0.9251 - val_loss: 1.0876 - val_accuracy: 0.7756\n",
      "Epoch 393/400\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.1999 - accuracy: 0.9139 - val_loss: 1.0868 - val_accuracy: 0.7692\n",
      "Epoch 394/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.2011 - accuracy: 0.9026 - val_loss: 1.0927 - val_accuracy: 0.7708\n",
      "Epoch 395/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1994 - accuracy: 0.9213 - val_loss: 1.0916 - val_accuracy: 0.7756\n",
      "Epoch 396/400\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.2051 - accuracy: 0.9064 - val_loss: 1.0865 - val_accuracy: 0.7676\n",
      "Epoch 397/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1962 - accuracy: 0.9176 - val_loss: 1.0955 - val_accuracy: 0.7772\n",
      "Epoch 398/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1977 - accuracy: 0.9251 - val_loss: 1.0902 - val_accuracy: 0.7740\n",
      "Epoch 399/400\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.1992 - accuracy: 0.9213 - val_loss: 1.0880 - val_accuracy: 0.7772\n",
      "Epoch 400/400\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.1987 - accuracy: 0.9288 - val_loss: 1.0924 - val_accuracy: 0.7660\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.89      0.83       386\n",
      "           1       0.76      0.56      0.65       238\n",
      "\n",
      "    accuracy                           0.77       624\n",
      "   macro avg       0.77      0.73      0.74       624\n",
      "weighted avg       0.77      0.77      0.76       624\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 15:21:42.874016: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=400, batch_size=100, validation_data=(X_test, y_test))\n",
    "pred = model.predict(X_test)\n",
    "pred = pd.DataFrame(pred)\n",
    "pred = pred[0].apply(lambda x: 1 if x >0.5 else 0)\n",
    "print(classification_report(y_test, pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d032af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdcd66b2",
   "metadata": {},
   "source": [
    "# Model Subclassing API로 모델 만들기\n",
    "* class 형태의 모델 정의 방법\n",
    "* tf.keras.Model을 상속 받아 작성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8a561aab",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Titanic(tf.keras.Model):\n",
    "    def __init__(self):\n",
    "        super(Titanic, self).__init__()\n",
    "        self.dense1= tf.keras.layers.Dense(32, activation='relu')\n",
    "        self.dense2 = tf.keras.layers.Dense(64, activation='relu')\n",
    "        self.dense3 = tf.keras.layers.Dense(16, activation='relu')\n",
    "        self.classifier = tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "        \n",
    "        \n",
    "    def call(self, inputs):\n",
    "        x= self.dense1(inputs)\n",
    "        x= self.dense2(x)\n",
    "        x= self.dense3(x)\n",
    "        return self.classifier(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4c7a9a64",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Titanic()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6913df42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 15:47:41.152939: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-09 15:47:41.213639: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-09 15:47:41.213701: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 759ms/step - loss: 0.7168 - accuracy: 0.5393 - val_loss: 0.7074 - val_accuracy: 0.5609\n",
      "Epoch 2/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.7009 - accuracy: 0.5955 - val_loss: 0.6943 - val_accuracy: 0.6250\n",
      "Epoch 3/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6867 - accuracy: 0.6442 - val_loss: 0.6828 - val_accuracy: 0.6699\n",
      "Epoch 4/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.6738 - accuracy: 0.6891 - val_loss: 0.6727 - val_accuracy: 0.7067\n",
      "Epoch 5/200\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 15:47:41.561924: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n",
      "2024-09-09 15:47:41.587046: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:306] Could not identify NUMA node of platform GPU ID 0, defaulting to 0. Your kernel may not have been built with NUMA support.\n",
      "2024-09-09 15:47:41.587120: I tensorflow/core/common_runtime/pluggable_device/pluggable_device_factory.cc:272] Created TensorFlow device (/job:localhost/replica:0/task:0/device:GPU:0 with 14845 MB memory) -> physical PluggableDevice (device: 0, name: DML, pci bus id: <undefined>)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 51ms/step - loss: 0.6623 - accuracy: 0.7116 - val_loss: 0.6639 - val_accuracy: 0.7099\n",
      "Epoch 6/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6521 - accuracy: 0.7341 - val_loss: 0.6558 - val_accuracy: 0.7244\n",
      "Epoch 7/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6429 - accuracy: 0.7416 - val_loss: 0.6486 - val_accuracy: 0.7468\n",
      "Epoch 8/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6345 - accuracy: 0.7790 - val_loss: 0.6419 - val_accuracy: 0.7452\n",
      "Epoch 9/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.6267 - accuracy: 0.7790 - val_loss: 0.6358 - val_accuracy: 0.7532\n",
      "Epoch 10/200\n",
      "1/1 [==============================] - 0s 62ms/step - loss: 0.6193 - accuracy: 0.7903 - val_loss: 0.6298 - val_accuracy: 0.7516\n",
      "Epoch 11/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.6121 - accuracy: 0.7903 - val_loss: 0.6236 - val_accuracy: 0.7548\n",
      "Epoch 12/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.6048 - accuracy: 0.8015 - val_loss: 0.6174 - val_accuracy: 0.7596\n",
      "Epoch 13/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5971 - accuracy: 0.8015 - val_loss: 0.6111 - val_accuracy: 0.7804\n",
      "Epoch 14/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.5896 - accuracy: 0.8052 - val_loss: 0.6050 - val_accuracy: 0.7853\n",
      "Epoch 15/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5821 - accuracy: 0.8090 - val_loss: 0.5990 - val_accuracy: 0.7853\n",
      "Epoch 16/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5746 - accuracy: 0.8127 - val_loss: 0.5931 - val_accuracy: 0.7837\n",
      "Epoch 17/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.5671 - accuracy: 0.8127 - val_loss: 0.5872 - val_accuracy: 0.7772\n",
      "Epoch 18/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5598 - accuracy: 0.8202 - val_loss: 0.5815 - val_accuracy: 0.7804\n",
      "Epoch 19/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.5525 - accuracy: 0.8202 - val_loss: 0.5758 - val_accuracy: 0.7821\n",
      "Epoch 20/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5454 - accuracy: 0.8165 - val_loss: 0.5703 - val_accuracy: 0.7837\n",
      "Epoch 21/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5385 - accuracy: 0.8127 - val_loss: 0.5649 - val_accuracy: 0.7853\n",
      "Epoch 22/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.5317 - accuracy: 0.8165 - val_loss: 0.5595 - val_accuracy: 0.7869\n",
      "Epoch 23/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5252 - accuracy: 0.8202 - val_loss: 0.5542 - val_accuracy: 0.7901\n",
      "Epoch 24/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.5187 - accuracy: 0.8240 - val_loss: 0.5489 - val_accuracy: 0.7885\n",
      "Epoch 25/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.5123 - accuracy: 0.8240 - val_loss: 0.5437 - val_accuracy: 0.7901\n",
      "Epoch 26/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.5059 - accuracy: 0.8240 - val_loss: 0.5385 - val_accuracy: 0.7869\n",
      "Epoch 27/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4997 - accuracy: 0.8202 - val_loss: 0.5333 - val_accuracy: 0.7885\n",
      "Epoch 28/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4935 - accuracy: 0.8240 - val_loss: 0.5280 - val_accuracy: 0.7917\n",
      "Epoch 29/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4875 - accuracy: 0.8240 - val_loss: 0.5228 - val_accuracy: 0.7933\n",
      "Epoch 30/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4815 - accuracy: 0.8277 - val_loss: 0.5177 - val_accuracy: 0.7949\n",
      "Epoch 31/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4756 - accuracy: 0.8240 - val_loss: 0.5126 - val_accuracy: 0.7965\n",
      "Epoch 32/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.4696 - accuracy: 0.8240 - val_loss: 0.5076 - val_accuracy: 0.7965\n",
      "Epoch 33/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4639 - accuracy: 0.8240 - val_loss: 0.5027 - val_accuracy: 0.7965\n",
      "Epoch 34/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.4583 - accuracy: 0.8240 - val_loss: 0.4981 - val_accuracy: 0.7965\n",
      "Epoch 35/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4530 - accuracy: 0.8240 - val_loss: 0.4937 - val_accuracy: 0.7965\n",
      "Epoch 36/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4480 - accuracy: 0.8240 - val_loss: 0.4894 - val_accuracy: 0.7965\n",
      "Epoch 37/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4431 - accuracy: 0.8240 - val_loss: 0.4854 - val_accuracy: 0.7965\n",
      "Epoch 38/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.4385 - accuracy: 0.8240 - val_loss: 0.4816 - val_accuracy: 0.7965\n",
      "Epoch 39/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.4341 - accuracy: 0.8240 - val_loss: 0.4780 - val_accuracy: 0.7949\n",
      "Epoch 40/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.4298 - accuracy: 0.8240 - val_loss: 0.4747 - val_accuracy: 0.7949\n",
      "Epoch 41/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.4259 - accuracy: 0.8240 - val_loss: 0.4716 - val_accuracy: 0.7981\n",
      "Epoch 42/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.4221 - accuracy: 0.8240 - val_loss: 0.4688 - val_accuracy: 0.8029\n",
      "Epoch 43/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4187 - accuracy: 0.8240 - val_loss: 0.4661 - val_accuracy: 0.8029\n",
      "Epoch 44/200\n",
      "1/1 [==============================] - 0s 58ms/step - loss: 0.4154 - accuracy: 0.8240 - val_loss: 0.4637 - val_accuracy: 0.8013\n",
      "Epoch 45/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.4124 - accuracy: 0.8277 - val_loss: 0.4614 - val_accuracy: 0.8013\n",
      "Epoch 46/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.4095 - accuracy: 0.8277 - val_loss: 0.4594 - val_accuracy: 0.8013\n",
      "Epoch 47/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4068 - accuracy: 0.8277 - val_loss: 0.4575 - val_accuracy: 0.8013\n",
      "Epoch 48/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.4041 - accuracy: 0.8277 - val_loss: 0.4558 - val_accuracy: 0.7997\n",
      "Epoch 49/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.4016 - accuracy: 0.8277 - val_loss: 0.4543 - val_accuracy: 0.8013\n",
      "Epoch 50/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3992 - accuracy: 0.8315 - val_loss: 0.4528 - val_accuracy: 0.8013\n",
      "Epoch 51/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3969 - accuracy: 0.8315 - val_loss: 0.4515 - val_accuracy: 0.8013\n",
      "Epoch 52/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3948 - accuracy: 0.8315 - val_loss: 0.4502 - val_accuracy: 0.7997\n",
      "Epoch 53/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3927 - accuracy: 0.8315 - val_loss: 0.4490 - val_accuracy: 0.8029\n",
      "Epoch 54/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3907 - accuracy: 0.8315 - val_loss: 0.4480 - val_accuracy: 0.8029\n",
      "Epoch 55/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3889 - accuracy: 0.8315 - val_loss: 0.4470 - val_accuracy: 0.8045\n",
      "Epoch 56/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3870 - accuracy: 0.8352 - val_loss: 0.4462 - val_accuracy: 0.8093\n",
      "Epoch 57/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3853 - accuracy: 0.8390 - val_loss: 0.4454 - val_accuracy: 0.8109\n",
      "Epoch 58/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3836 - accuracy: 0.8390 - val_loss: 0.4447 - val_accuracy: 0.8093\n",
      "Epoch 59/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3819 - accuracy: 0.8464 - val_loss: 0.4441 - val_accuracy: 0.8125\n",
      "Epoch 60/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3802 - accuracy: 0.8427 - val_loss: 0.4435 - val_accuracy: 0.8125\n",
      "Epoch 61/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3787 - accuracy: 0.8427 - val_loss: 0.4430 - val_accuracy: 0.8173\n",
      "Epoch 62/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3772 - accuracy: 0.8427 - val_loss: 0.4426 - val_accuracy: 0.8157\n",
      "Epoch 63/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3758 - accuracy: 0.8427 - val_loss: 0.4421 - val_accuracy: 0.8141\n",
      "Epoch 64/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3744 - accuracy: 0.8427 - val_loss: 0.4417 - val_accuracy: 0.8125\n",
      "Epoch 65/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3731 - accuracy: 0.8390 - val_loss: 0.4413 - val_accuracy: 0.8125\n",
      "Epoch 66/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3718 - accuracy: 0.8390 - val_loss: 0.4409 - val_accuracy: 0.8125\n",
      "Epoch 67/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3705 - accuracy: 0.8390 - val_loss: 0.4404 - val_accuracy: 0.8125\n",
      "Epoch 68/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3693 - accuracy: 0.8390 - val_loss: 0.4400 - val_accuracy: 0.8125\n",
      "Epoch 69/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3681 - accuracy: 0.8427 - val_loss: 0.4396 - val_accuracy: 0.8125\n",
      "Epoch 70/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3669 - accuracy: 0.8427 - val_loss: 0.4392 - val_accuracy: 0.8109\n",
      "Epoch 71/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3658 - accuracy: 0.8464 - val_loss: 0.4388 - val_accuracy: 0.8141\n",
      "Epoch 72/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3648 - accuracy: 0.8502 - val_loss: 0.4384 - val_accuracy: 0.8205\n",
      "Epoch 73/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3637 - accuracy: 0.8539 - val_loss: 0.4380 - val_accuracy: 0.8189\n",
      "Epoch 74/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3627 - accuracy: 0.8539 - val_loss: 0.4377 - val_accuracy: 0.8189\n",
      "Epoch 75/200\n",
      "1/1 [==============================] - 0s 59ms/step - loss: 0.3618 - accuracy: 0.8577 - val_loss: 0.4375 - val_accuracy: 0.8189\n",
      "Epoch 76/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3608 - accuracy: 0.8577 - val_loss: 0.4373 - val_accuracy: 0.8125\n",
      "Epoch 77/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3599 - accuracy: 0.8614 - val_loss: 0.4371 - val_accuracy: 0.8125\n",
      "Epoch 78/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3590 - accuracy: 0.8614 - val_loss: 0.4370 - val_accuracy: 0.8157\n",
      "Epoch 79/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3582 - accuracy: 0.8614 - val_loss: 0.4369 - val_accuracy: 0.8141\n",
      "Epoch 80/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3574 - accuracy: 0.8614 - val_loss: 0.4368 - val_accuracy: 0.8125\n",
      "Epoch 81/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3566 - accuracy: 0.8652 - val_loss: 0.4368 - val_accuracy: 0.8125\n",
      "Epoch 82/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3558 - accuracy: 0.8652 - val_loss: 0.4368 - val_accuracy: 0.8157\n",
      "Epoch 83/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3550 - accuracy: 0.8652 - val_loss: 0.4368 - val_accuracy: 0.8157\n",
      "Epoch 84/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3542 - accuracy: 0.8614 - val_loss: 0.4369 - val_accuracy: 0.8173\n",
      "Epoch 85/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3535 - accuracy: 0.8614 - val_loss: 0.4369 - val_accuracy: 0.8173\n",
      "Epoch 86/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3528 - accuracy: 0.8614 - val_loss: 0.4370 - val_accuracy: 0.8189\n",
      "Epoch 87/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3521 - accuracy: 0.8614 - val_loss: 0.4371 - val_accuracy: 0.8173\n",
      "Epoch 88/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3513 - accuracy: 0.8614 - val_loss: 0.4372 - val_accuracy: 0.8173\n",
      "Epoch 89/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3506 - accuracy: 0.8614 - val_loss: 0.4373 - val_accuracy: 0.8173\n",
      "Epoch 90/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3499 - accuracy: 0.8614 - val_loss: 0.4374 - val_accuracy: 0.8173\n",
      "Epoch 91/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3493 - accuracy: 0.8614 - val_loss: 0.4375 - val_accuracy: 0.8173\n",
      "Epoch 92/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3486 - accuracy: 0.8614 - val_loss: 0.4377 - val_accuracy: 0.8173\n",
      "Epoch 93/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3479 - accuracy: 0.8614 - val_loss: 0.4378 - val_accuracy: 0.8173\n",
      "Epoch 94/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3472 - accuracy: 0.8614 - val_loss: 0.4380 - val_accuracy: 0.8173\n",
      "Epoch 95/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3465 - accuracy: 0.8614 - val_loss: 0.4381 - val_accuracy: 0.8173\n",
      "Epoch 96/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3458 - accuracy: 0.8614 - val_loss: 0.4383 - val_accuracy: 0.8173\n",
      "Epoch 97/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3452 - accuracy: 0.8614 - val_loss: 0.4386 - val_accuracy: 0.8173\n",
      "Epoch 98/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3446 - accuracy: 0.8614 - val_loss: 0.4388 - val_accuracy: 0.8173\n",
      "Epoch 99/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3440 - accuracy: 0.8614 - val_loss: 0.4390 - val_accuracy: 0.8173\n",
      "Epoch 100/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3433 - accuracy: 0.8614 - val_loss: 0.4393 - val_accuracy: 0.8173\n",
      "Epoch 101/200\n",
      "1/1 [==============================] - 0s 41ms/step - loss: 0.3427 - accuracy: 0.8614 - val_loss: 0.4395 - val_accuracy: 0.8173\n",
      "Epoch 102/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3421 - accuracy: 0.8577 - val_loss: 0.4397 - val_accuracy: 0.8173\n",
      "Epoch 103/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3415 - accuracy: 0.8577 - val_loss: 0.4399 - val_accuracy: 0.8205\n",
      "Epoch 104/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3409 - accuracy: 0.8577 - val_loss: 0.4401 - val_accuracy: 0.8205\n",
      "Epoch 105/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3404 - accuracy: 0.8577 - val_loss: 0.4403 - val_accuracy: 0.8205\n",
      "Epoch 106/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3398 - accuracy: 0.8577 - val_loss: 0.4406 - val_accuracy: 0.8205\n",
      "Epoch 107/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3392 - accuracy: 0.8577 - val_loss: 0.4408 - val_accuracy: 0.8205\n",
      "Epoch 108/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3386 - accuracy: 0.8577 - val_loss: 0.4410 - val_accuracy: 0.8205\n",
      "Epoch 109/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3381 - accuracy: 0.8577 - val_loss: 0.4411 - val_accuracy: 0.8205\n",
      "Epoch 110/200\n",
      "1/1 [==============================] - 0s 55ms/step - loss: 0.3375 - accuracy: 0.8614 - val_loss: 0.4413 - val_accuracy: 0.8205\n",
      "Epoch 111/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3369 - accuracy: 0.8614 - val_loss: 0.4415 - val_accuracy: 0.8205\n",
      "Epoch 112/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3364 - accuracy: 0.8614 - val_loss: 0.4417 - val_accuracy: 0.8205\n",
      "Epoch 113/200\n",
      "1/1 [==============================] - 0s 42ms/step - loss: 0.3358 - accuracy: 0.8614 - val_loss: 0.4419 - val_accuracy: 0.8157\n",
      "Epoch 114/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3352 - accuracy: 0.8614 - val_loss: 0.4422 - val_accuracy: 0.8157\n",
      "Epoch 115/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3346 - accuracy: 0.8652 - val_loss: 0.4424 - val_accuracy: 0.8157\n",
      "Epoch 116/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3341 - accuracy: 0.8652 - val_loss: 0.4427 - val_accuracy: 0.8157\n",
      "Epoch 117/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3335 - accuracy: 0.8652 - val_loss: 0.4430 - val_accuracy: 0.8157\n",
      "Epoch 118/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3329 - accuracy: 0.8652 - val_loss: 0.4432 - val_accuracy: 0.8157\n",
      "Epoch 119/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3323 - accuracy: 0.8652 - val_loss: 0.4435 - val_accuracy: 0.8157\n",
      "Epoch 120/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3318 - accuracy: 0.8652 - val_loss: 0.4437 - val_accuracy: 0.8157\n",
      "Epoch 121/200\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3312 - accuracy: 0.8652 - val_loss: 0.4439 - val_accuracy: 0.8173\n",
      "Epoch 122/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3307 - accuracy: 0.8652 - val_loss: 0.4441 - val_accuracy: 0.8173\n",
      "Epoch 123/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3301 - accuracy: 0.8652 - val_loss: 0.4443 - val_accuracy: 0.8173\n",
      "Epoch 124/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3296 - accuracy: 0.8652 - val_loss: 0.4445 - val_accuracy: 0.8173\n",
      "Epoch 125/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3291 - accuracy: 0.8652 - val_loss: 0.4448 - val_accuracy: 0.8173\n",
      "Epoch 126/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3286 - accuracy: 0.8652 - val_loss: 0.4450 - val_accuracy: 0.8173\n",
      "Epoch 127/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3281 - accuracy: 0.8652 - val_loss: 0.4453 - val_accuracy: 0.8173\n",
      "Epoch 128/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3276 - accuracy: 0.8652 - val_loss: 0.4456 - val_accuracy: 0.8189\n",
      "Epoch 129/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3271 - accuracy: 0.8652 - val_loss: 0.4459 - val_accuracy: 0.8189\n",
      "Epoch 130/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3266 - accuracy: 0.8652 - val_loss: 0.4461 - val_accuracy: 0.8189\n",
      "Epoch 131/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3261 - accuracy: 0.8652 - val_loss: 0.4464 - val_accuracy: 0.8189\n",
      "Epoch 132/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3256 - accuracy: 0.8652 - val_loss: 0.4467 - val_accuracy: 0.8189\n",
      "Epoch 133/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3251 - accuracy: 0.8652 - val_loss: 0.4469 - val_accuracy: 0.8189\n",
      "Epoch 134/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3247 - accuracy: 0.8652 - val_loss: 0.4471 - val_accuracy: 0.8205\n",
      "Epoch 135/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3242 - accuracy: 0.8652 - val_loss: 0.4474 - val_accuracy: 0.8205\n",
      "Epoch 136/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3237 - accuracy: 0.8652 - val_loss: 0.4476 - val_accuracy: 0.8205\n",
      "Epoch 137/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3232 - accuracy: 0.8652 - val_loss: 0.4479 - val_accuracy: 0.8205\n",
      "Epoch 138/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3228 - accuracy: 0.8689 - val_loss: 0.4482 - val_accuracy: 0.8205\n",
      "Epoch 139/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3223 - accuracy: 0.8689 - val_loss: 0.4484 - val_accuracy: 0.8205\n",
      "Epoch 140/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3218 - accuracy: 0.8689 - val_loss: 0.4487 - val_accuracy: 0.8205\n",
      "Epoch 141/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3213 - accuracy: 0.8689 - val_loss: 0.4491 - val_accuracy: 0.8205\n",
      "Epoch 142/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3208 - accuracy: 0.8689 - val_loss: 0.4494 - val_accuracy: 0.8205\n",
      "Epoch 143/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3203 - accuracy: 0.8689 - val_loss: 0.4498 - val_accuracy: 0.8205\n",
      "Epoch 144/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3198 - accuracy: 0.8689 - val_loss: 0.4501 - val_accuracy: 0.8205\n",
      "Epoch 145/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3193 - accuracy: 0.8689 - val_loss: 0.4505 - val_accuracy: 0.8221\n",
      "Epoch 146/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3189 - accuracy: 0.8689 - val_loss: 0.4510 - val_accuracy: 0.8221\n",
      "Epoch 147/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3184 - accuracy: 0.8727 - val_loss: 0.4514 - val_accuracy: 0.8205\n",
      "Epoch 148/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3179 - accuracy: 0.8727 - val_loss: 0.4518 - val_accuracy: 0.8205\n",
      "Epoch 149/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3175 - accuracy: 0.8727 - val_loss: 0.4523 - val_accuracy: 0.8205\n",
      "Epoch 150/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3170 - accuracy: 0.8727 - val_loss: 0.4527 - val_accuracy: 0.8189\n",
      "Epoch 151/200\n",
      "1/1 [==============================] - 0s 52ms/step - loss: 0.3165 - accuracy: 0.8689 - val_loss: 0.4532 - val_accuracy: 0.8189\n",
      "Epoch 152/200\n",
      "1/1 [==============================] - 0s 54ms/step - loss: 0.3161 - accuracy: 0.8689 - val_loss: 0.4536 - val_accuracy: 0.8189\n",
      "Epoch 153/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3156 - accuracy: 0.8689 - val_loss: 0.4541 - val_accuracy: 0.8189\n",
      "Epoch 154/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3152 - accuracy: 0.8689 - val_loss: 0.4545 - val_accuracy: 0.8173\n",
      "Epoch 155/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3147 - accuracy: 0.8689 - val_loss: 0.4549 - val_accuracy: 0.8173\n",
      "Epoch 156/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3142 - accuracy: 0.8689 - val_loss: 0.4554 - val_accuracy: 0.8173\n",
      "Epoch 157/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3138 - accuracy: 0.8727 - val_loss: 0.4557 - val_accuracy: 0.8173\n",
      "Epoch 158/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3133 - accuracy: 0.8727 - val_loss: 0.4561 - val_accuracy: 0.8157\n",
      "Epoch 159/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3129 - accuracy: 0.8727 - val_loss: 0.4565 - val_accuracy: 0.8173\n",
      "Epoch 160/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3124 - accuracy: 0.8727 - val_loss: 0.4568 - val_accuracy: 0.8173\n",
      "Epoch 161/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3119 - accuracy: 0.8727 - val_loss: 0.4572 - val_accuracy: 0.8173\n",
      "Epoch 162/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3115 - accuracy: 0.8727 - val_loss: 0.4576 - val_accuracy: 0.8173\n",
      "Epoch 163/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3111 - accuracy: 0.8764 - val_loss: 0.4581 - val_accuracy: 0.8173\n",
      "Epoch 164/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.3106 - accuracy: 0.8764 - val_loss: 0.4586 - val_accuracy: 0.8157\n",
      "Epoch 165/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3102 - accuracy: 0.8764 - val_loss: 0.4590 - val_accuracy: 0.8141\n",
      "Epoch 166/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.3097 - accuracy: 0.8764 - val_loss: 0.4594 - val_accuracy: 0.8125\n",
      "Epoch 167/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3093 - accuracy: 0.8764 - val_loss: 0.4599 - val_accuracy: 0.8125\n",
      "Epoch 168/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3088 - accuracy: 0.8764 - val_loss: 0.4603 - val_accuracy: 0.8125\n",
      "Epoch 169/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3084 - accuracy: 0.8764 - val_loss: 0.4608 - val_accuracy: 0.8125\n",
      "Epoch 170/200\n",
      "1/1 [==============================] - 0s 56ms/step - loss: 0.3079 - accuracy: 0.8764 - val_loss: 0.4612 - val_accuracy: 0.8125\n",
      "Epoch 171/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3075 - accuracy: 0.8764 - val_loss: 0.4617 - val_accuracy: 0.8125\n",
      "Epoch 172/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3071 - accuracy: 0.8764 - val_loss: 0.4622 - val_accuracy: 0.8125\n",
      "Epoch 173/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.3066 - accuracy: 0.8764 - val_loss: 0.4626 - val_accuracy: 0.8125\n",
      "Epoch 174/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3062 - accuracy: 0.8764 - val_loss: 0.4631 - val_accuracy: 0.8125\n",
      "Epoch 175/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3058 - accuracy: 0.8764 - val_loss: 0.4635 - val_accuracy: 0.8125\n",
      "Epoch 176/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.3053 - accuracy: 0.8764 - val_loss: 0.4639 - val_accuracy: 0.8125\n",
      "Epoch 177/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3049 - accuracy: 0.8764 - val_loss: 0.4644 - val_accuracy: 0.8125\n",
      "Epoch 178/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3045 - accuracy: 0.8764 - val_loss: 0.4650 - val_accuracy: 0.8125\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 179/200\n",
      "1/1 [==============================] - 0s 47ms/step - loss: 0.3040 - accuracy: 0.8764 - val_loss: 0.4656 - val_accuracy: 0.8125\n",
      "Epoch 180/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3036 - accuracy: 0.8764 - val_loss: 0.4662 - val_accuracy: 0.8125\n",
      "Epoch 181/200\n",
      "1/1 [==============================] - 0s 53ms/step - loss: 0.3032 - accuracy: 0.8764 - val_loss: 0.4668 - val_accuracy: 0.8125\n",
      "Epoch 182/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3028 - accuracy: 0.8764 - val_loss: 0.4674 - val_accuracy: 0.8125\n",
      "Epoch 183/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.3023 - accuracy: 0.8764 - val_loss: 0.4679 - val_accuracy: 0.8125\n",
      "Epoch 184/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.3019 - accuracy: 0.8764 - val_loss: 0.4684 - val_accuracy: 0.8125\n",
      "Epoch 185/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3015 - accuracy: 0.8764 - val_loss: 0.4690 - val_accuracy: 0.8125\n",
      "Epoch 186/200\n",
      "1/1 [==============================] - 0s 48ms/step - loss: 0.3011 - accuracy: 0.8764 - val_loss: 0.4696 - val_accuracy: 0.8109\n",
      "Epoch 187/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3006 - accuracy: 0.8801 - val_loss: 0.4702 - val_accuracy: 0.8109\n",
      "Epoch 188/200\n",
      "1/1 [==============================] - 0s 43ms/step - loss: 0.3002 - accuracy: 0.8801 - val_loss: 0.4707 - val_accuracy: 0.8109\n",
      "Epoch 189/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2997 - accuracy: 0.8801 - val_loss: 0.4712 - val_accuracy: 0.8109\n",
      "Epoch 190/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2993 - accuracy: 0.8801 - val_loss: 0.4718 - val_accuracy: 0.8109\n",
      "Epoch 191/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2988 - accuracy: 0.8801 - val_loss: 0.4724 - val_accuracy: 0.8109\n",
      "Epoch 192/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2984 - accuracy: 0.8801 - val_loss: 0.4730 - val_accuracy: 0.8109\n",
      "Epoch 193/200\n",
      "1/1 [==============================] - 0s 51ms/step - loss: 0.2979 - accuracy: 0.8801 - val_loss: 0.4737 - val_accuracy: 0.8109\n",
      "Epoch 194/200\n",
      "1/1 [==============================] - 0s 49ms/step - loss: 0.2975 - accuracy: 0.8801 - val_loss: 0.4743 - val_accuracy: 0.8109\n",
      "Epoch 195/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2970 - accuracy: 0.8801 - val_loss: 0.4750 - val_accuracy: 0.8109\n",
      "Epoch 196/200\n",
      "1/1 [==============================] - 0s 50ms/step - loss: 0.2966 - accuracy: 0.8801 - val_loss: 0.4756 - val_accuracy: 0.8093\n",
      "Epoch 197/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2961 - accuracy: 0.8801 - val_loss: 0.4762 - val_accuracy: 0.8093\n",
      "Epoch 198/200\n",
      "1/1 [==============================] - 0s 46ms/step - loss: 0.2957 - accuracy: 0.8801 - val_loss: 0.4768 - val_accuracy: 0.8093\n",
      "Epoch 199/200\n",
      "1/1 [==============================] - 0s 44ms/step - loss: 0.2952 - accuracy: 0.8801 - val_loss: 0.4775 - val_accuracy: 0.8093\n",
      "Epoch 200/200\n",
      "1/1 [==============================] - 0s 45ms/step - loss: 0.2948 - accuracy: 0.8801 - val_loss: 0.4781 - val_accuracy: 0.8093\n",
      "20/20 [==============================] - 0s 3ms/step\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.62      1.00      0.76       386\n",
      "           1       0.00      0.00      0.00       238\n",
      "\n",
      "    accuracy                           0.62       624\n",
      "   macro avg       0.31      0.50      0.38       624\n",
      "weighted avg       0.38      0.62      0.47       624\n",
      "\n",
      "Model: \"titanic\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_21 (Dense)            multiple                  224       \n",
      "                                                                 \n",
      " dense_22 (Dense)            multiple                  2112      \n",
      "                                                                 \n",
      " dense_23 (Dense)            multiple                  1040      \n",
      "                                                                 \n",
      " dense_24 (Dense)            multiple                  17        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,393\n",
      "Trainable params: 3,393\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-09-09 15:47:51.817672: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:114] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "history = model.fit(X_train, y_train, epochs=200, batch_size=500, validation_data=(X_test, y_test))\n",
    "pred = model.predict(X_test)\n",
    "pred= pd.DataFrame(pred)\n",
    "pred = pred[0].apply(lambda x: 1 if x>5 else 0)\n",
    "print(classification_report(y_test,pred))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3cff6b6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80323e35",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6002523",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbef10ac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0341ef6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "646ddb83",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d152ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

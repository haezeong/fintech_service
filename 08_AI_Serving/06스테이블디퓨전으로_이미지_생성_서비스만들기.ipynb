{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5618a225",
   "metadata": {},
   "source": [
    "생성형 ai"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2b50cd9",
   "metadata": {},
   "source": [
    "# 스테이블디퓨전으로 이미지 생성 서비스 만들기\n",
    "* 두가지 버전 만들건데\n",
    "* 1. 간단한 스케치를 기반으로 이미지 생성\n",
    "* 2. 스케치가 되어있는 이미지를 업로드해서 생성\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18271321",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install diffusers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1f15522e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import os\n",
    "from typing import IO\n",
    "import gradio as gr\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from diffusers import StableDiffusionImg2ImgPipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed883b19",
   "metadata": {},
   "source": [
    "# 스케치 투 이미지 생성 UI 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e5f84b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.40.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "WIDTH =512\n",
    "HEIGHT =256\n",
    "\n",
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"## 프롬프트 입력\")\n",
    "    with gr.Row():\n",
    "        prompt = gr.Textbox(label =\"Prompt\")\n",
    "    with gr.Row():\n",
    "        n_prompt= gr.Textbox(label =\"Nagative Prompt\")\n",
    "    \n",
    "    gr.Markdown(\"## 스케치 to 이미지 생성\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            with gr.Tab(\"Canvas\"):\n",
    "                with gr.Row():\n",
    "                    canvas = gr.Image(\n",
    "                        label =\"Draw\",\n",
    "                        source ='canvas',\n",
    "                        image_mode ='RGB',\n",
    "                        tool='color-sketch',\n",
    "                        interactive = True,\n",
    "                        width =WIDTH,\n",
    "                        height = HEIGHT,\n",
    "                        shape =(WIDTH,HEIGHT),\n",
    "                        brush_radius =20,\n",
    "                        type='pil'\n",
    "                    )\n",
    "                with gr.Row():\n",
    "                    canvas_run_btn = gr.Button(value='Generate')\n",
    "                    \n",
    "            with gr.Tab(\"File\"):\n",
    "                with gr.Row():\n",
    "                    file = gr.Image(\n",
    "                        label =\"Upload\",\n",
    "                        source ='upload',\n",
    "                        image_mode ='RGB',\n",
    "                        tool='color-sketch',\n",
    "                        interactive = True,\n",
    "                        width =WIDTH,\n",
    "                        height = HEIGHT,\n",
    "                        shape =(WIDTH,HEIGHT),\n",
    "                        type='pil'\n",
    "                    )\n",
    "                    \n",
    "                with gr.Row():\n",
    "                    file_run_btn = gr.Button(value='Generate')\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "617debfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7866\n",
      "Running on public URL: https://09a1c659fcf85a13ce.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "app.launch(inline=False, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3c14808b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7866\n"
     ]
    }
   ],
   "source": [
    "app.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5baf166b",
   "metadata": {},
   "source": [
    "# 모델 다운로드 UI 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a994e277",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.40.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"## 모델 다운로드\")\n",
    "    with gr.Row():\n",
    "        model_url = gr.Textbox(label = \"모델 URL\", placeholder = \"https://civitai.com/\")\n",
    "        download_model_btn = gr.Button(value = \"모델 다운로드\")\n",
    "    with gr.Row():\n",
    "        model_file = gr.File(label = \"모델 파일\")\n",
    "\n",
    "    download_model_btn.click(\n",
    "        download_model,\n",
    "        [model_url],\n",
    "        [model_file]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f4ed3b0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7866\n",
      "Running on public URL: https://5e131cd84afd9a37ec.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "models/disneyPixarCartoon_v10.safetensors: 100%|██████████████████████| 3.95G/3.95G [10:58<00:00, 6.45MiB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] File downloaded: models/disneyPixarCartoon_v10.safetensors\n",
      "[INFO] File already exists: models/disneyPixarCartoon_v10.safetensors\n",
      "[INFO] File already exists: models/disneyPixarCartoon_v10.safetensors\n"
     ]
    }
   ],
   "source": [
    "app.launch(inline=False, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c1800b",
   "metadata": {},
   "outputs": [],
   "source": [
    "app.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2588bca1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ad14b1ae",
   "metadata": {},
   "source": [
    "# 모델 다운로드 기능 구현하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "26fa94ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import glob  # 디렉토리 안에 있는 모든 파일명을 리스트로 만들어주는 라이브러리\n",
    "\n",
    "\n",
    "# 전역변수로 모델 경로와 파일명을 저장\n",
    "MODEL_PATH = None \n",
    "\n",
    "# URL로부터 파일 다운로드 함수\n",
    "def download_from_url(url, file_path, chunk_size=1024):\n",
    "    try:\n",
    "        resp = requests.get(url, stream = True)\n",
    "        resp.raise_for_status()\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] {e}\")\n",
    "        raise e \n",
    "\n",
    "    total = int(resp.headers.get('content-length', 0))  # 파일 크기 추출\n",
    "    with open(file_path, 'wb') as file, tqdm(desc=file_path, total=total, unit='iB', unit_scale=True, \n",
    "                                            unit_divisor = 1024) as bar:\n",
    "        for data in resp.iter_content(chunk_size=chunk_size):\n",
    "            size = file.write(data)\n",
    "            bar.update(size)\n",
    "\n",
    "\n",
    "# 모델을 다운로드하고 경로를 기억하는 함수\n",
    "def download_model(url: str) -> str: \n",
    "    global MODEL_PATH    # 전역 변수를 사용해서 경로를 파악\n",
    "\n",
    "    model_id = url.replace(\"https://civitai.com/models/\", \"\").split(\"/\")[0]\n",
    "\n",
    "    try:\n",
    "        response = requests.get(f\"https://civitai.com/api/v1/models/{model_id}\", timeout = 6000)\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] {e}\")\n",
    "        raise e\n",
    "\n",
    "    download_url = response.json()['modelVersions'][0]['downloadUrl']\n",
    "    filename = response.json()['modelVersions'][0]['files'][0]['name']\n",
    "\n",
    "    file_path = f\"models/{filename}\"\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"[INFO] File already exists: {file_path}\")\n",
    "        MODEL_PATH = file_path   # 모델 경로 기억\n",
    "        return file_path \n",
    "\n",
    "    os.makedirs(\"models\", exist_ok = True)\n",
    "    download_from_url(download_url, file_path)\n",
    "    print(f\"[INFO] File downloaded: {file_path}\")\n",
    "\n",
    "# 모델 경로 기억\n",
    "    MODEL_PATH = file_path\n",
    "    return file_path\n",
    "\n",
    "\n",
    "# ./models 폴더에서 가장 최근에 수정된 모델 파일 찾기\n",
    "def find_latest_model_in_directory(directory):\n",
    "    model_files = glob.glob(f\"{directory}/*.safetensors\")\n",
    "    if not model_files:\n",
    "        return None\n",
    "\n",
    "\n",
    "# 가장 최근에 수정된 모델 파일 선택\n",
    "    latest_model = max(model_files, key =os.path.getmtime)\n",
    "    return latest_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6ae553e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "b905e33f",
   "metadata": {},
   "source": [
    "# 다운로드한 모델 불러와서 초기화하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "59956574",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_pipeline():\n",
    "    global MODEL_PATH \n",
    "\n",
    "    if MODEL_PATH is None:\n",
    "        MODEL_PATH = find_latest_model_in_directory(\"./models\")\n",
    "    if MODEL_PATH is None:\n",
    "        return \"Error: No model found in ./models\"\n",
    "\n",
    "    global PIPELINE\n",
    "\n",
    "    try:\n",
    "        PIPELINE = StableDiffusionImg2ImgPipeline.from_single_file(\n",
    "                MODEL_PATH,\n",
    "                torch_dtype = torch.float16,\n",
    "                variant = \"fp16\",\n",
    "                use_safetensors = True,\n",
    "        ).to('cpu')\n",
    "        print(\"[INFO] Initialized pipeline\")\n",
    "        return \"Model Loaded!\"\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "2e727619",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IMPORTANT: You are using gradio version 3.40.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n"
     ]
    }
   ],
   "source": [
    "with gr.Blocks() as app:\n",
    "    gr.Markdown(\"## 모델 불러오기\")\n",
    "    with gr.Row():\n",
    "        load_model_btn = gr.Button(value=\"모델 불러오기\")\n",
    "    with gr.Row():\n",
    "        is_model_check = gr.Textbox(label=\"Model Load Check\", value=\"Model Not Loaded\")\n",
    "\n",
    "    load_model_btn.click(\n",
    "        init_pipeline,\n",
    "        None,\n",
    "        [is_model_check]\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f91130e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7870\n",
      "Running on public URL: https://98fc1fe06bdd6e306e.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Fetching 11 files: 100%|████████████████████████████████████████████████████| 11/11 [00:01<00:00, 10.74it/s]\n",
      "Loading pipeline components...:   0%|                                                 | 0/6 [00:00<?, ?it/s]/home/user/miniforge3/envs/torch/lib/python3.11/site-packages/transformers/models/clip/feature_extraction_clip.py:28: FutureWarning: The class CLIPFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use CLIPImageProcessor instead.\n",
      "  warnings.warn(\n",
      "Some weights of the model checkpoint were not used when initializing CLIPTextModel: \n",
      " ['text_model.embeddings.position_ids']\n",
      "Loading pipeline components...: 100%|█████████████████████████████████████████| 6/6 [00:32<00:00,  5.34s/it]\n",
      "You have disabled the safety checker for <class 'diffusers.pipelines.stable_diffusion.pipeline_stable_diffusion_img2img.StableDiffusionImg2ImgPipeline'> by passing `safety_checker=None`. Ensure that you abide to the conditions of the Stable Diffusion license and do not expose unfiltered results in services or applications open to the public. Both the diffusers team and Hugging Face strongly recommend to keep the safety filter enabled in all public facing circumstances, disabling it only for use-cases that involve analyzing network behavior or auditing its results. For more information, please have a look at https://github.com/huggingface/diffusers/pull/254 .\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n",
      "Pipelines loaded with `dtype=torch.float16` cannot run with `cpu` device. It is not recommended to move them to `cpu` as running them will fail. Please make sure to use an accelerator to run the pipeline in inference, due to the lack of support for`float16` operations on this device in PyTorch. Please, remove the `torch_dtype=torch.float16` argument, or use another device for inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Initialized pipeline\n"
     ]
    }
   ],
   "source": [
    "app.launch(inline=False, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8b203828",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing server running on port: 7870\n"
     ]
    }
   ],
   "source": [
    "app.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "550e2947",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0ca9238c",
   "metadata": {},
   "source": [
    "# 스케치 투 이미지 생성기능 구현"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef9057c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#모델을 불러와서 모델에서 이미지 생성하는\n",
    "def sketch_to_image(sketch, prompt, negative_prompt):\n",
    "    global PIPELINE\n",
    "    if PIPELINE is None:\n",
    "        return \"Error Pipeline is not initialized\"\n",
    "    prompt = [prompt]\n",
    "    negative_prompt =[negative_prompt]\n",
    "    \n",
    "    images =[sketch] * len(prompt)\n",
    "    \n",
    "    try:\n",
    "        #이미지 생성\n",
    "        result = PIPELINE(\n",
    "            image=images,\n",
    "            prompt=prompt\n",
    "            negative_prompt= negative_prompt,\n",
    "            height= height,\n",
    "            width=width,\n",
    "            num_images_per_prompt=4,\n",
    "            num_inference_steps=20,\n",
    "            strength = 0.7\n",
    "        ).images\n",
    "    except Excption as e:\n",
    "        print(e)\n",
    "        \n",
    "        #gpu메모리 캐시 비우기\n",
    "        #with torch.cuda.device(\"cuda\")\n",
    "        #torch.cuda.empty_cache()\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46753d03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "7b583bd1",
   "metadata": {},
   "source": [
    "# 이미지 생성 전체 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdeacbc5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/user/miniforge3/envs/torch/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "/home/user/miniforge3/envs/torch/lib/python3.11/site-packages/gradio_client/documentation.py:106: UserWarning: Could not get documentation group for <class 'gradio.mix.Parallel'>: No known documentation group for module 'gradio.mix'\n",
      "  warnings.warn(f\"Could not get documentation group for {cls}: {exc}\")\n",
      "/home/user/miniforge3/envs/torch/lib/python3.11/site-packages/gradio_client/documentation.py:106: UserWarning: Could not get documentation group for <class 'gradio.mix.Series'>: No known documentation group for module 'gradio.mix'\n",
      "  warnings.warn(f\"Could not get documentation group for {cls}: {exc}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import glob  # 디렉토리 안에 있는 모든 파일명을 리스트로 만들어주는 라이브러리\n",
    "from typing import IO\n",
    "import gradio as gr\n",
    "import requests\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "from diffusers import StableDiffusionImg2ImgPipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a1aaa7c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "WIDTH =512\n",
    "HEIGHT =512\n",
    "\n",
    "# 전역변수로 모델 경로와 파일명을 저장\n",
    "MODEL_PATH = None \n",
    "PIPELINE=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43e81877",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# URL로부터 파일 다운로드 함수\n",
    "def download_from_url(url, file_path, chunk_size=1024):\n",
    "    try:\n",
    "        resp = requests.get(url, stream = True)\n",
    "        resp.raise_for_status()\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] {e}\")\n",
    "        raise e \n",
    "\n",
    "    total = int(resp.headers.get('content-length', 0))  # 파일 크기 추출\n",
    "    with open(file_path, 'wb') as file, tqdm(desc=file_path, total=total, unit='iB', unit_scale=True, \n",
    "                                            unit_divisor = 1024) as bar:\n",
    "        for data in resp.iter_content(chunk_size=chunk_size):\n",
    "            size = file.write(data)\n",
    "            bar.update(size)\n",
    "\n",
    "\n",
    "# 모델을 다운로드하고 경로를 기억하는 함수\n",
    "def download_model(url: str) -> str: \n",
    "    global MODEL_PATH    # 전역 변수를 사용해서 경로를 파악\n",
    "\n",
    "    model_id = url.replace(\"https://civitai.com/models/\", \"\").split(\"/\")[0]\n",
    "\n",
    "    try:\n",
    "        response = requests.get(f\"https://civitai.com/api/v1/models/{model_id}\", timeout = 6000)\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] {e}\")\n",
    "        raise e\n",
    "\n",
    "    download_url = response.json()['modelVersions'][0]['downloadUrl']\n",
    "    filename = response.json()['modelVersions'][0]['files'][0]['name']\n",
    "\n",
    "    file_path = f\"models/{filename}\"\n",
    "    if os.path.exists(file_path):\n",
    "        print(f\"[INFO] File already exists: {file_path}\")\n",
    "        MODEL_PATH = file_path   # 모델 경로 기억\n",
    "        return file_path \n",
    "\n",
    "    os.makedirs(\"models\", exist_ok = True)\n",
    "    download_from_url(download_url, file_path)\n",
    "    print(f\"[INFO] File downloaded: {file_path}\")\n",
    "\n",
    "# 모델 경로 기억\n",
    "    MODEL_PATH = file_path\n",
    "    return file_path\n",
    "\n",
    "\n",
    "# ./models 폴더에서 가장 최근에 수정된 모델 파일 찾기\n",
    "def find_latest_model_in_directory(directory):\n",
    "    model_files = glob.glob(f\"{directory}/*.safetensors\")\n",
    "    if not model_files:\n",
    "        return None\n",
    "\n",
    "\n",
    "# 가장 최근에 수정된 모델 파일 선택\n",
    "    latest_model = max(model_files, key =os.path.getmtime)\n",
    "    return latest_model\n",
    "\n",
    "\n",
    "def init_pipeline():\n",
    "    global MODEL_PATH \n",
    "\n",
    "    if MODEL_PATH is None:\n",
    "        MODEL_PATH = find_latest_model_in_directory(\"./models\")\n",
    "    if MODEL_PATH is None:\n",
    "        return \"Error: No model found in ./models\"\n",
    "\n",
    "    global PIPELINE\n",
    "\n",
    "    try:\n",
    "        PIPELINE = StableDiffusionImg2ImgPipeline.from_single_file(\n",
    "                MODEL_PATH,\n",
    "                torch_dtype = torch.float32,\n",
    "                variant = \"fp32\",\n",
    "                use_safetensors = True,\n",
    "        ).to('cpu')\n",
    "        print(\"[INFO] Initialized pipeline\")\n",
    "        return \"Model Loaded!\"\n",
    "    except Exception as e:\n",
    "        print(f\"[Error] {e}\")\n",
    "        \n",
    "#모델을 불러와서 모델에서 이미지 생성하는\n",
    "def sketch_to_image(sketch, prompt, negative_prompt):\n",
    "    global PIPELINE\n",
    "    if PIPELINE is None:\n",
    "        return \"Error Pipeline is not initialized\"\n",
    "    prompt = [prompt]\n",
    "    negative_prompt =[negative_prompt]\n",
    "    \n",
    "    images =[sketch] * len(prompt)\n",
    "    \n",
    "    try:\n",
    "        #이미지 생성\n",
    "        result = PIPELINE(\n",
    "            image=images,\n",
    "            prompt=prompt,\n",
    "            negative_prompt= negative_prompt,\n",
    "            height= height,\n",
    "            width=width,\n",
    "            num_images_per_prompt=4,\n",
    "            num_inference_steps=20,\n",
    "            strength = 0.7\n",
    "        ).images\n",
    "    except Excption as e:\n",
    "        print(e)\n",
    "        return e\n",
    "        #gpu메모리 캐시 비우기\n",
    "        #with torch.cuda.device(\"cuda\")\n",
    "        #torch.cuda.empty_cache()\n",
    "        \n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04ebeb06",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5f8018a4",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "unindent does not match any outer indentation level (<tokenize>, line 78)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m<tokenize>:78\u001b[0;36m\u001b[0m\n\u001b[0;31m    download_model_btn.click(\u001b[0m\n\u001b[0m    ^\u001b[0m\n\u001b[0;31mIndentationError\u001b[0m\u001b[0;31m:\u001b[0m unindent does not match any outer indentation level\n"
     ]
    }
   ],
   "source": [
    "# with gr.Blocks() as app:\n",
    "    \n",
    "#     #모델 다운로드 블록\n",
    "# #     with gr.Blocks() as app:\n",
    "#     gr.Markdown(\"## 모델 다운로드\")\n",
    "#     with gr.Row():\n",
    "#         model_url = gr.Textbox(label = \"모델 URL\", placeholder = \"https://civitai.com/\")\n",
    "#         download_model_btn = gr.Button(value = \"모델 다운로드\")\n",
    "#     with gr.Row():\n",
    "#         model_file = gr.File(label = \"모델 파일\")\n",
    "\n",
    "#     download_model_btn.click(\n",
    "#         download_model,\n",
    "#         [model_url],\n",
    "#         [model_file]\n",
    "#     )\n",
    "    \n",
    "#     #모델 불러오기 블록\n",
    "#     gr.Markdown(\"## 모델 불러오기\")\n",
    "#     with gr.Row():\n",
    "#         load_model_btn = gr.Button(value=\"모델 불러오기\")\n",
    "#     with gr.Row():\n",
    "#         is_model_check = gr.Textbox(label=\"Model Load Check\", value=\"Model Not Loaded\")\n",
    "\n",
    "    \n",
    "#     #프롬프트 입력 블록\n",
    "#     gr.Markdown(\"## 프롬프트 입력\")\n",
    "#     with gr.Row():\n",
    "#         prompt = gr.Textbox(label =\"Prompt\")\n",
    "#     with gr.Row():\n",
    "#         n_prompt= gr.Textbox(label =\"Nagative Prompt\")\n",
    "    \n",
    "#     #스케치에서 이미지 생성 블록\n",
    "#     gr.Markdown(\"## 스케치 to 이미지 생성\")\n",
    "#     with gr.Row():\n",
    "#         with gr.Column():\n",
    "#             with gr.Tab(\"Canvas\"):\n",
    "#                 with gr.Row():\n",
    "#                     canvas = gr.Image(\n",
    "#                         label =\"Draw\",\n",
    "#                         source ='canvas',\n",
    "#                         image_mode ='RGB',\n",
    "#                         tool='color-sketch',\n",
    "#                         interactive = True,\n",
    "#                         width =WIDTH,\n",
    "#                         height = HEIGHT,\n",
    "#                         shape =(WIDTH,HEIGHT),\n",
    "#                         brush_radius =20,\n",
    "#                         type='pil'\n",
    "#                     )\n",
    "#                 with gr.Row():\n",
    "#                     canvas_run_btn = gr.Button(value='Generate')\n",
    "                    \n",
    "#             with gr.Tab(\"File\"):\n",
    "#                 with gr.Row():\n",
    "#                     file = gr.Image(\n",
    "#                         label =\"Upload\",\n",
    "#                         source ='upload',\n",
    "#                         image_mode ='RGB',\n",
    "#                         tool='color-sketch',\n",
    "#                         interactive = True,\n",
    "#                         width =WIDTH,\n",
    "#                         height = HEIGHT,\n",
    "#                         shape =(WIDTH,HEIGHT),\n",
    "#                         type='pil'\n",
    "#                     )\n",
    "                    \n",
    "#                 with gr.Row():\n",
    "#                     file_run_btn = gr.Button(value='Generate')\n",
    "                    \n",
    "                    \n",
    "#         #결과 이미지 갤러리\n",
    "#         with gr.Column():\n",
    "#             result_gallery = gr.Gallery(label=\"Output\", height=512)\n",
    "            \n",
    "        \n",
    "#     #모델\n",
    "#      download_model_btn.click(\n",
    "#         download_model,\n",
    "#         [model_url],\n",
    "#         [model_file]\n",
    "#     )\n",
    "        \n",
    "#     #모델 로드 실행\n",
    "#     load_model_btn.click(\n",
    "#         init_pipeline,\n",
    "#         None,\n",
    "#         [is_model_check]\n",
    "#     )\n",
    "    \n",
    "#     #canvas에서 이미지 생성 버튼 실행\n",
    "#     canvas_run_btn.click(\n",
    "#         sketch_to_image,\n",
    "#         [canvas, prompt, n_prompt],\n",
    "#         [result_gallery]\n",
    "#         )\n",
    "    \n",
    "#     #File 업로드에서 이미지 생성 버튼 실행\n",
    "#     file_run_btn.click(\n",
    "#         sketch_to_image,\n",
    "#         [file, prompt, n_prompt],\n",
    "#         [result_gallery]\n",
    "#         )\n",
    "    \n",
    "# app.launch(inline=False, share=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9ebd88dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7866\n",
      "IMPORTANT: You are using gradio version 3.40.0, however version 4.29.0 is available, please upgrade.\n",
      "--------\n",
      "Running on public URL: https://9bb8f56e488b001119.gradio.live\n",
      "\n",
      "This share link expires in 72 hours. For free permanent hosting and GPU upgrades, run `gradio deploy` from Terminal to deploy to Spaces (https://huggingface.co/spaces)\n"
     ]
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with gr.Blocks() as app:\n",
    "    \n",
    "    # 모델 다운로드 블록\n",
    "    gr.Markdown(\"## 모델 다운로드\")\n",
    "    with gr.Row():\n",
    "        model_url = gr.Textbox(label = \"모델 URL\", placeholder = \"https://civitai.com/\")\n",
    "        download_model_btn = gr.Button(value = \"모델 다운로드\")\n",
    "    with gr.Row():\n",
    "        model_file = gr.File(label = \"모델 파일\")\n",
    "    \n",
    "    \n",
    "    # 모델 불러오기 블록\n",
    "    gr.Markdown(\"## 모델 불러오기\")\n",
    "    with gr.Row():\n",
    "        load_model_btn = gr.Button(value=\"모델 불러오기\")\n",
    "    with gr.Row():\n",
    "        is_model_check = gr.Textbox(label=\"Model Load Check\", value=\"Model Not Loaded\")\n",
    "        \n",
    "    \n",
    "    # 프롬프트 입력 블록\n",
    "    gr.Markdown(\"## 프롬프트 입력\")\n",
    "    with gr.Row():\n",
    "        prompt = gr.Textbox(label=\"Prompt\")\n",
    "    with gr.Row():\n",
    "        n_prompt = gr.Textbox(label=\"Negative Prompt\")\n",
    "    \n",
    "    \n",
    "    # 스케치에서 이미지 생성 블록\n",
    "    gr.Markdown(\"## 스케치 to 이미지 생성\")\n",
    "    with gr.Row():\n",
    "        with gr.Column():\n",
    "            with gr.Tab(\"Canvas\"):\n",
    "                with gr.Row():\n",
    "                    canvas = gr.Image(\n",
    "                        label = \"Draw\",\n",
    "                        source = \"canvas\",\n",
    "                        image_mode = 'RGB',\n",
    "                        tool = 'color-sketch',\n",
    "                        interactive = True,\n",
    "                        width = WIDTH, \n",
    "                        height = HEIGHT, \n",
    "                        shape = (WIDTH, HEIGHT), \n",
    "                        brush_radius = 20,\n",
    "                        type = 'pil'\n",
    "                    )         \n",
    "                with gr.Row():\n",
    "                    canvas_run_btn = gr.Button(value = \"Generate\")\n",
    "            \n",
    "            with gr.Tab(\"File\"):\n",
    "                with gr.Row():\n",
    "                    file = gr.Image(\n",
    "                        label = \"Upload\",\n",
    "                        source = \"upload\",\n",
    "                        image_mode = 'RGB',\n",
    "                        tool = 'color-sketch',\n",
    "                        interactive = True,\n",
    "                        width = WIDTH, \n",
    "                        height = HEIGHT, \n",
    "                        shape = (WIDTH, HEIGHT), \n",
    "                        type = 'pil'\n",
    "                    )\n",
    "                with gr.Row():\n",
    "                    file_run_btn = gr.Button(value = \"Generate\")\n",
    "        \n",
    "        # 결과 이미지 갤러리\n",
    "        with gr.Column():\n",
    "            result_gallery = gr.Gallery(label=\"Output\", height=512)\n",
    "    \n",
    "    \n",
    "    # 모델 다운로드 실행    \n",
    "    download_model_btn.click(\n",
    "        download_model,\n",
    "        [model_url],\n",
    "        [model_file]\n",
    "        )\n",
    "    # 모델 로드 실행          \n",
    "    load_model_btn.click(\n",
    "        init_pipeline,\n",
    "        None,\n",
    "        [is_model_check]\n",
    "        )\n",
    "    # Canvas 에서 이미지 생성 버튼 실행\n",
    "    canvas_run_btn.click(\n",
    "        sketch_to_image,\n",
    "        [canvas, prompt, n_prompt],\n",
    "        [result_gallery]\n",
    "        )\n",
    "    # File 업로드에서 이미지 생성 버튼 실행\n",
    "    file_run_btn.click(\n",
    "        sketch_to_image,\n",
    "        [file, prompt, n_prompt],\n",
    "        [result_gallery]\n",
    "        )\n",
    "    \n",
    "\n",
    "    \n",
    "    \n",
    "app.queue().launch(inline=False, share=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18b018af",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
